{
    "acceptedDate": "",
    "authors": [
        {
            "name": "Brand, Alexandra"
        }
    ],
    "contributors": [],
    "createdDate": "2019-07-09T10:53:57+01:00",
    "dataProvider": {
        "id": 1323,
        "name": "DigitalCommons@Pace",
        "url": "https://api.core.ac.uk/v3/data-providers/1323",
        "logo": "https://api.core.ac.uk/data-providers/1323/logo"
    },
    "depositedDate": "",
    "documentType": "research",
    "doi": "",
    "downloadUrl": "https://core.ac.uk/download/212892541.pdf",
    "fullText": "Pace UniversityDigitalCommons@PaceHonors College Theses Pforzheimer Honors CollegeSummer 7-2018Fake News and Editing: Marketing Techniquesused to Spin Controversies in Video MediumsAlexandra BrandHonors College, Pace UnivesityFollow this and additional works at: https://digitalcommons.pace.edu/honorscollege_thesesPart of the Communication Technology and New Media Commons, Journalism StudiesCommons, Mass Communication Commons, Social Influence and Political CommunicationCommons, and the Social Media CommonsThis Thesis is brought to you for free and open access by the Pforzheimer Honors College at DigitalCommons@Pace. It has been accepted for inclusionin Honors College Theses by an authorized administrator of DigitalCommons@Pace. For more information, please contact rracelis@pace.edu.Recommended CitationBrand, Alexandra, \"Fake News and Editing: Marketing Techniques used to Spin Controversies in Video Mediums\" (2018). HonorsCollege Theses. 166.https://digitalcommons.pace.edu/honorscollege_theses/166           Fake News and Editing:  Marketing Techniques Used to Spin Controversies in Video Mediums        Alexandra Brand Film and Screen Studies/Communication Studies Professor Colin Williamson May 2018     Brand 2  Table of Contents Abstract………………………………………………..……………………………...Page 3 Context of the Problem………………………………………………………………..Page 4-10 Methodology…………………………………………………………………………. Page 11-13 Results…………………………………………………………..……………………. Page 14-15 Discussion and Future Directions…………………………….……….…………..…. Page 16-18 Works Cited……………………..………………………….……………………..…. Page 19 Appendix……………………………………………………………………………... Page 20-30 Consent Form………………………………………………………………… Page 20-21 Survey Questionnaire ……………………………………………………..…. Page 22-24 Survey Links to Video A and B……………………………………… Page 22 List of Figures and Tables……………………………………………………. Page 25-30 Pie Chart IX…………………………………………………………... Page 25 Graph I……………………………………………………………..…. Page 26 Graph II……………………………………………………………..… Page 26 Graph III………………………………………………………...…….. Page 27 Pie Chart I………………………………………………………..……. Page 27-28 Pie Chart II…………………………………………………………….. Page 29 Pie Chart III……………………………………………………………. Page 30          Brand 3  Abstract This thesis explores the topic of fake news in today’s digital landscape by analyzing how young adults (18-23) form and change prior opinions based on the media they consume. I measured this by showing respondents one of two bias montages in response to Google’s Project Owl initiative. Project Owl is Google’s controversial attempt to regulate false or abusive news by launching new feedback forms in addition to altering their algorithm in a way the company has not yet disclosed to the public (Sullivan). Each self-edited montage is two minutes in length and together they cover two radically different responses to Project Owl: one is positioned critically against the principles behind this move by Google, and one is clearly in support of the company’s project.  To test the effects of “spinning” each video to change viewers’ perceptions of Project Owl, I developed a survey and designed a study to collect data from one-hundred people. Of the one-hundred people surveyed, half were randomly assigned to watch video A and half were randomly assigned to watch video B. Each participant was asked to answer a set of questions before and after watching their assigned video. The survey was designed to provide data on how their responses to Project Owl change after watching their assigned video. By using surveys that target the effects on audiences of informative video compilations that spin Project Owl, the thesis shows the manipulation of editing and short-form informational social media videos have on society more broadly.  This intricate project is especially relevant because, while President Donald Trump regularly reprimands the promotion of “fake news” through Twitter, left-wing activists argue that false information spread across the Internet contributed to the outcome of the 2016 election. These arguments from opposing sides are intensified in the 21st century age of New Media and information overload, a period in media history when the fact that the production and circulation of “news” can come from anyone, anywhere, and at any time means that the difficulty of assessing the authenticity and reliability of that information is increasing exponentially. Brand 4  Context of the Problem  Individuals have learned to recognize and combat fake news as early as the mid-nineteenth century. In 1835, a man known as the “Shakespeare of Advertising”, P.T. Barnum, launched his career with a traveling freak show called “P.T. Barnum’s Traveling Museum, Menagerie, Caravan & Hippodrome” (Liffreing). Although Barnum has been described as a devoted family man, he made his fortune by using deceitful tactics and elaborate disguises (Harris, 4). In this crucial Post-civil-war era, Barnum built an empire utilizing solely print media to elicit excitement and form a community that saw truth where he drew up radical hoaxes and outlandish headlines.  His first step in advertising the show was with a poster that described his female slave Joice Heth as “The greatest natural curiosity in the world,” “The first person to put clothes on President George Washington,” and “The most ancient specimen of mortality Americans were ever likely to experience,” (Harris, 22) By harping on the slave’s odd appearance and using her public speaking prowess, Barnum was able to convince many mainstream newspapers to write editorial and front-page stories on Heth (Harris, 24). Once that novelty wore off, Barnum took matter into his own hands by writing an anonymous letter to a Boston newspaper describing Heth as a robot, which made ticket sales skyrocket (Liffreing). Barnum went so far as to release a public autopsy for Heth in order to continue to capture the attention and speculation of people across America.  Throughout all of the schemes surrounding the mysterious Heth, Barnum developed his own special version of humbugging. This version of humbugging did not have to guarantee truthfulness, but simply possess probability and invite doubt (Harris, 23). The public time and time again accepted the humbugging because it appeared to solve certain problems of mass sensibility, such as reducing an encounter with that that is exotic or unfamiliar to a more simple judgement (Harris, 78). Viewers were Brand 5  much more excited at the idea of controversy rather than conclusiveness as long as the issue remained alive in print media. With the distribution of outlandish and exaggerated posters in many major cities, Americans began investigating the truth behind these advertising campaigns. Through the process of Americans conducting detailed research instead of using exclusively word-of-mouth to measure the validity of Barnum’s spectacles, Americans had the opportunity to become skeptical consumers. Barnum’s publication of lies through newspapers and posters serves as an example of fake news serving a purpose because Americans became more aware and less easily swayed by mass advertising. His campaigns served to “glorify doubt and celebrate individual judgement”, forcing consumers to begin to actively search for the meaning behind the media that was prevalent in their daily lives, which developed a skill that is still important and should be used by the global consumer today (Harris, 4).   The wave of New Media that ushered in the information age began most prominently in the 1970s. Journalist Ryan Holiday attributes the spread of this phenomenon to our Contemporary moment on blogs and blogging culture. He describes the heavily bias stories as a tactic used to increase internet traffic for sites and bloggers, just as P.T. Barnum drew traffic to his museum through print media hoaxes (Harris, 275). For example, in April 2011 Business Insider editor Henry Blodget asked for publicists to submit their own stories for product launches of their own clients. By lazily allowing the publicists to contribute directly to Business Insider instead of using his writers to create an objective story pitch and distribute unbiased information, he passed off advertisements constructed by marketing professionals as real news to his readers (Holiday, 218).  Manipulation can become more powerful than reality by creating a pseudo-event, trading it up the chain, eliciting real responses and action, a process that can end up altering reality itself (Holiday, 220). Another example of fake news becoming real occurred back in 2002 when Vice President Dick Brand 6  Cheney leaked bogus information to a reporter for the New York Times and then used the leak to address the subject on Meet the Press, further convincing the public to invade Iraq based on his media manipulation (Holiday, 221).  The increase in pseudo-events in the news has coincided with the proliferation of new media. One specific example surrounded the release of highly-anticipated film A Dog’s Purpose. Three weeks before the film was projected to gross more than $25 million its opening weekend, TMZ released an edited shareable video depicting the titular dog as nearly drowning during an on-set stunt. The headline, “TERRIFIED GERMAN SHEPHERD FORCED INTO TURBULENT WATER” in all caps went viral across all social media platforms and plunged the opening weekend earnings down nearly 20%. The damage had been done despite an independent investigative report finding that the two scenes shown in the video were filmed at separate times and were edited to include exclusively brief moments of distress from the dog.   Today’s trend of short shareable social media videos fall victim to this process of producing fake news often. Branded content is a huge factor in the success of the social media video industry. Restaurants, museums, and companies that are seeking to advertise products pay third-party platforms like Business Insider and Buzzfeed to produce videos and share these videos with their millions of followers. Most of Buzzfeed’s audiences who “like” these pages think that they are viewing videos from an unbiased entertainment and news source. Consequently, they decide to share the video with their own followers, furthering the chain of promotion and gaining traction using the “Two-step” flow of communication.  The two-step flow of communication hypothesis, first introduced by Paul Lazarsfeld, Bernard Berelson, and Hazel Gaudet, asserts that information from the media moves in two different stages: first from individuals (opinion leaders) who receive information from mass media and second from the Brand 7  opinion leaders to their followers after passing their own interpretations on the content (Mass Media: Two Step Flow Theory). The two-step flow of communication is particularly inter-woven with the internet medium and how social media videos are distributed because of the quick ability for Facebook users to share with their inner circles.  The current state of Internet privacy is a driving force in the reason why sponsored content is so effective. While computing tools can make the user feel like their data function for their personal gain, the sense of privacy is an illusion. Corporations make niche marketing campaigns based on extremely specific data submissions by users while governments have boundless access to private communications like social media posts, text messages, emails, and other data typically thought of as private (Internet Abuses and Privacy Rights, 3). The economic stakes that these corporations have in this enterprise also interfere with the physical access that users have to certain websites. Net neutrality, an idea that all traffic on the Internet should be treated equally, is heavily debated today because of the fear that ISP companies like Comcast could slow down web traffic for its competitors like Netflix or Hulu (Internet Abuses and Privacy Rights, 39). If net neutrality is restricted, it could limit the democratic nature of the Internet and oppress its utility in promoting free speech.  As a result of the use of misleading information and abuse of personal data, many consumers have asked whether the government should intervene to censor data in order to protect the general public by providing them with accurate information and keeping personal data out of reach of corporations. This concept is described as censorship, which has been heavily criticized by the American Civil Liberties Union for going against the first amendment and freedom of speech. The first amendment has protected the right of public school students to wear black armbands to protest the Vietnam War, struck down government bans on flag desecration, and released labor leader Eugene V. Debs from prison after he told a rally of workers that they were “fit for something better than slavery and cannon fodder.” Brand 8  (Roleff, 21). However, censorship supporters argue that hate groups like the Ku Klux Klan and the Neo-Nazis are also protected by organizations like the American Civil Liberties Union. To prevent fake and abusive language, the government and websites like Google or Facebook could get involved with monitoring content. In September of 2017, Mark Zuckerberg was criticized for allowing Russian groups to proliferate Facebook with false information involving smearing a candidate from the 2016 presidential election. As recently as April of 2018, Cambridge Analytica, the political data firm behind President Trump’s 2016 election, was exposed as having gained access to private information on more than 50 million Facebook users (Kang). This economic and political abuse of privacy rights and data collection via social media raised several new questions about whether website powerhouses should more closely monitor and protect the data users from potential breaches of confidentiality. This divide over whether the companies and political structures with power should interfere and ask companies to label their branded content or monitor abusive language is a crucial topic surrounding new media today. Despite branded content or sponsored content not being immediately obvious to the consumer, a video can also be deliberately edited to portray a subject in a more positive or negative light. The manipulative techniques used to compose these videos are part of why social media videos fall prey to fake news so often. The technical manipulation of short-form videos to spin a topic in order to sway someone to think about an issue in a certain fashion is regularly used in social media videos.  The phenomenon has a long history in the cinema. Sergei Eisenstein, a political filmmaker of the 1920s, for example, examined the manipulation technique whereby two factors collide and create conflict, producing a new concept. In the French film La Passion de Jeanne d’Arc (1928), the grotesque combination of shots of the aggression of the judges juxtaposed with Joan’s distressed teary face produce a synthesis of the audience feeling a sense of helplessness for Joan and her fate. Formalists like Eisenstein believed in being transparent about the editing techniques used to manipulate audiences’ Brand 9  attitudes toward certain ideas. Within the social media world, short shareable videos utilize this theory to contrast images and cast a negative or positive light on a subject.   Another film theorist, Jean-Louis Baudry, was primarily recognized for exploring Apparatus Theory, which states that reality is transformed during the production stage through an apparatus and the mechanical reproduction of the reality produce a representation of reality through diegetic absorption and a full development of a narrative. Filmmakers use this apparatus of production in order to use the dreamlike qualities of the cinema against audiences. Audiences play into these manipulations because of their desire and impulse to experience film as reality and in turn are exposed to coercion and deception masquerading as reality. Apparatus Theory is related to Plato’s “Allegory of a Cave” because the basic premise explains that individuals subconsciously take filmic representations for reality because they prefer it to reality and find escapism within the film’s world. Baudry explains how viewers can relate so easily to the film’s representation when he states, “The cinematographic apparatus is unique in that it offers the subject perceptions ‘of a reality’ whose status seems similar to that of representations experienced as perception” (Baudry, 220). This theory applies as much to the cinema as to the social media compilation videos traditionally endorsing a product or condemning an idea because the formalist technical properties of the video can align with a desired reality of the individual that may prompt the person to “share” the video to their followers.  Despite inaccurate or sponsored news being misleading and at times abusive, as Barnum’s traveling circus promotions show, fake news can be a good thing as it has the potential to keep consumers skeptical and can compel them to research the content that is spoon-fed to them. The issue of privacy rights and censorship is still a source of division amongst Internet users today. However, global consumers can all agree that Internet users serve as the checks and balances to a system that can become inevitably corrupt, so it is important for viewers of social media videos like the ones described below to Brand 10  be particularly self-aware of the spin that video producers put on their content and the technical manipulation that is active in the world of new media today.                                  Brand 11  Methodology I have edited two montages in response to Google’s Project Owl initiative. Each montage is two minutes in length and together they cover two radically different responses to Project Owl: one is positioned critically against the principles behind this move by Google, and one is clearly in support of the company’s project. I retrieved the source videos from various YouTube videos: some were pulled from a report aired on a major news network like MSNBC and other segments are pulled from independent podcast hosts and YouTube influencers. The methods used in piecing the montages together are similar to those used in the millions of short shareable videos shared on users’ Facebook pages each year, such as the videos from NowThis, Insider, and Buzzfeed. The sources of the videos and the way they are retrieved are rarely dissected before being used in the compilation videos that are circulated widely on digital platforms.  To test the effects of “spinning” each video on viewers’ perceptions of Project Owl, I developed a survey and designed a study to collect data from one-hundred people (see Appendix for survey materials). Of the one-hundred people surveyed, half were randomly assigned to watch video A and half were randomly assigned to watch video B. Each participant was asked to answer a set of questions before and after watching their assigned video. The survey was designed to provide data on their opinion of Project Owl before and after watching their assigned video. As discussed in the next section, I conducted an audience reception study of both videos to get a sense of how the video they viewed affected their perception of the topic. To gain a consistent respondent pool, I circulated the survey to exclusively Pace University students via class pages on Blackboard. My specific goal was to understand how elements of a video medium can influence or incite a viewer to action and to form strong opinions on a topic which they know nothing about.  The video assigned to Group A took an anti-Project Owl perspective and spun the issue as an attack on free speech because of the heavy censorship used in the initiative. One example used in the Brand 12  video covered how Google stopped redirecting search queries to World Socialist Web site, thereby controlling what they deem to be “fake news” but instead censoring anti-war and progressive ideals. Another critique of Project Owl that the video covered concerns the blocked advertisements on LGBTQ videos and the taking down of these videos in “Restricted mode” on Youtube, another one of Google’s assets. Google was portrayed as trying to not be soft on hate speech just to keep advertisers appearing on non-offensive content and to therefore retain their funds from advertisers. The privacy of the company was portrayed in a negative light by covering Google’s tightly guarded mathematical equations that rank sites. The visuals I used in the criticism of Project Owl would include images of men in suits and the CEO of Google, big money deals and handshakes exchanged between companies, LGBTQ suppression with clips from YouTuber videos about “Restricted mode”, such as from Tyler Oakley and Rowan Ellis, and a generally negative conspiracy-filled perspective on the initiative.  The video assigned to Group B offered a positive perspective on Project Owl and reflected how Google is using this initiative to fight the spread of misleading, offensive, or false information. This looked more specifically at the features of the project, including the user feedback mechanisms and complaints platform with the project. The video also explained what Project Owl is responding to, which includes the fact that a Holocaust denial was the first Google search result when “Did the Holocaust happen” was googled back in December 2016, in addition to the false news of Barack Obama planning a coup occurring high in search results within the same year. Video B explained Google’s lack of transparency by stating that Google can’t reveal too much about its algorithms or companies would use the algorithms to try and game the search placement. The montage would emphasize Project Owl as trying to not be soft on hate speech in order to give more accurate and efficient results. The video representation of the fight against fake or abusive news would include images like the Charlottesville Brand 13  White Supremacy protest, records of how Google filtered out white supremacist websites, positive general protests for change visuals, google advertisements, and the official press release of Project Owl.                                            Brand 14  Results:  The vast majority of the respondents (87%) have not heard about Google’s algorithm Project Owl. According to Graph I, 56% more of the Video B viewers agreed that Project Owl is contributing positively to society than Video A viewers. 25% of the respondents that watched video A (Conspiracy) agreed or somewhat agreed that Project Owl is contributing to society in a positive way, while 81% of the respondents that watched video B (Corporate) agreed or somewhat agreed that Project Owl is contributing to society in a positive way. The vast majority (62%) of the respondents that watched Video A (Conspiracy) agreed that Project Owl violates our freedom of speech while only 28% of the respondents that watched Video B (Corporate) agreed that Project Owl violates our freedom of speech (Graph II). 38% of the Video A respondents agreed or strongly agreed that Project Owl protects internet users from false or abusive content, whereas as much as 70% of Video B viewers agreed that Project Owl protects internet users from false or abusive content (Graph III).  The respondents that watched video B (Corporate) were more decisive in their support for Project Owl when compared to video A watchers’ opposing views towards Project Owl. In fact, as demonstrated by Pie Chart I, video A watchers were almost twice as likely to respond “agree” or “somewhat agree” to the statement “Social media companies like Google, Twitter, and Facebook should be more vigilant in regulating language posted on the websites” after watching video B. Video A respondents showed little to no change in the likelihood of agreeing or disagreeing with the same statement after watching Video A. While the distribution of those in favor of government regulation of internet language was equal for Video A and B respondents, the distribution in support of Project Owl’s regulation of internet language was radically different for Video B viewers when compared to Video A viewers (Pie Chart II). The percentage increase for Video B viewers in support of language regulations between the before and Brand 15  after statements was 30%, whereas the percentage increase for those that watched Video A was a 4% increase between the two statements. Therefore, respondents who saw Video B were more likely to be in favor of internet language regulation (through Project Owl and not the government) than Video A viewers.  Despite both videos being engineered as pieces of fake news and being skewed extremely heavily towards one side, 81% of respondents agreed or somewhat agreed that the video explained Project Owl clearly (Pie Chart III).                  Brand 16  Discussion and Future Directions Despite 87% of those surveyed having never heard of Project Owl before taking the survey, the respondents formed a solid decisive opinion about the Project Owl initiative after watching their assigned randomized video.  The type of video shown to the respondent heavily affected the respondent’s perspective. Their responses to the post-video questions were heavily divided, with as much as a 56% difference between the A and B groups that agreed Project Owl is contributing to society in a positive way. Rarely does a one-time showing of a video medium lasting less than two minutes instill a new opinion in an individual. Therefore, the video shown appears to reaffirm and reinforce preconceived beliefs. I constructed each video to fit into two neat categories: monitoring abusive and hateful language is a noble act for the bettering of society, or corporations are oppressive and censor the individual’s freedom of speech. By choosing the clips, music, pacing, and tone to best reflect the respective category, bias was activated within the individual. Starting out, I expected the more unconventionally edited grass roots-style of Video A to perform well because the compilation has quicker cuts and forms a stronger overall message with the ominous music and clearly distraught YouTubers. However, based on the results in Pie Chart I, Video A has a similar effect as propaganda. Perhaps, the conspiracy message was too direct and radical for the viewer to digest and did not perform what it was intended to do: call the audience to action. In the end, it seems that various YouTubers passionately condemning the algorithm and darkly lit images of corporate meetings could not get rid of positivity the audience held towards the thought of Google, a common tool the majority of respondents successfully use 5-9 times a day. Video B viewers were more decisive about the idea of regulating Internet language than Video A viewers were against regulating Internet language. This might be because Video B chooses instead to Brand 17  reinforce a belief rather than attempt to change the viewers’ opinion. Video B consistently played it safe by having smoother transitions and fewer clips in the compilation; it also included voices that were more confident and far less emotional. The narrative structure may also have been a major factor in the success of Video B. By describing the algorithm with key points and offering the initiative as a resolution to a problem, the audience receives the information from Video B in digestible bites. Video B’s editing follows the order of a problem-resolution or a cause-and-effect structure, whereas Video A presents the problems first, does not pose any kind of solution, and the clips are arranged based on the level of troubling stakes within each clip and are in ascending order of anxiety-inducing implications. While the data provided significant insight on the level at which a piece of bias content can solidify an opinion, this research could be taken in another direction by conducting a follow-up study based on the artistic and technical form of the medium. By circulating the same video but instead focusing on asking questions in the post-video section about the pacing of cuts or how an image or narrative made the audience feel, one could gather data on what specifically the audience connects with to pinpoint what makes a powerful influential piece of “fake news”. However, this could make the audience biased in the analysis of their own subconscious and mistrustful attitudes towards the video they view. It is possible, moreover, that, given the limited time users are willing to devote to consuming these sorts of videos, lengthening the survey with another set of questions to acquire data on this might result in fewer respondents. Overall, the results of the present study have demonstrated how daily news is collapsing into a successful marketing tool. By creating two of my own pieces of successful fake news, I learned that in today’s fragile media landscape, content is easily spun with an ulterior motive, whether that is to promote a brand or make a profit. Just as President Trump takes facts or non-facts to wield news Brand 18  politically, marketers can weave narratives through short shareable content to achieve a goal and solidify even unconscious beliefs in consumerist-based facets of society.                       Brand 19  Works Cited  Braudy, Leo, and Marshall Cohen. Film theory and criticism: introductory readings. Oxford University Press, 1999.  Damon, Andre. “World Socialist Web Site.” Google intensifies censorship of left-Wing websites, World Socialist Web Site wsws.Org. Published by the International Committee of the Fourth International (ICFI), 19 Sept. 2017, www.wsws.org/en/articles/2017/09/19/goog-s19.html.  Eisenstein, Sergei, and Jay Leyda. Film form; essays in film theory. Harcourt, Brace, 1949.   Harris, Neil, and Joel Hoffman. Humbug: the Art of P.T. Barnum. University of Chicago Press, 1981.  Hill, Charles A., and Marguerite Helmers. Defining Visual Rhetorics. Taylor and Francis, 2012.  Holiday, Ryan. Trust me, I’m lying: confessions of a media manipulator. Portfolio/Penguin, 2013.  Internet abuses and privacy rights. Grey House Publishing, 2017.  Jansen, Sue Curry. Censorship: the knot that binds power and knowledge. Oxford University Press, 1988.  Kang, Cecilia, et al. “Mark Zuckerberg Testimony: Day 2 Brings Tougher Questioning.” The New York Times, The New York Times, 11 Apr. 2018, www.nytimes.com/2018/04/11/us/politics/zuckerberg-facebook-cambridge-analytica.html  Liffreing, Ilyse. “Fake news, guerrilla postings and PR: How Ringling Bros. and Barnum & Bailey Circus helped invent advertising.” Campaign US, www.campaignlive.com/article/fake-news-guerrilla-postings-pr-ringling-bros-barnum-bailey-circus-helped-invent-advertising/1421636.  “Mass Media | Two Step Flow Theory.” Universiteit Twente, www.utwente.nl/en/bms/communication-theories/sorted-by-cluster/Mass%20Media/Two_Step_Flow_Theory-1/.  Roleff, Tamara L. Censorship: opposing viewpoints. Greenhaven Press, 2002.  Seife, Charles. Virtual unreality: just because the Internet told you, how do you know its true? Viking, 2014.  Staiger, Janet. “Social Scientific Theories” Media Reception Studies. Sullivan, Danny. “Google’s ‘Project Owl’ – a Three-Pronged Attack on Fake News & Problematic Content.” Search Engine Land, 27 Apr. 2017, searchengineland.com/googles-project-owl-attack-fake-news-273700  Brand 20  Appendix Pace University, New York CONSENT TO ACT AS A HUMAN RESEARCH SUBJECT Fake News and Project Owl  RESEARCH TEAM Lead Researcher Alexandra Brand Film and Screen Studies Telephone number: (347)762-0335 E-mail address: ab66735n@pace.edu   Faculty Sponsor Colin Williamson Film and Screen Studies E-mail address: cwilliamson@pace.edu    You are invited to participate in this research study on online survey platform Qualtrics. Participation is completely voluntary.  Please read the information below and ask questions about anything that you do not understand.  A researcher listed below will be available to answer your questions.  Introduction and Purpose My name is Alexandra Brand.  I am an undergraduate student at Pace University working with my faculty adviser, Professor Colin Williamson in the Film and Screen Studies Department. I would like to invite you to take part in my research study for my Pace University Honors Senior Thesis project, which concerns Google’s filtering algorithm called Project Owl. Procedures If you agree to participate in my research, you can complete this online survey. The survey is in three parts: the first part will involve questions about regulating language on social media, the second part will require you to watch a two-minute long video, and the third part will ask you to answer questions about the video you watched. The survey should take about 5 minutes total to complete. Benefits You will be entered to win a $25 Dunkin Donuts gift card. Also, it is hoped that the research will give Internet users more information about the filtration of fake news.  Risks/Discomforts Brand 21  There are minimal risks. However, you are free to decline to answer any questions you don't wish to, or to stop participating at any time. As with all research, there is a chance that confidentiality could be compromised; however, we are taking precautions to minimize this risk. Confidentiality Your study data will be handled as confidentially as possible. If results of this study are published or presented, individual names and other personally identifiable information will not be used. To minimize the risks to confidentiality, we will limit access to study records to the primary researcher and the faculty sponsor. The data I collect will be de-identified to protect confidentiality and privacy. Subjects will not be allowed to enter their identifying information anywhere. When the research is completed, I may save the data for use in future research done by myself or others.  I will retain these records for up to 2 years after the study is over. The same measures described above will be taken to protect confidentiality of this study data. Compensation You will be entered to win a $25 Dunkin Donuts gift card. Rights Participation in research is completely voluntary.  You are free to decline to take part in the project.  You can decline to answer any questions and are free to stop taking part in the project at any time.  Whether or not you choose to participate, to answer any particular question, or continue participating in the project, there will be no penalty to you or loss of benefits to which you are otherwise entitled. Questions If you have any questions about this research, please feel free to contact me.  I can be reached at (347)762-0335 orab66735n@pace.edu. If you have any questions about your rights or treatment as a research participant in this study, please contact Office of Sponsored Research by phone, (212) 346-1153, by e-mail at paceirb@pace.edu. You should not complete this consent form until all of your questions about this study have been answered by a member of the research team listed at the top of this form. Participation in this study is voluntary.  You may refuse to answer any question or discontinue your involvement at any time without penalty or loss of benefits to which you might otherwise be entitled.   If you agree to take part in the research, please print a copy of this page to keep for future reference, then click on the “Accept” button below. Clicking on the “Agree” button indicates that            You have read the above information          You voluntarily agree to participate  Brand 22  Links to the videos used with the surveys: Video A:  https://bit.ly/2qFgRfw Video B: https://bit.ly/2JVVU8n   Survey Questions: PRE-VIDEO QUESTIONS What is your age? ______________ How do you identify in terms of race? a. American Indian or Alaska Native b. Asian c. Black or African American d. Native Hawaiian or Other Pacific Islander e. White f. Other: ______________  How do you identify in terms of gender? a. Female b. Male c. Self-Identify:___________  What is your occupational status? (select all that apply)  a. Employed full-time b. Employed part-time c. Homemaker/at-home parent/ on maternity leave d. Student e. Unemployed/in-between job  Rate how frequently you use the search engine Google:  a. Never b. Once a week Brand 23  c. 1-4 times a day d. 5-9 times a day e. 10+ times a day  Rate your agreement with the following statement: “Social media companies like Google, Twitter, and Facebook should regulate language posted on their websites.” a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree e. Strongly agree  Rate your agreement with the following statement: “The government should be able to prevent people publicly making statements that are offensive to minority groups.” a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree e. Strongly agree  Have you heard of the Project Owl initiative? a. Yes, and I am familiar with details about it. b. Yes, but I am not familiar with details about it. c. No, I have not heard of it.   POST-VIDEO QUESTIONS The video you watched explained Project Owl clearly.  a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree e. Strongly agree  Rate your agreement with the following statement: “The Project Owl initiative is contributing to society in a positive way.” a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree Brand 24  e. Strongly agree  Rate your agreement with the following statement: “Project Owl violates our freedom of speech.” a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree e. Strongly agree  Rate your agreement with the following statement: “Project Owl protects internet users from false or abusive content.” a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree e. Strongly agree  Rate your agreement with the following statement: “Social media companies like Google, Twitter, and Facebook should be more vigilant in regulating language posted on the websites.” a. Strongly disagree b. Somewhat disagree c. Neither agree nor disagree d. Somewhat agree e. Strongly agree  Do you expect more internet regulations to be enacted following the Project Owl initiative? a. Yes b. No c. Maybe      Brand 25  List of Figures and Tables I have used the terms “Corporate” and “Conspiracy” to label video A and video B in order to differentiate the videos based on the themes within each respective video.  Pie Chart IX. Have you heard of the Project Owl initiative?             Yes, and I am familiar with details about itYes, but I am not familiar with details about itNo, I have not heard about itBrand 26  Graph I. Rate your agreement with the following statement: “The Project Owl initiative is contributing to society in a positive way.”     Graph II. Rate your agreement with the following statement: “Project Owl violates our freedom of speech.”    0 5 10 15 20 25 30 35 40Video A (Conspiracy)Video B (Corporate)Graph I.Total Agree or Strongly Agree Total Disagree or Strongly Disagree0 5 10 15 20 25 30 35Video A (Conspiracy)Video B (Corporate)Graph II.Total Agree or Strongly Agree Total Disagree or Strongly DisagreeBrand 27  Graph III. Rate your agreement with the following statement: “Project Owl protects internet users from false or abusive content.”    Pie Chart I. Before Question: “Social media companies like Google, Twitter, and Facebook should regulate language posted on their websites.” After Question: “Rate your agreement with the following statement: “Social media companies like Google, Twitter, and Facebook should be more vigilant in regulating language posted on the websites.”                      0 5 10 15 20 25 30 35Video A (Conspiracy)Video B (Corporate)Graph III.Total Agree or Strongly Agree Total Disagree or Strongly DisagreeBrand 28  Video A (Conspiracy):  BEFORE                                          AFTER    Percentage increase of respondents’ agreement with language regulation: 0% increase  Video B (Corporate):         BEFORE                                        AFTER    Percentage increase of respondents’ agreement with language regulation: 50% increase  Strongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeStrongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeStrongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeStrongly DisagreeSomewhat DisagreeNeither Agree nor DisagreeSomewhat AgreeStrongly AgreeBrand 29  Pie Chart II. Before statement: Rate your agreement with the following statement: “The government should be able to prevent people publicly making statements that are offensive to minority groups.” After statement: Rate your agreement with the following statement: “Project Owl protects internet users from false or abusive content.” For Video A:                                   BEFORE                                         AFTER    For Video B:          BEFORE                                         AFTER     Strongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeStrongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeStrongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeStrongly disagreeSomewhat DisagreeNeither agree nor disagreeSomewhat AgreeStrongly agreeBrand 30  Pie Chart III. Rate your agreement with the following statement: “The video you watched explained Project Owl clearly.”       Strongly disagree Somewhat disagreeNeither agree nor disagree Somewhat agreeStrongly agree",
    "id": 212892541,
    "identifiers": {
        "doi": null,
        "oai": "oai:digitalcommons.pace.edu:honorscollege_theses-1173"
    },
    "title": "Fake News and Editing: Marketing Techniques used to Spin Controversies in Video Mediums",
    "language": {
        "code": "en",
        "name": "English"
    },
    "publishedDate": "2018-07-01T08:00:00+01:00",
    "publisher": "DigitalCommons@Pace",
    "references": [],
    "sourceFulltextUrls": [
        "https://digitalcommons.pace.edu/cgi/viewcontent.cgi?article=1173&amp;context=honorscollege_theses"
    ],
    "updatedDate": "",
    "yearPublished": "2018",
    "links": [
        {
            "type": "download",
            "url": "https://core.ac.uk/download/212892541.pdf"
        },
        {
            "type": "reader",
            "url": "https://core.ac.uk/reader/212892541"
        },
        {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/212892541/medium"
        },
        {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/212892541/large"
        },
        {
            "type": "display",
            "url": "https://core.ac.uk/outputs/212892541"
        }
    ],
    "abstract": "This thesis explores the topic of fake news in today\\u27s digital landscape by analyzing how young adults (18-2) form and change prior opinions based on the media they consume. I measured this by showing respondents one of two bias montages in response to Google\\u27s Project Owl initiative. Project Owl is Google\\u27s controversial attempt to regulate false or abusive news by launching new feedback forms in addition to altering their algorithm in a way the company has not yet disclosed to the public (Sullivan). Each self-edited montage is two minutes in length and together they cover two radically different responses to Project Owl: one is positioned critically against the principles behind this move by Google, and one is clearly in support of the company\\u27s project.\nTo test the effects of  spinning  each video to change viewers\\u27 perception of Project Owl, I developed a survey and designed a study to collect data from one-hundred people. Of the hundred people surveyed, half were randomly assigned to watch video A and half were randomly assigned to watch video B. Each participant was asked to answer a set of questions before and after watching their assigned video. The survey was designed to provide data on how their responses to Project Owl change after watching their assigned video. By using surveys that target the effects on audiences of informative video compilations that spin Project Owl, the thesis shows the manipulation of editing and short-form informational social media videos have on society more broadly.\nThe intricate project is especially relevant because, while President Donald Trump regularly reprimands the promotion of   fake news  through Twitter, left-wing activists argue that false information spread across the Internet contributed to the outcome of the 2016 election. These arguments from opposing sides are intensified in the 21st century age of New Media and information overload, a period in media history when the fact that the production and circulation of  news  can come from anyone, anywhere, and at any time means that the difficulty of assessing the authenticity and reliability of that information is increasing exponentially",
    "tags": [
        "text",
        "editing",
        "fake news",
        "marketing",
        "Communication",
        "Communication Technology and New Media",
        "Journalism Studies",
        "Mass Communication",
        "Social Influence and Political Communication",
        "Social Media"
    ],
    "fulltextStatus": "enabled",
    "subjects": [
        "text"
    ],
    "oai": "oai:digitalcommons.pace.edu:honorscollege_theses-1173",
    "deleted": "ALLOWED",
    "disabled": false,
    "journals": null,
    "repositories": {
        "id": "1323",
        "openDoarId": 0,
        "name": "DigitalCommons@Pace",
        "urlHomepage": null,
        "uriJournals": null,
        "physicalName": "noname",
        "roarId": 0,
        "baseId": 0,
        "pdfStatus": null,
        "nrUpdates": 0,
        "lastUpdateTime": null
    },
    "repositoryDocument": {
        "id": 212892541,
        "depositedDate": null,
        "publishedDate": "2018-07-01T08:00:00+01:00",
        "updatedDate": "2024-01-23T23:53:28+00:00",
        "acceptedDate": null,
        "createdDate": "2019-07-09T10:53:57+01:00"
    },
    "urls": [
        "https://digitalcommons.pace.edu/honorscollege_theses/166",
        "https://digitalcommons.pace.edu/context/honorscollege_theses/article/1173/viewcontent/Alexandra_Brand_FinalThesis_Draft_04182018_withAppendix.pdf"
    ],
    "lastUpdate": "2024-01-23T23:53:28+00:00",
    "setSpecs": []
}