{
    "acceptedDate": "",
    "authors": [
        {
            "name": "McNair, Ben J."
        },
        {
            "name": "Bennett, Jeffrey W."
        },
        {
            "name": "Hensher, David A."
        }
    ],
    "contributors": [],
    "createdDate": "2012-07-06T03:45:13+01:00",
    "dataProvider": {
        "id": 153,
        "name": "Research Papers in Economics",
        "url": "https://api.core.ac.uk/v3/data-providers/153",
        "logo": "https://api.core.ac.uk/data-providers/153/logo"
    },
    "depositedDate": "",
    "documentType": "research",
    "doi": "",
    "downloadUrl": "https://core.ac.uk/download/pdf/6407572.pdf",
    "fullText": "Strategic response to a sequence of discrete choice questions \n \nBen McNair\n1, Jeff Bennett\n2 and David A. Hensher\n3 \n \nPaper presented at the 54\nth Annual Conference of the Australian Agricultural and \nResource Economics Society, Adelaide, South Australia, 10-12 February 2010 \n \nAbstract        According  to  neoclassical  economic  theory,  the  only  stated  preference \nelicitation format that can feasibly be employed in field studies to which truthful response \ncan be the dominant strategy for all respondents is a single binary choice between the \nstatus quo and one alternative. In studies where the objective is estimation of preferences \nfor multiple attributes of a good, it is preferred (and, in some cases, necessary) based on \neconometric  considerations,  to  present  respondents  with  a  sequence  of  choice  tasks. \nEconomic  theory  predicts  that  utility-maximising  respondents  may  find  it  optimal  to \nmisrepresent their preferences in this elicitation format. In this paper, the effect on stated \npreferences of expanding the number of choice tasks per respondent from one to four is \ntested  using  a  split  sample  treatment  in  an  attribute-based  survey  relating  to  the \nundergrounding of overhead electricity and telecommunications wires in the Australian \nCapital Territory. We find evidence to suggest that presenting multiple choice tasks per \nrespondent decreases estimates of total willingness to pay and that this effect is related to \nthe ordering of cost levels presented over the sequence of choice tasks. Two behavioural \nexplanations  can  be  advanced  -  a  weak  cost  minimisation  strategy,  which  implies \ndivergence between stated and true preferences, and a ‘good deal / bad deal’ heuristic, in \nwhich  stated  preferences  reflect  true  preferences  that  change  over  the  course  of  the \nsequence of choice tasks. Preferences stated in the first of a sequence of choice tasks are \nnot significantly different from those stated in  the incentive  compatible single binary \nchoice task. A key objective of future research will be to establish whether this effect \nbecomes less prevalent as the number of attributes and alternatives per choice task are \nincreased. \n \nKeywords    Choice experiments, willingness to pay, incentive compatibility, strategic \nbehaviour, order effects, underground electricity \n                                                           \n1 (presenting author) Crawford School of Economics and Government, The Australian National University, \nCanberra ACT 0200, Australia. Email address: ben.mcnair@anu.edu.au \n2 Crawford School of Economics and Government, The Australian National University, Canberra ACT \n0200, Australia. \n3  Institute  of  Transport  and  Logistics  Studies,  Faculty  of  Economics  and  Business,  The  University  of \nSydney, NSW 2006, Australia. 2    B. McNair, J. Bennett, D. A. Hensher \n \n1. Introduction \nAny attempt to achieve the social welfare maximising level of electricity network service \nquality relies upon estimates of the social valuation of changes in service quality. In the \ncase of public provision, this social valuation forms one half of the classic Samuelson \n(1956) condition for optimal provision of a public good. In the case of private monopoly \nprovision, this social valuation is used by the regulator to set quality incentive rates, \nwhich can result in the optimal social welfare outcome when applied as part of a quality-\nadjusted price cap with yardstick competition over both cost and quality (which is the \nculmination of theory developed by Spence (1975), Loeb and Magat (1979), Baron and \nMyerson (1982) and Shleifer (1985) among others). The literature on optimal private \nmonopoly  provision  (termed  ‘the  new  regulatory  economics’  by  Laffont  and  Tirole \n(1993)) is based on the use of mechanism design techniques (Green and Laffont 1979) to \nanalyse regulation as a  principal-agent problem where firms have private information \nabout costs. Less attention has been paid in the regulatory economics literature to the fact \nthat consumers have private information about their preferences and to the difficulties \nintroduced by the need to elicit those preferences in order to estimate the social valuation \nof  service  quality.  Regulators  and  firms  are  increasingly  employing  stated  preference \nsurveys to gather detailed information on consumers’ preferences with respect to service \nquality (for example KPMG (2003) and Accent (2008, 2003)). The theory of mechanism \ndesign (Mirrlees (1971) and Hurwicz (1972)), which has been used extensively to analyse \ninteractions between firms and regulators, can also be used to analyse whether utility-\nmaximising  consumers  may  find  it  optimal  to  misrepresent  their  preferences  in  such \nsurveys.  \nIdeally, regulators would implement survey mechanisms in which truthful response is the \ndominant strategy for all respondents. That is, truthful response is the utility-maximising \nresponse for all respondents regardless of their beliefs about others’ responses. Such a \nsurvey mechanism is said to be incentive compatible. It has long been recognised that a \nsurvey mechanism can be incentive compatible if its elicitation format is in the form of a Strategic response to a sequence of discrete choice questions  3 \n \nsingle binary (SB) choice between the status quo and an alternative (Farquharson 1969).\n4 \nA  format  comprising  repeated  binary  choices  between  the  status  quo  and  various \nalternatives can only be incentive compatible where the social choice function is based on \na single randomly selected choice task from the sequence (Carson and Groves 2007). \nThis  ‘random  selection’  social  choice  function  may  be  possible  in  a  laboratory \nenvironment (Boyle et al. 2004), but in field surveys respondents are unlikely to believe \nthat  the  agency  would  discard  the  majority  of  the  data  that  they  expended  resources \ncollecting.  Our  maintained  assumption  is  that  this  is  the  case  and  therefore  the  SB \nelicitation format is the only format that can be incentive compatible in field surveys.  \nThe SB format has successfully been employed where the price of the alternative varies \nacross respondents, but the good is fixed. This is the form of contingent valuation (CV) \nsurvey recommended by the NOAA panel in 1993 (Arrow et al. 1993). However, there \nare a number of difficulties associated with employing the SB format when the good in \nthe alternative varies across respondents. This is the form required to elicit preferences \nfor multiple attributes, which is often the regulator’s objective (for instance to estimate \npreferences for the frequency, duration, advance warning and time of day of electricity \nsupply interruptions). Estimates of willingness to pay from SB data are less statistically \nsignificant than those from repeated choice data because of the absence of opportunities \nfor institutional learning (Braga and Starmer 2005) as well as the much lower number of \nchoice  observations.  Some  evidence  suggests  that  it  may  not  be  possible  to  estimate \nindividual-specific  taste  intensities  or  the  heterogeneity  in  taste  intensities  across  a \npopulation  using  SB  data.\n5  For  these  reasons,  formats  used  to  elicit  preferences  for \nmultiple attributes have tended to involve the presentation of multiple choice tasks per \nrespondent– and in doing so, lose the property of incentive compatibility.  \n                                                           \n4 A necessary condition is that the agency can credibly claim to be able to force any of the alternatives on \nany given respondent. However, it is not necessary for the SB choice survey to be binding (Carson et al. \n1997) or a full public vote (Green and Laffont 1978). \n5 Estimating random parameters on the single binary choice data is problematic because the models may be \nunable to disentangle the Gumbel error distribution and the random parameter distributions. Rose et al \n(2009)  found  random  parameter  estimates  statistically  insignificant  where  data  were  a  single  choice \nobservation per respondent in their study of the impact of the number of choice tasks per respondent. 4    B. McNair, J. Bennett, D. A. Hensher \n \nThis  paper  uses  a  split  sample  treatment  of  elicitation  format  in  a  web-based  survey \nrelating to the undergrounding of overhead electricity and telecommunications wires in \nthe Australian Capital Territory to assess the effect on stated preferences of presenting \nmultiple  choice  tasks  per  respondent.  The  elicitation  formats  employed  in  the  survey \ninclude a SB choice task and a sequence of four binary choice tasks (RB).\n6 The objectives \nof this paper are to use the data from these two elicitation formats to test: \na)  whether  stated  preferences  are  affected  by  presenting  four  as  opposed  to  one \nattribute-based choice task per respondent; and, \nb)  whether  stated  preferences  in  the  first  choice  task  presented  are  affected  by \nadvance knowledge that four as opposed to one choice tasks will be presented.  \nWhere stated preferences are affected by elicitation format we would also like to identify \nthe response strategies or other effects underlying the difference. \nThe paper is organised as follows. Section 2 discusses the effects of elicitation format on \nstated preferences identified in the literature both in theory and empirically. Section 3 sets \nout the design of the survey mechanism used in this study and the econometric modelling \napproaches used to analyse the data. The results of the analysis are set out in Section 4 \nand Section 5 concludes.  \n \n2. Elicitation format and stated preferences \nThere are a number of possible behavioural explanations for differences in preferences \nstated in a SB choice and a sequence of binary choices. One such explanation is that \nrespondents employ a ‘cost minimisation strategy’ as predicted by neoclassical economic \ntheory. It has long been recognised that consumers may conceal their true preferences if it \nenables  them  to  obtain  a  public  good  at  a  lower  cost  (Samuelson  1954).  In  choice \nexperiments,  this  strategy  is  generally  thought  to  be  manifest  by  the  rejection  of  an \n                                                           \n6 The survey also employed a sequence of four choice tasks containing two alternatives to the status quo \n(RMN). Data from this format are not analysed in this paper. Strategic response to a sequence of discrete choice questions  5 \n \nalternative that is preferred to the status quo when a similar good was offered at a lower \ncost in a previous choice task. In doing so, respondents increase the likelihood that their \nmost preferred option across the sequence of choice tasks is implemented. Bateman et al. \n(2008) differentiate between a ‘strong’ case, in which respondents always reject a good if \nit was offered at a lower cost in a previous choice task, and a ‘weak’ case, in which \nrespondents  weigh  up  this  rejection  against  the  perceived  risk  of  the  good  not  being \nprovided at the lower cost. These strategies imply that preferences stated in a sequence of \nchoice tasks may diverge from true underlying preferences. \nAnother  explanation  for  divergence  between  preferences  stated  in  SB  and  sequential \nchoice formats is that respondents discover their preferences as they progress through a \nsequence of choice tasks (Plott 1996). Bateman et al. (2008) describe a ‘good deal / bad \ndeal’ heuristic in which respondents revise their preferences on the basis of the cost levels \npresented as they progress through the sequence of choice tasks. An alternative is more \n(less) likely to be chosen if its price level is low (high) relative to the levels presented in \nprevious choice tasks. This heuristic could arise where respondents take the average of \ncost levels presented in the sequence to that point as a signal for the quality of the good. \nThe  key  difference  between  this  and  the  cost  minimisation  strategies  is  that  the  cost \nminimisation strategies assume respondents hold constant, well-formed preferences. The \noffering  of  a  high-cost  alternative  would  increase  the  likelihood  of  acceptance  in \nsubsequent choice tasks under the ‘good deal / bad deal’ heuristic, but not under the \nstrong cost minimisation strategy.\n7 According to the ‘value learning’ and ‘good deal / bad \ndeal’  heuristic  explanations,  preferences  stated  in  a  sequence  of  choice  tasks  do  not \ndiverge from true underlying preferences. \nA  potential  consequence  of  presenting  a  sequence  of  choice  tasks  containing  similar \ngoods with large variations in cost levels is that respondents may find some alternatives \n                                                           \n7 In the weak cost minimisation strategy the perceived risk of the good not being provided depends upon \nthe  cost  levels  in  the  chosen  alternatives  in  the  sequence  to  that  point.  The  offering  of  a  high-cost \nalternative that is rejected would result in a higher likelihood of acceptance in subsequent choice tasks than \nthe offering of a lower-cost alternative if that alternative is accepted and has the highest cost level of all \nalternatives chosen in the sequence to that point.  6    B. McNair, J. Bennett, D. A. Hensher \n \nimplausible  and  answer the  question  as  though  cost  were  at  a  level  considered  more \nrealistic  by  the  respondent.  Bateman  et  al.  (2008)  refer  to  this  as  a  cost  averaging \nstrategy. Under such a strategy we would expect alternatives with cost levels from the \nlow  (high)  end  of  the  range  observed  by  the  respondent  to  be  accepted  less  (more) \nfrequently than in a truthful response. This strategy implies that preferences stated in a \nsequence  of  choice  tasks  diverge  from  the  true  underlying  preference  for  the  levels \nactually set out in the choice tasks. \nPresenting a sequence of choice tasks also affords respondents with opportunities to learn \nand become more familiar with the choice task format. Braga and Starmer (2005) refer to \nthis as an institutional learning process in which responses become more accurate as the \nsequence progresses. This learning process is thought to have the effect of decreasing the \nvariance of the random error component in choice models (or equivalently increasing \nscale) (Holmes and Boyle 2005). There is also evidence to suggest that respondents may \nbecome fatigued and respond less accurately once they proceed beyond a certain point in \na survey (Bradley and Daly 1994, Caussade et al. 2005). Fatigue is thought to have the \neffect of increasing error variance (or equivalently, decreasing scale). \nSeveral studies have tested the effects of expanding the SB format in the fixed good (CV) \ncontext.  Recognising  the  large  sample  sizes  required  for  statistically  significant \nestimation  when  using  the  SB  choice  format,  some  CV  surveys  have  incorporated  a \nsecond (or follow-up) question in the elicitation format. A number of studies have found \ndifferences in the WTP implied by the first and second questions in this double-bounded \nCV format (Cameron and Quiggan 1994, Hanemann et al. 1991, McFadden and Leonard \n1995). Herriges and Shogren (1996) interpret this difference as starting point bias. Carson \net al. (2008) relate the difference to strategic response by showing that responses to the \nfirst and second questions are equivalent in the presence of a social choice function in \nwhich the outcome of the second question cancels out and replaces the outcome of the \nfirst question. Strategic response to a sequence of discrete choice questions  7 \n \nThe attribute-based choice experiment format has not been subject to the same degree of \ntesting  for  strategic  response  as  the  CV  format.\n8  Some  studies  have  compared  stated \npreferences from fixed-good (CV) SB and attribute-based repeated binary formats. For \nexample Cameron et al. (2002) were unable to reject the hypothesis of identical indirect \nutility-difference  functions across these  elicitation formats. A number  of studies have \nexamined  the  implications  of  presenting  multiple  attribute-based  choice  tasks  per \nrespondent  without  employing  an  incentive  compatible  SB  comparator.  Carlsson  and \nMartinsson (2006) found no evidence of starting point bias in their split sample treatment \nof inclusion of a ‘good deal’ alternative (one with a large improvement in the good at a \nlow cost) in the first choice task of a sequence. Bateman et al. (2008) found evidence of a \nweak cost minimisation strategy using a split sample treatment of advance knowledge of \nattribute  levels  in  a  sequence  of  choice  tasks.  They  used  the  first  choice  task  in  a \nsequence  as  an  incentive  compatible  comparator  where  respondents  had  not  been \ninformed that they would be presented with multiple choice tasks. This relies on the \nassumption that respondents assumed with certainty that the first choice task would be the \nonly choice task presented. If respondents had any uncertainty as to whether this would \nbe the case, then the necessary ‘take it or leave it’ property of the incentive compatible \nSB choice is violated.  \nNone  of  the  field  studies  discussed  above  make  spilt-sample  comparisons  between \npreferences  stated  in  a  sequence  of  choice  tasks  and  those  stated  in  an  incentive \ncompatible attribute-based SB choice task. We have found only two such studies. The \n                                                           \n8 A number of studies have focussed on hypothetical bias by comparing results from hypothetical choice \nexperiments with those from choice experiments with immediate and certain implementation (Alfnes and \nSteine 2005, Carlsson and Martinsson 2001, Hensher 2009, Lusk and Schroeder 2004). Carson and Groves \n(2007) distinguish between inconsequential hypothetical surveys (where a respondent believes there is 0 \nper cent chance of implementation) and consequential hypothetical surveys (where a respondent believes \ntheir  responses  will  influence  up  to  some  non-zero  probability  the  likelihood  of  an  alternative  being \nimplemented  by  the  agency).  The  same  conditions  for  incentive  compatibility  apply  to  the  survey \nmechanism regardless of whether it is a consequential hypothetical survey or a survey with immediate and \ncertain implementation. If the survey is inconsequential, then neoclassical economic theory cannot be used \nto predict responses. Consistent with this theory, Carson et al. (2006) found a difference between responses \nto  inconsequential  hypothetical  questions  and  questions  involving  100  per  cent  probability  of  actual \npayment, but, importantly, found equivalence in responses to all questions involving a non-zero (20 per \ncent, 50 per cent, 80 per cent and 100 per cent) probability of actual payment. 8    B. McNair, J. Bennett, D. A. Hensher \n \nfirst  is  a  study  by  Racevskis  and  Lupi  (2008),  which  found  a  significant  difference \nbetween models fitted to data collected from single and repeated binary attribute-based \nchoice tasks. The second is a study by Scheufele and Bennett (2010a), which is being \nconducted concurrently with this study. This paper adds to this small, but growing, body \nof research. It builds on previous research by modelling the response strategies employed \nby respondents when presented with a sequence of choice tasks. Bateman et al. (2008) \npresent models that allow cost sensitivity to change over the course of a sequence of \nchoice tasks by including in their random parameter logit models an interaction between \nquestion order and cost. In this paper, we present a more flexible model of the effect of \nquestion order on cost sensitivity and develop new models that allow cost sensitivity to \nchange  according  to  the  positioning  of  the  cost  level  relative  to  levels  presented  in \nprevious choice tasks. A number of authors, including Bateman et al. (2008) and Carson \nand  Groves  (2007),  have  discussed  the  potential  effects  of  cost  levels  presented  in \nprevious choice sets, but, to our knowledge, no studies have modelled these effects. We \naim to fill this research gap in this paper. \n \n3. Research design and method \nThe  empirical  testing  was  carried  out  on  data  from  a  survey  of  homeowners  in  the \nAustralian Capital Territory (ACT) in 2009. The main objective of the survey was to \nestablish  homeowners’  willingness  to  pay  to  have  overhead  electricity  and \ntelecommunications  wires  in  their  suburb  replaced  by  new  underground  wires.\n9  Until \naround 1990, electricity and telecommunications networks in the ACT were installed as \noverhead wires supported by poles. Since that time, underground networks have become \nthe accepted service standard in new developments due to a number of advantages over \noverhead networks. Fires, high winds, ice storms, lightning  and other severe weather \nevents can damage overhead networks leading to extended power outages and risks of \n                                                           \n9 Further analysis of these data is to take place, including identification of the appropriate point estimate of \nmean willingness to pay, before completion of the economic evaluation of an undergrounding program in \nthe ACT.  Strategic response to a sequence of discrete choice questions  9 \n \nelectrocution by members of the public. The supply reliability of overhead networks is \nalso affected by vegetation coming into contact with power lines. Underground networks \nlead to more aesthetically pleasing residential areas and allow unobstructed views. Other \nhousehold benefits include the avoided costs of trimming trees away from power lines \nand increased flexibility in the use of residential yard space. At the project area level, \nundergrounding can be analysed as a public good due to the indivisibility of provision. \nHowever, we note that the benefits conferred on homeowners in a project area can be \nreflected  in  higher  property  values  (McNair  2009).  The  good  therefore  has  a  private \nelement in that it is a property characteristic that can be traded in the property market as \npart  of  a  bundle  of  characteristics,  albeit  subject  to  high  transaction  costs.  As  a \nconsequence, there is a possibility that respondents answered questions not only with \ntheir  own  preferences  in  mind,  but  also  the  preferences  of  others  in  the  form  of  a \nperceived property market value. Almost all participants in pre-testing interviews stated \nthat they did not consider any property value impact when completing the choice tasks. \nOnly 4 per cent of respondents to the main survey answered ‘yes’ to the question, ‘Were \nany of your choices influenced by what you think other respondents would choose?’ We \nexpect that stated preferences were not greatly influenced by perceived property market \nvalue,  but  this  cannot  be  tested.  We  therefore  make  a  maintained  assumption  in  the \nanalysis  that  follows  that  the  preferences  underlying  responses  are  not  affected  by \nproperty market considerations. We note that our analysis of the effects of elicitation \nformat on stated preferences does not rely upon this assumption. The assumption relates \nto the underlying (or initial) demand that is formed before respondents begin completing \nthe choice task(s). The opportunities to cost-minimise or revise this demand over the \ncourse of a sequence of choice tasks remain. \nThe survey employed a hybrid stated preference methodology, combining the attribute-\nbased  approach  of  choice  experiments  with  the  project-based  dichotomous  choice \napproach of contingent valuation. Three elicitation formats were used in the survey – a \nsingle  binary  choice  task  (SB),  a  sequence  of  four  binary  choice  tasks  (RB)  and  a \nsequence of four choice tasks containing two alternatives to the status quo (RMN). In \neach choice task, respondents were presented with a description of their current service \nand either one or two undergrounding options. Each choice alternative was described in 10    B. McNair, J. Bennett, D. A. Hensher \n \nterms of the attributes in Table 1. All of the benefits of undergrounding other than supply \nreliability benefits are embodied in the Type attribute. This includes the amenity and \nsafety  benefits  that  are  generally  thought  to  be  the  major  household  benefits  from \nundergrounding.  \nTable 1: Attributes used to describe alternatives in choice tasks \nAttribute description in choice tasks \nType of infrastructure (underground or overhead) \nPower cuts without warning: \nNumber of power cuts each 5 years \nAverage duration of power cuts \nPower cuts with 7 days written notice (occurring in normal business hours): \nNumber of power cuts each 5 years \nAverage duration of power cuts \nYour one-off undergrounding contribution\n10  \n \nIn the status quo alternative, the ‘type of infrastructure’ (Type) attribute was set at the \n‘overhead’  level  and  the  cost  attribute  was  set  at  the  level  $0.  Respondents  were \npresented with default supply reliability attribute levels for the status quo and given the \nopportunity to adjust them to fit with their own experience. The Type attribute was set to \nthe ‘underground’ level for all change (non status quo) alternatives in the design. This \nensured  that  every  alternative  in  the  design  was  meaningful  as  a  SB  choice,  while \nallowing the same set of alternatives to be used in all three elicitation formats. The supply \nreliability levels in the undergrounding alternatives were calculated as a proportion of the \nstatus  quo  level:  ‘number  of  power  cuts  without  warning’  (0.25,  0.5,  0.75  and  1), \n‘duration of power cuts without warning’ (0.33, 0.66, 1.33, 1.66), ‘number of power cuts \nwith notice’ (0.2, 0.4, 0.6, 0.8) and ‘duration of power cuts with notice’ (0.33, 0.66, 1.33, \n1.66). Where respondents chose very low status quo levels (1 or less) for the power cut \nfrequency attributes absolute levels were assigned (0, 1 and 2). The cost attribute took 16 \n                                                           \n10 Payable either up-front with a 3 per cent discount or in instalments for up to 5 years at a 6.5 per cent per \nannum interest rate. Strategic response to a sequence of discrete choice questions  11 \n \nlevels. Eight were assigned ($1000, $2000, $3000, $4000, $6000, $8000, $12,000 and \n$16,000) and a further eight were anchored on these levels as part of the experimental \ndesign (-$200, -$100, +$100 and +$200). \nEight  choice  tasks  were  designed  in  the  RMN  elicitation  format  to  maximise  the  C-\nefficiency (Scarpa and Rose 2008) of the design using Bayesian priors (derived from pre-\ntesting  responses  and  NERA  and  ACNielsen  (2003))  assuming  the  default  supply \nreliability levels for the status quo. This approach maximises the statistical significance of \nthe least significant WTP estimate across the attributes of interest (assuming a standard \nmultinomial  logit  model).  The  RMN  design  was  used  because  it  was  expected  that \nestimates of WTP for supply reliability, which were less statistically significant in the \ndesign than the Type and cost attributes, would rely heavily on data from that elicitation \nformat. These eight choice sets were blocked into 2 sequences of 4 choice tasks. Each \nrespondent in the RMN sample split received one of these sequences. The RB design was \ncreated by splitting each of these sequences into two new sequences giving 4 sequences \nof 4 choice tasks with only one alternative to the status quo. That is, each of the 16 \ndifferent (non-status-quo) alternatives present in the RMN design represented a binary \nchoice task in the RB design. Each respondent in the SB sample split received one of \nthese 16 choice tasks. This could be thought of as extreme blocking of the RB design. \nThe web-based questionnaire was refined based on in-depth interviews with a total of 11 \nparticipants. Households were recruited by telephone and screening questions were used \nto  ensure  that  participating  households  were  owner-occupiers  of  stand-alone  houses \nserviced by overhead wires.\n11 Email invitations were sent to the 2,485 households that \nagreed  to  participate.  The  invitation  included  some  background  information  on  the \nresearch and a URL and unique password for accessing the online questionnaire. 1,744 \nrespondents  completed  the  online  questionnaire  (1,163  in  SB  and  292  in  RB).  The \nquestionnaire  provided  background  information  on  undergrounding  before  asking \nrespondents to identify the most important benefits and disadvantages of undergrounding \n                                                           \n11 This is the only group that face both the benefits and the costs of both undergrounding and reliability \nimprovements. 12    B. McNair, J. Bennett, D. A. Hensher \n \nto  their  household.  After  establishing  individual-specific  reference  levels  for  power \nsupply  reliability  attributes,  the  questionnaire  advised  respondents  of  the  number  of \nchoice tasks that would be presented, the number of alternatives that would be presented \nin each task and the attributes that would be used to describe each alternative.\n12 The \nquestionnaire outlined a suburb-based majority rule social choice function (often referred \nto as a provision rule or decision rule in the non-market valuation literature) that ensured \nincentive compatibility in the SB response format. In the RB format the equivalent social \nchoice  function  was  that  an  undergrounding  option  would  be  considered  for \nimplementation in a suburb if it was preferred to the status quo by more than 50 per cent \nof respondents in that suburb. Importantly, the survey program did not allow respondents \nto navigate back through the sequence of choice tasks. The survey was programmed to \ncycle  through  the  various  blocks  and  elicitation  format  sample  splits  to  ensure \napproximately equal representation across choice observations. The final sections of the \nquestionnaire  comprised  questions  about  information  processing  and  the  socio-\ndemographic characteristics of the respondent and their household. \nThree  different  modelling  approaches  are  used  to  analyse  the  effect  of  presenting  a \nsequence of binary choice tasks (RB) as opposed to a SB choice. The first is the binary \nlogit  model,  which  estimates  the  effect  of  elicitation  format  on  the  probability  of \nchoosing  the  undergrounding  option  in  a  given  choice  task.  This  approach  allows \nexamination of bid acceptance curves and total willingness to pay (TWTP) in line with \nstandard  analysis  of  single  binary  choice  data  in  the  literature  on  CV referenda.  The \nsecond and third are the multinomial logit (MNL) model and the panel random parameter \nlogit (RPL) model, which are used to estimate marginal willingness to pay (MWTP) for \nthe various attributes of the electricity network service. These models are commonly used \nto  analyse  data  from  surveys  in  which  respondents  are  presented  with  a  sequence  of \nattribute-based choice tasks (choice experiments or conjoint analysis). The RPL model \nhas been preferred to the MNL model in the recent choice experiment literature due to its \ngenerality and its ability to estimate heterogeneity in preferences across the population. \n                                                           \n12 The questionnaire did not include a practice or learning choice task. Strategic response to a sequence of discrete choice questions  13 \n \nHowever,  there  is  some  doubt  as  to  whether  a  single  observation  per  respondent  is \nsufficient to enable the separate estimation of random parameter and error distributions \nthat characterises the RPL model. We therefore present evidence on TWTP and MWTP \nfrom both MNL and RPL models. \nAll of these models are based on random utility theory, which is built on the assumption \nthat  the  utility,  U,  derived  by  a  respondent  from  an  alternative  is  a  function  of  the \nattributes of the alternative, the characteristics of the respondent as well as unobserved \nindividual heterogeneity (in the case of the RPL model) and a random element, ε. In any \ngiven choice task, respondents choose the alternative that yields the highest utility. The \noutcome is an index of the observed choice, y. The utility that respondent i derives from \nalternative j in choice task t is \nUijt = βi′xijt + δi′zit + εijt. \nwhere xijt is a vector of observed variables, zit is a set of choice invariant characteristics \n(potentially socio-demographic characteristics of the respondent or characteristics of the \nchoice  task  such  as  its  position  order  in  any  sequence)  and  βi  and  δi  are  vectors  of \ncoefficients  to  be  estimated.  The  models  presented  in  this  paper  assume  ε  to  be \nindependently and identically distributed (i.i.d.) according to the extreme value type I \nfunction. In the case of a binary choice between the status quo and one alternative, the \nprobability that respondent i chooses the alternative (y=1) rather than the status quo (y=0) \nin choice task t is \n( )\n) ' exp( 1\n) ' exp(\n| 1 Pr\nit\nit\nx\nx\nx y\nβ\nβ\n+\n= =    \nwhere the components of x are defined as the difference in attribute levels between the \nalternative  and  the  status  quo.  In  the  standard  multinomial  logit  (MNL)  model,  the \nprobability that respondent i chooses alternative j in choice task t is \n( ) ( )\n( ) ∑ =\n= J\nm imt\nijt\nx\nx\nj\n1 ' exp\n' exp\nPr\nβ\nβ\n  14    B. McNair, J. Bennett, D. A. Hensher \n \nand in the case of the random parameter logit (RPL) model, the probability is \n  ( ) ( )\n( ) ∑ =\n= J\nm imt i\nijt i\ni\nx\nx\nv j\n1 ' exp\n' exp\n| Pr\nβ\nβ\n  where  i i v z Γ + ∆ + = β β   \nГ  is  a  diagonal  matrix  containing  on  its  diagonal  σk,  the  standard  deviations  of  the \nmarginal distributions of βi, and vi is distributed with mean 0 and standard deviation 1 \naccording to the distribution specified by the analyst. Correlation between the multiple \nobservations from each respondent (panel data) is accommodated by incorporating in the \nlog-likelihood function the probability of respondent i's observed sequence of choices, \nwhich is the product of the probabilities for each choice task in the sequence. \nTo test whether stated  preferences are affected by presenting  four as  opposed to one \nattribute-based choice task per respondent, we compare estimates of TWTP from basic \nbinary logit, MNL and (if possible) RPL models estimated on data from the SB format \nwith  equivalent  models  estimated  on  data  from  the  RB  format.  We  also  compare \nestimates  of  MWTP  from  the  MNL  and  RPL  models  where  possible.  To  identify \nbehavioural  explanations  for  any  differences,  we  examine  three  additional  variable \nspecifications  for  models  on  data  from  the  RB  format.  The  first  incorporates  effects \ncoded variables for the order in which choice tasks were presented as described in Table \n2.\n13 In the binary logit model, these variables enter the bid acceptance function directly. \nIn the MNL and RPL models, these are interacted with the cost variable. Bateman et al. \n(2008)  used  an  interaction  between  cost  and  log  of  question  order  to  show that  cost \nsensitivity  increases  over  the  course  of  a  sequence  of  choice  tasks.  Our  specification \nallows for a non-monotonic relationship between cost sensitivity and question order. We \nalso examine the resulting relationship between question order and WTP, where MWTP \nfor attribute x is: \nMWTP(x) = -βx / (βcost + q1.βq1*cost + q2.βq2*cost + q3.βq3*cost) \n                                                           \n13 The order in which choice tasks were presented to respondents was cycled so that each choice task was \napproximately equally represented in each order position over the population. Strategic response to a sequence of discrete choice questions  15 \n \nTo test whether advance knowledge that multiple choice tasks will be presented affects \nstated preferences in the first of a sequence of choice tasks, we compare WTP estimates \nderived from the basic models on data from the SB format with WTP estimates from the \nmodel with question order variables on the RB data, where, consistent with the formula \nabove, MWTP for attribute x evaluated at the first question in the sequence is: \nMWTP(x) = -βx / (βcost + βq1*cost) \nIn the second extended model, we incorporate two variables in addition to the effects \ncoded  question  order  variables.  The  first  is  an  interaction  between  cost  and  a  (1,-1) \nvariable indicating whether the cost level is the minimum presented to the respondent in \nthe sequence to that point (Min). The second is a similar interaction between cost and a \n(1,-1)  variable  indicating  whether  the  cost  level  is  the  maximum  presented  to  the \nrespondent in the sequence to that point (Max). We use this model to examine whether \nany  relationship  between  cost  sensitivity  and  question  order  can  be explained  by  the \npositioning of the cost level relative to the levels presented to the respondent in previous \nchoice tasks. A positive parameter estimate on the Min interaction indicates that cost \nsensitivity is lower (WTP is higher) when the cost level being presented is the lowest \npresented  in  the  sequence  to  that  point  (with  all  other  variables,  including  cost,  held \nconstant).  A  negative  parameter  estimate  on  the  Max  interaction  indicates  that  cost \nsensitivity is higher (WTP is lower) when the cost level being presented is the highest \npresented  in  the  sequence  to  that  point  (with  all  other  variables,  including  cost,  held \nconstant). The signs on the Min and Max interactions implied by the various response \nstrategies discussed above are presented in Table 3.  \nTable 2: Effects coding of question order variables \nVariable  q1  q2  q3 \nLevel in question 1  1  0  0 \nLevel in question 2  0  1  0 \nLevel in question 3  0  0  1 \nLevel in question 4  -1  -1  -1 \n 16    B. McNair, J. Bennett, D. A. Hensher \n \nThe  third  extended  model  includes  effects  coded  variables  accounting  for  the  four \npossible ‘relativities’ for the cost level presented in a choice task as described in Table \n4.\n14 In any given choice task, the cost level presented must be either: \na)  both the minimum and the maximum level presented in the sequence to that point \n(m11); \nb)  the minimum, but not the maximum level presented in the sequence to that point \n(m10); \nc)  the maximum, but not the minimum level presented in the sequence to that point \n(m01); or \nd)  neither the minimum nor the maximum level presented in the sequence to that \npoint (m00). \nTable 3: Parameter signs and relationships implied by response strategies \nResponse strategy  βmin*cost  βmax*cost  βm10*cost, βm11*cost, βm00*cost, βm01*cost \nStrong cost minimisation  +  = 0  βm10*cost=βm11*cost>βm00*cost=βm01*cost \nWeak cost minimisation  +  ? \n15  βm10*cost>βm00*cost and βm11*cost>βm01*cost \nGood deal / bad deal heuristic  +  - \nβm10*cost>βm11*cost>βm01*cost and \nβm10*cost>βm00*cost>βm01*cost \nCost averaging  -  + \nβm10*cost<βm11*cost<βm01*cost and \nβm10*cost<βm00*cost<βm01*cost \nTruthful (with stable preferences)  = 0  = 0  βm10*cost=βm11*cost=βm00*cost=βm01*cost=0 \n \n                                                           \n14 The order variables are omitted from this model since the q1 and m11 variables are essentially identical \n(since the cost level in first choice task presented is always both the minimum and maximum presented to \nthat point and this is not possible at any other point in the sequence). \n15 It can be shown using simple examples that, for a given cost in the current choice task, acceptance can be \nmore likely or less likely when the cost in the current choice task is the maximum presented in the sequence \nto that point. The likelihood depends on the level of the maximum cost accepted in the sequence to that \npoint, which depends on the cost levels presented in previous choice tasks as well as the preferences of the \nrespondent. It is difficult to differentiate between the effects of a weak cost minimisation strategy and a \n‘good deal / bad deal’ heuristic in this study as our experimental design does not allow a scope test such as \nthat conducted by Bateman et al. (2008). Strategic response to a sequence of discrete choice questions  17 \n \nThe full sample of RB data contained 289, 299, 297 and 271 choice observations for the \nm11, m10, m01 and m00 cost level relativities, respectively. In the binary logit model, \nthese variables enter the bid acceptance function directly. In the MNL and RPL models, \nthese  are  interacted  with  the  cost  variable.  This  allows  estimation  of  the  relationship \nbetween  cost  sensitivity  and  the  positioning  of  the  cost  level  relative  to  the  levels \npresented to the respondent in previous choice tasks. If the parameter estimate for the \nm00 interaction is significantly higher than that for the m01 interaction, this indicates that \ncost sensitivity is lower (and WTP is higher) when the cost level is within the range of \nlevels presented in previous choice tasks relative to when it is the highest level presented \nin the sequence to that point (with all other variables, including cost, held constant). This \nimplies, for example, that an alternative with a cost level of $4,000 is more likely to be \nchosen if previously presented cost levels were  $2,000 and $6,000 than if they were \n$2,000 and $1,000. The relationships between the cost relativity interactions implied by \nvarious response strategies are presented in Table 3. \nTable 4: Effects coding of cost relativity variables \nVariable  m11  m10  m01 \nLevel when cost is both minimum and maximum \npresented in the sequence to that point \n1  0  0 \nLevel when cost is minimum, but not maximum \npresented in the sequence to that point \n0  1  0 \nLevel when cost is maximum, but not minimum \npresented in the sequence to that point \n0  0  1 \nLevel when cost is neither minimum nor maximum \npresented in the sequence to that point \n-1  -1  -1 \n \nWe  also  examine  the  resulting  relationship  between  cost  relativity  and  WTP,  where \nMWTP for attribute x is: \nMWTP(x) = -βx / (βcost + m11.βm11*cost + m10.βm10*cost + m01.βm01*cost) \nThe  m11  cost  relativity  occurs  only  in  the  first  question  in  a  sequence  and  the  first \nquestion can only take only this cost relativity. Therefore, we can further test whether \nadvance knowledge that multiple choice tasks will be presented affects stated preferences \nin the first of a sequence of choice tasks by comparing WTP estimates derived from the 18    B. McNair, J. Bennett, D. A. Hensher \n \nbasic models on data from the SB format with WTP estimates from the model with cost \nrelativity variables on the RB data, where, consistent with the formula above, MWTP for \nattribute x evaluated at the first question in the sequence is: \nMWTP(x) = -βx / (βcost + βm11*cost) \n \n4. Results \nThe  binary  logit  model  results  are  presented  in  Table  5.  Data  are  excluded  where \nrespondents took less than 5 minutes to complete the SB survey or less than 6 minutes to \ncomplete  the  RB  survey.  It  is  expected  that  these  questions  were  answered  without \nconsideration (possibly  randomly) solely as  a means of qualifying  for the prize draw \nparticipation incentive. The basic models on the SB and RB formats (Models 1 and 2, \nrespectively) include a constant, the log of the contribution amount, supply reliability \nattributes  and  effects  coded  (-1,1  or  -1,0,1)  variables  for  the  respondent’s  sex,  age, \nhousehold income and exposure to media coverage of the issue of undergrounding in \nCanberra.  Other  socio-demographic  characteristics  were  tested  and  omitted  from  the \nmodels after they were found to be statistically insignificant.  \nThe bid acceptance curves derived from Models 1 and 2 with non-cost variables set at \ntheir population means are shown in Figure 1. Bid acceptance is significantly lower in the \nRB format relative to the incentive compatible SB format for all cost levels except those \nat the lower end of the range used in the design. This is consistent with predictions based \nboth on the cost minimisation strategy (both the strong and weak cases) and on the ‘good \ndeal / bad deal’ heuristic. The bid acceptance rate is at least as high in the RB format for \nchoice tasks with cost levels at the lower end of the range used in the design. The effect \non  the  shape  of  the  bid  acceptance  curve  from  presenting  multiple  choice  tasks  per \nrespondent is the opposite outcome to that predicted by the cost averaging strategy, which \nwas lower bid acceptance at low cost levels and higher bid acceptance at high cost levels \nrelative to the incentive compatible response. Strategic response to a sequence of discrete choice questions  19 \n \nTable 5: Summary of results from binary logit models \nModel  Model 1  Model 2  Model 3  Model 4  Model 5 \nResponse format  SB  RB  RB  RB  RB \nParameter estimates:           \nConstant  .65063***       \n(.16489) \n.91712***       \n(.17105) \n.92918***       \n(.17199) \n.67703***       \n(.18144) \n.33437          \n(.21173) \nLog of household contribution \n($’000s) \n-.64969***       \n(.07768) \n-1.1276***       \n(.08734) \n-1.1404***       \n(.08806) \n-.90854***       \n(.10195) \n-.77625***       \n(.11441) \nChange in number of unplanned \noutages per 5 years \n-.04957          \n(.05533) \n-.04692          \n(.04197) \n-.04669          \n(.04218) \n-0.07938*         \n(0.04448) \n-.06986          \n(.04346) \nChange in unplanned minutes off \nsupply per 5 years \n-.00061          \n(.00055) \n-.000044          \n(.00046) \n.000006          \n(.00046) \n.00014          \n(.00047) \n.00011          \n(.00047) \nChange in planned minutes off \nsupply per 5 years \n-0.00034*         \n(0.0002) \n-.00062***       \n(.00020) \n-.00064***       \n(.00020) \n-.00052***       \n(.00019) \n-.00053***       \n(.00019) \nGender (male=1)  .05860          \n(.06481) \n.13980*         \n(.07168) \n.14024*         \n(.07190) \n.13954*         \n(.07251) \n.13319*         \n(.07262) \nAge: young (<40=1)  -.12385          \n(.12163) \n-.32247**        \n(.12775) \n-.32272**        \n(.12809) \n-.32396**        \n(.12852) \n-.32022**        \n(.12878) \nAge: old (>65=1)  .05994          \n(.12577) \n.32288**        \n(.13863) \n.32375**        \n(.13888) \n.31080**        \n(.14099) \n.30544**        \n(.14109) \nHousehold income: lower \n(<$52,000 pa =1) \n-.18730          \n(.14051) \n-.41362**        \n(.16680) \n-.42543**        \n(.16818) \n-.39958**        \n(.16883) \n-.41485**        \n(.16887) \nHousehold income: upper \n(>$182,000 pa =1) \n.01561          \n(.10678) \n-.00160          \n(.12240) \n.00413          \n(.12331) \n.01748          \n(.12383) \n.02872          \n(.12407) \nExposure to media (yes=1)  .16884**        \n(.06805) \n.11986          \n(.07352) \n.12153          \n(.07396) \n.14361*         \n(.07491) \n.15400**        \n(.07514) \nOrder: question 1  (q1=1)      .29826**        \n(.11844) \n.06355          \n(.19155)   \nOrder: question 2 (q2=1)      -.12053          \n(.11917) \n-.09576          \n(.12346)   \nOrder: question 3 (q3=1)      -0.20429*         \n(0.12023) \n-.10884          \n(.13847)   \nMinimum cost in sequence to that \npoint (minimum=1) * log of \ncontribution \n      .22848***       \n(.06435)   \nMaximum cost in sequence to that \npoint (maximum=1) * log of \ncontribution \n      -.13564**        \n(.06211)   \nRelativity: M11 (minimum and \nmaximum cost in sequence to that \npoint =1) \n        .35528***       \n(.11686) \nRelativity: M10 (minimum, but \nnot maximum cost in sequence to \nthat point =1) \n        .49496***       \n(.14831) \nRelativity: M01 (maximum, but \nnot minimum cost in sequence to \nthat point =1) \n        -.87863***       \n(.17496) \nModel fit:           \nObservations  1090  1112  1112  1112  1112 \nLog-likelihood  -705  -631  -627  -616  -616 \nInformation criterion AIC  1.31  1.15  1.15  1.14  1.13 \n *, ** and *** indicate statistical significance at the 0.1, 0.05 and 0.01 levels respectively; standard errors are in parentheses. 20    B. McNair, J. Bennett, D. A. Hensher \n \n \nFigure 1: Bid acceptance curves derived from Models 1 and 2 \n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15\nCost ($'000s)\nM\no\nd\ne\nl\nl\ne\nd\n \nb\ni\nd\n \na\nc\nc\ne\np\nt\na\nn\nc\ne\nSB\nRB\n \nThe  descriptive  statistics  for  mean  TWTP  estimates  derived  from  these  models  are \npresented in Table 7.\n16 Point estimates for mean TWTP are $6,916 and $5,362 in the SB \nand  RB  models,  respectively,  calculated  as  the  area  under  the  bid  acceptance  curve \ntruncated at the $16,000 cost level with  all non-cost variables set at their population \nmeans. The result of a test to establish whether TWTP is significantly lower in the RB \nformat than in the incentive compatible SB format is presented in Table 6. The null \nhypothesis that mean TWTP in the SB format is less than or equal to that in the RB \nformat is rejected at the .10 level, but not at the .05 level.  \nTable 6: Tests for differences in TWTP \nNull hypothesis (H0) \nTWTPModel 1 ≤ \nTWTPModel 2 \nTWTPModel 1 = \nTWTPModel 3:q1 \nTWTPModel 1 = \nTWTPModel 5:m11 \np-value  0.0993  0.6099  0.8512 \n \n                                                           \n16 Confidence intervals and hypothesis testing were based on a bootstrapping procedure with 1000 random \ndraws of WTP (calculated by drawing from normal distributions for all relevant parameters with moments \nset at their means and standard errors). Strategic response to a sequence of discrete choice questions  21 \n \nTable 7: Estimates of TWTP derived from binary logit models ($2009) \n  Mean  90 per cent CI \nModel 1  6,916  5,386 - 8,481 \nModel 2  5,362  4,120 - 6,752 \nModel 3: Q1  6,233  4,736 - 7,879 \nModel 3: Q2  5,013  3,740 - 6,485 \nModel 3: Q3  4,786  3,551 - 6,207 \nModel 3: Q4  5,459  3,855 - 7,262 \nModel 5: M11  6,624  4,667 - 8,708 \nModel 5: M10  7,104  5,008 - 9,344 \nModel 5: M01  3,094  1,936 - 4,523 \nModel 5: M00  5,595  3,546 - 8,033 \n \nModel 3 incorporates into the RB model effects coded variables for the order in which \nchoice tasks were presented to the respondent. The parameter estimate for the q1 variable \nis  positive  and  significantly  higher  than  the  parameter  estimates  for  the  q2  and  q3 \nvariables. The coding of the variables, which is set out in Table 2, means that the implicit \nparameter estimate for q4 is the negative of the sum of the parameter estimates for q1, q2, \nand  q3,  which  is  0.02656.  The  parameter  estimates  indicate  that  bid  acceptance  is \nsignificantly higher in the first question relative to the later questions in the sequence \n(with  all  other  variables,  including  cost,  held  constant).  The  modelled  relationship \nbetween  question  order  and  TWTP  (mean  and  90  per  cent  confidence  interval)  is \npresented in Figure 2. The point estimate of TWTP is highest in the first choice task \npresented. It decreases over the second and third choice tasks before increasing at the \nfourth and final choice task. This is similar to the finding of Bateman et al. (2008) that \ncost sensitivity increases over a sequence of choice tasks.  \nThe model predicts mean TWTP in the first choice task at $6,233, which is slightly lower \nthan  the  point  estimate  of  mean  TWTP  from  the  incentive  compatible  SB  format  of \n$6,916. Table 6 presents a test of the statistical significance of this difference. We fail to \nreject statistical equivalence of these two estimates with a p-value of 0.61. That is, we \nfind no evidence to suggest that advance knowledge that multiple choice tasks would be \npresented has an effect on stated preferences in the first choice task. 22    B. McNair, J. Bennett, D. A. Hensher \n \nFigure 2: TWTP by question order (estimated in Model 3) \n2,000\n3,000\n4,000\n5,000\n6,000\n7,000\n8,000\n9,000\nQ1 Q2 Q3 Q4\nT\nW\nT\nP\n \nThe question order variables are retained in Model 4 and Min and Max interactions are \nadded. Min and Max are (1,-1) variables indicating whether the cost level is the minimum \nand maximum, respectively, presented to the respondent in the sequence to that point. \nBoth of these interactions are statistically significant at the 0.05 level and the AIC value \nsuggests  the  explanatory  power  of  the  model  is  improved.  All  of  the  effects  coded \nvariables for question order become insignificant indicating that there is no significant \nresidual order effect once we account for the effect of cost levels presented in earlier \nchoice tasks. This is a key result because it indicates that other possible interpretations for \norder  effects,  such  as  learning  and  fatigue  effects,  do  not  appear  to  be  affecting  bid \nacceptance (and therefore TWTP) in this case, though they may be affecting the error \nvariance (and scale). The positive coefficient on the Min interaction indicates that an \nundergrounding option is less likely to be chosen if an option with a lower cost had been \npresented  earlier  in  the  sequence.  The  negative  coefficient  on  the  Max  interaction \nindicates that an undergrounding option is more likely to be chosen if an option with a \nhigher cost had been presented earlier in the sequence. This evidence is consistent with a \n‘good deal / bad deal’ heuristic and possibly a weak cost minimisation strategy. It is \nclearly contrary to the hypotheses of cost averaging and truthful response with stable \npreferences.  Strategic response to a sequence of discrete choice questions  23 \n \nFigure 3: TWTP by cost relativity (estimated in Model 5) \n0\n2,000\n4,000\n6,000\n8,000\n10,000\nMin and Max Min only Max only Neither Min nor\nMax\nT\nW\nT\nP\n \nModel 5 includes effects coded variables for cost relativity as described in Table 4. Cost \nlevel relativity was found to have a significant effect on bid acceptance. The relationship \nbetween  cost  level  relativity  and  TWTP  (mean  and  90  per  cent  confidence  interval) \nevaluated at population means for all variables is shown in Figure 3. The relativity with \nthe highest point estimate of TWTP is m10 (minimum, but not maximum). The incentive \ncompatible relativity, m11, had the next highest estimate, while m01 (maximum, but not \nminimum) had the lowest. This is further evidence to support a ‘good deal / bad deal’ \nheuristic hypothesis (βm10*cost>βm11*cost>βm01*cost and βm10*cost>βm00*cost>βm01*cost) or a weak \ncost  minimisation  strategy  hypothesis  rather  than  a  strong  cost  minimisation  strategy \nhypothesis  (βm10*cost=βm11*cost>βm00*cost=βm01*cost),  a  cost  averaging  hypothesis \n(βm10*cost<βm11*cost<βm01*cost and βm10*cost<βm00*cost<βm01*cost) or truthful response with stable \npreferences  (βm10*cost=βm11*cost=βm00*cost=βm01*cost=0).  Mean  TWTP  is  $6,624  when \nevaluated at the incentive compatible relativity, m11. This is remarkably similar to the \nmean  TWTP  estimate  from  the  incentive  compatible  SB  format  of  $6,916.  Table  6 \npresents a test of the statistical significance of the difference between these two estimates. \nWe  fail  to  reject  statistical  equivalence  with  a  p-value  of  0.85.  That  is,  we  find  no 24    B. McNair, J. Bennett, D. A. Hensher \n \nevidence that advance knowledge that multiple choice tasks would be presented had an \nimpact on responses to the first choice task. \nThe MNL model results are presented in Table 9. The basic models on the SB and RB \ndata (Models 6 and 7, respectively) include supply reliability variables and the ‘type of \ninfrastructure’  and  cost  variables.  All  parameter  estimates  are  more  statistically \nsignificant in the model on the RB data (Model 7) than in the model on the SB data \n(Model  6)  even  without  accounting  for  the  panel  nature  of  the  data  from  the  RB \nelicitation format. The estimates of TWTP derived from the MNL models are presented \nin Table 8. Consistent with the binary logit model results, the point estimate of mean \nTWTP is higher in the SB model than in the RB model. The result of the test of statistical \nsignificance of this difference is set out in Table 10. We fail to reject the null hypothesis \nthat TWTP in the SB format is less than or equal to TWTP from the RB format with a p-\nvalue of 0.21. This is a higher p-value than that derived from the equivalent test on \nTWTP estimates from the binary logit models. It appears the difference is mainly due to a \nlarger standard error on the TWTP estimate from the MNL model on the SB data.  \nTable 8: Estimates of mean TWTP for mean undergrounding scenario (from MNL models) ($2009) \nModel  Mean  90 per cent CI \nModel 6 (SB)  5,585  2,893 - 8,438 \nModel 7 (RB)  4,069  2,759 - 5,428 \nModel 8: Q1        5,864         3,673 - 8,551 \nModel 8: Q2        3,730         2,499 - 5,028 \nModel 8: Q3        3,465         2,299 - 4,740 \nModel 8: Q4        4,030         2,511 - 5,872   \nModel 10: m11        5,574         2,679 - 9,758 \nModel 10: m10\n a        7,948   -25,256 - 47,180 \nModel 10: m01        3,141         1,676 - 4,765   \nModel 10: m00        3,260         1,594 - 5,642  \na Confidence intervals are large because the denominator in WTP calculations (βcost + βcost*m10) was very \nclose to zero in a number of the random draws. Mean is 10,139 after removing outliers (absolute value > \n$40,000) from random draws. \n Strategic response to a sequence of discrete choice questions  25 \n \nTable 9: Summary of results from MNL models \nModel  Model 6  Model 7  Model 8  Model 9  Model 10 \nResponse format  SB  RB  RB  RB  RB \nParameter estimates:           \nHousehold contribution ($’000s)  -.10901***       \n(.01397) \n-.19976***       \n(.01713) \n-.21104***       \n(.01793) \n-.16199***       \n(.02652) \n-.16161***       \n(.02650) \nChange in frequency of unplanned \noutages each 5 years \n-.08506          \n(.05538) \n-.08416**        \n(.04284) \n-.08801**        \n(.04301) \n-.10150**        \n(.04411) \n-.09637**        \n(.04366) \nChange in unplanned minutes off \nsupply each 5 years \n-.00040          \n(.00054) \n.00011          \n(.00045) \n.00013          \n(.00046) \n.00019          \n(.00047) \n.00016          \n(.00046) \nChange in planned minutes off \nsupply each 5 years \n-.00022          \n(.00018) \n-.00045**        \n(.00018) \n-.00044**        \n(.00018) \n-.00044**        \n(.00018) \n-.00042**        \n(.00018) \nType of infrastructure \n(underground=1) \n.19822***       \n(.06331) \n.29816***       \n(.06398) \n.31795***       \n(.06460) \n.22916***       \n(.07521) \n.23013***       \n(.07506) \nInteractions with household \ncontribution:           \nOrder: question 1  (q1=1)      .06251***       \n(.01611) \n-.07499          \n(.04720)   \nOrder: question 2  (q2=1)      -.01906          \n(.01914) \n.00069          \n(.02111)   \nOrder: question 3  (q3=1)      -0.03636*         \n(0.02011) \n.02026          \n(.02748)   \nMinimum cost in sequence to that \npoint (minimum=1)        .09398***       \n(.02939)   \nMaximum cost in sequence to that \npoint (maximum=1)        .01092          \n(.01690)   \nRelativity: M11 (minimum and \nmaximum cost in sequence to that \npoint =1) \n        .03049          \n(.02002) \nRelativity: M10 (minimum, but not \nmaximum cost in sequence to that \npoint =1) \n        .09255**        \n(.03870) \nRelativity: M01 (maximum, but not \nminimum cost in sequence to that \npoint =1) \n        -.05938***       \n(.02115) \nModel fit:           \nObservations  1090  1112  1112  1112  1112 \nLog-likelihood  716  656  648  643  644 \nInformation criterion AIC  1.32  1.19  1.18  1.17  1.17 \n*, ** and *** indicate statistical significance at the 0.1, 0.05 and 0.01 levels respectively; standard errors are in parentheses. \n \n \nTable 10: Tests for differences in TWTP (derived from MNL models) \nNull hypothesis (H0) \nTWTPModel 6 ≤ \nTWTPModel 7 \nTWTPModel 6 = \nTWTPModel 8:Q1 \nTWTPModel 6 = \nTWTPModel 10:m11 \np-value  0.2122  0.9247  0.9333 \n 26    B. McNair, J. Bennett, D. A. Hensher \n \nThe estimates of MWTP derived from the MNL models are presented in Table 11. Point \nestimates of MWTP are generally lower in the RB model than the SB model. However, \nthe test results presented in Table 12 indicate that the differences are not statistically \nsignificant even at the 0.1 level.  \nTable 11: Estimates of mean MWTP (based on MNL models) ($2009) \nAttribute level change  Model  Mean  90 per cent CI \nModel 6 (SB)  3,682  1,681 - 5,929  Type of infrastructure \n(OH to UG)  Model 7 (RB)  3,000  1,901 - 4,195 \nModel 6 (SB)  -798  -1,711 - 46  Number of unplanned \npower cuts each 5 years \n(unit increase)  Model 7 (RB)  -426  -793 - -74 \nModel 6 (SB)  -3.77  -12.26 - 4.43  Unplanned minutes off \nsupply each 5 years \n(unit increase)  Model 7 (RB)  0.53  -3.20 - 4.18 \nModel 6 (SB)  -2.07  -4.91 - 0.64  Planned minutes off \nsupply each 5 years \n(unit increase)  Model 7 (RB)  -2.28  -3.87 - -0.80 \n \nTable 12: Tests for differences in MWTP (derived from MNL models) \nAttribute  \nType of \ninfrastructure  \nNumber of \nunplanned power \ncuts each 5 years  \nUnplanned minutes \noff supply each 5 \nyears  \nPlanned minutes \noff supply each 5 \nyears  \nNull hypothesis H0: \nMWTPModel 6 ≤ \nMWTPModel 7 \n-MWTPModel 6 ≤  \n-MWTPModel 7 \n-MWTPModel 6 ≤  \n-MWTPModel 7 \n-MWTPModel 6 ≤  \n-MWTPModel 7 \np-value  0.3370  0.2537  0.2217  0.5344 \n \nModel  8  incorporates  interactions  between  the  cost  variable  and  the  question  order \nvariables effects coded as described in Table 2. The positive and significant coefficient \non the q1 interaction indicates that cost sensitivity is relatively low in the first choice task \n(with all other variables, including cost, held constant). Figure 4 shows that, consistent \nwith the results from the binary logit model, the point estimate of mean TWTP is highest \nfor the first choice task, and decreases over the second and third choice tasks before \nincreasing at the fourth choice task. The estimate of mean TWTP for the first choice task \nin the RB format is $5,864. Table 10 shows that we fail to reject statistical equivalence \nbetween  this  estimate  and  the  estimate  from  the  incentive  compatible  SB  format  of Strategic response to a sequence of discrete choice questions  27 \n \n$5,585 with a p-value of 0.92. That is, we find no evidence to suggest that advance \nknowledge  that  multiple  choice  tasks  would  be  presented  has  an  effect  on  stated \npreferences in the first choice task. \nFigure 4: TWTP by question order (estimated in Model 8) \n-\n1,000\n2,000\n3,000\n4,000\n5,000\n6,000\n7,000\n8,000\n9,000\nQ1 Q2 Q3 Q4\nT\nW\nT\nP\n \nConsistent with results from the binary logit model (Model 4), the order variables become \ninsignificant once the Min and Max interactions are incorporated in Model 9, indicating \nthat the majority of the order effect is explained by the effect of cost levels in previously \npresented choice tasks. Model 10 incorporates interactions between the cost variable and \nthe cost relativity variables effects coded as described in Table 4. Figure 5 shows the \nmeans  and  90  per  cent  confidence  intervals  for  TWTP  estimated  at each  of  the  cost \nrelativity effects. The ranking of mean effects is the same as that derived from the binary \nlogit  model  (Model  5),  which  is  consistent  with  a  ‘good  deal  /  bad  deal’  heuristic \nhypothesis  (βm10*cost>βm11*cost>βm01*cost  and  βm10*cost>βm00*cost>βm01*cost).  However,  after \naccounting for uncertainty around the estimates, the evidence is more supportive of a \nweak cost minimisation strategy hypothesis (βm11*cost>βm01*cost and βm10*cost>βm00*cost) or a \nstrong  cost  minimisation  strategy  hypothesis  (βm10*cost=βm11*cost>βm00*cost=βm01*cost).  The \nresults  are  contrary  to  the  cost  averaging  hypothesis  (βm10*cost<βm11*cost<βm01*cost  and \nβm10*cost<βm00*cost<βm01*cost)  and  truthful  response  with  stable  preferences \n(βm10*cost=βm11*cost=βm00*cost=βm01*cost=0). At $5,574, the estimate of mean TWTP evaluated \nat the incentive compatible relativity (m11) is remarkably close to the estimate from the 28    B. McNair, J. Bennett, D. A. Hensher \n \nincentive compatible SB format of $5,585. Table 10 shows that we fail to reject statistical \nequivalence of the two estimates with a p-value of 0.93. Again, we find no evidence to \nsuggest that advance knowledge that multiple choice tasks would be presented has an \neffect on stated preferences in the first choice task. \nFigure 5: TWTP by cost relativity (estimated in Model 10) \n-\n1,000\n2,000\n3,000\n4,000\n5,000\n6,000\n7,000\n8,000\n9,000\n10,000\nMin and Max Min only Max only Neither Min nor\nMax\nT\nW\nT\nP\n \nRandom  parameter  models  accounting  for  the  panel  nature  of  the  data  from  the  RB \nresponse  format  (Models  12–15)  are  presented  in  Table  14.  The  estimated  effects  of \nquestion order and cost level relativity are consistent with those from the MNL models. \nThe model results on the SB data (Model 11) do little to dispel the doubts as to whether a \nsingle  observation  per  respondent  is  sufficient  to  enable  the  separate  estimation  of \nrandom parameter and error distributions. Very little heterogeneity across respondents is \nestimated in parameter estimates even for the Type parameter. The standard error for \nmean TWTP in the SB model is more than twice the size of that in the RB model,\n17 and, \nat around $3,000 (after accounting for outliers), the estimate of mean TWTP based on \nindividual-specific conditional distributions for the SB data is somewhat low. Rose et al. \n                                                           \n17 Variance of mean WTP was calculated as β\n-2[Var(α) - 2α/β.Cov(α,β) + (α/β)\n2Var(β)] as per Scarpa and \nRose (2008). Strategic response to a sequence of discrete choice questions  29 \n \n(2009)  had  similar  problems  estimating  an  RPL  model  on  data  with  a  single  choice \nobservation per respondent. Meaningful comparisons between the SB and RB estimates \nare  hampered  by  these  problems.  The  model  results  are  presented  here  in  order  to \nhighlight  this  key  restriction  on  analysis  when  using  the  incentive  compatible  SB \nelicitation format.  \nEstimates  of  mean  TWTP  calculated  using  individual-specific  conditional  parameter \ndistributions for the mean undergrounding scenario in the survey are set out for both \nelicitation formats in Table 13. At -$4,782, the mean estimate of TWTP in Model 11 is \nimplausible and closer inspection reveals that it is strongly influenced by an outlier in the \nmean estimates of conditional WTP. This is a problem that is common when taking the \nratio of two unconstrained distributions. One way of obtaining more plausible estimates \nof  mean  WTP  is  to  remove  or  limit  outliers  at  some  arbitrary  thresholds  after \nestimation.\n18 Table 13 presents such estimates based on thresholds set at -$40,000 and \n$40,000.  \nTable 13: Estimates of mean TWTP for mean undergrounding scenario (from RPL models) \nModel \nModel 11 \n(SB) \nModel 12 \n(RB) \nMean  -$4,782           $8,684  \nMean after removing outliers \n(>$40k or <-$40k) \n$2,812           $5,101  \nMean after limiting outliers \n(>$40k or <-$40k) \n$3,239           $4,360  \nStandard error  $917             $369  \n \n                                                           \n18 Modelling solutions to this problem include constraining the distribution on the random cost parameter \n(Hensher and Greene 2003) or estimating the model in WTP-space rather than utility space (Fiebig et al. \n2009, Hensher and Greene 2009, Scarpa et al. 2008, Train and Weeks 2005). Both types of models were \nnot estimable on the SB data. Although they were estimated on the RB data, they are excluded here because \nno meaningful comparison between SB and RB models is possible. 30    B. McNair, J. Bennett, D. A. Hensher \n \nTable 14: Summary of RPL models \nModel  Model 11  Model 12  Model 13  Model 14  Model 15 \nResponse format  SB  RB  RB  RB  RB \nRandom parameters: means           \nHousehold contribution ($’000s)  -.28094***       \n(.10286) \n-1.48572***       \n(.27525) \n-1.67766***       \n(.42140) \n-1.37517***       \n(.31462) \n-1.42002***       \n(.32023) \nChange in frequency of unplanned \noutages each 5 years \n-.16112          \n(.09832) \n.04288          \n(.14050) \n-.03936          \n(.20513) \n-.03097          \n(.13026) \n-.01380          \n(.12899) \nChange in unplanned minutes off \nsupply each 5 years \n-.00166          \n(.00117) \n-.00073          \n(.00138) \n-.00057          \n(.00196) \n-.00064          \n(.00163) \n-.00083          \n(.00158) \nChange in planned minutes off \nsupply each 5 years \n-.00048          \n(.00034) \n-.00225**        \n(.00091) \n-.00227**        \n(.00105) \n-.00201**        \n(.00084) \n-.00203**        \n(.00086) \nType of infrastructure \n(underground=1) \n.37109**        \n(.15052) \n2.28979***       \n(.45483) \n2.88937***       \n(.74042) \n2.22473***       \n(.52385) \n2.27083***       \n(.53007) \nRandom parameters: standard \ndeviations           \nHousehold contribution ($’000s) \n(triangular) \n.82343**        \n(.40680) \n2.19786***       \n(.40319) \n2.16636***       \n(.60178) \n2.48494***       \n(.53236) \n2.55728***       \n(.52548) \nChange in frequency of unplanned \noutages each 5 years (normal) \n.16478          \n(.39574) \n.08065          \n(.20073) \n1.25167***       \n(.39564) \n.23629          \n(.16347) \n.23083          \n(.15508) \nChange in unplanned minutes off \nsupply each 5 years (normal) \n.00455*         \n(.00269) \n.00249          \n(.00192) \n.00763***       \n(.00290) \n.00367          \n(.00261) \n.00371          \n(.00240) \nChange in planned minutes off \nsupply each 5 years (normal) \n.00018          \n(.00054) \n.00181          \n(.00186) \n.00244*         \n(.00133) \n.00034          \n(.00095) \n.00039          \n(.00097) \nType of infrastructure \n(underground=1) (normal) \n.24422          \n(.49869) \n2.55384***       \n(.48749) \n3.76972***       \n(.95573) \n2.95092***       \n(.62700) \n2.98149***       \n(.63927) \nHeterogeneity in means           \nHousehold contribution ($’000s):           \nOrder: question 1  (q1=1)      .27882***       \n(.09674) \n-.26923          \n(.18912)   \nOrder: question 2  (q2=1)      -.03957          \n(.07171) \n.01166          \n(.07176)   \nOrder: question 3  (q3=1)      -0.16294*         \n(0.08583) \n.09254          \n(.08470)   \nMinimum cost in sequence to \nthat point (minimum=1)        .38571***       \n(.12932)   \nMaximum cost in sequence to \nthat point (maximum=1)        .02378          \n(.07027)   \nRelativity: M11 (minimum and \nmaximum cost in sequence to \nthat point =1) \n        .15152*         \n(.07841) \nRelativity: M10 (minimum, but \nnot maximum cost in sequence \nto that point =1) \n        .40679**        \n(.16700) \nRelativity: M01 (maximum, but \nnot minimum cost in sequence \nto that point =1) \n        -.29465***       \n(.10295) \nModel fit:           \nObservations  1090  1112  1112  1112  1112 \nLog-likelihood  709  485  479  470  471 \nInformation criterion AIC  1.32  0.89  0.88  0.87  0.87 \n*, ** and *** indicate statistical significance at the 0.1, 0.05 and 0.01 levels respectively; standard errors are in parentheses. Strategic response to a sequence of discrete choice questions  31 \n \nFinally,  we  put  the  results  in  context  by  making  some  comments  on  the  attribute \nprocessing strategies employed by respondents in this study. The models presented herein \nare based on the assumption that all attributes are strictly processed as full compensatory. \nHowever, pre-testing interviews revealed that the supply reliability attributes were often \nignored in the SB and RB response formats.\n19 Questions about attribute attendance after \neach choice task revealed that attendance to the supply reliability attributes was generally \nlow in the SB and RB formats, with some respondents effectively treating the choice \ntasks as dichotomous CV questions by focussing solely on the Type and cost attributes.\n20 \nOpportunities  for  strategic  response  may  have  been  relatively  obvious  in  this  case \nbecause the good was viewed as similar from one choice task to another, while cost levels \nvaried significantly.  \n \n5. Conclusions \nThe evidence presented in this paper suggests that estimates of mean TWTP from an \nelicitation format presenting multiple choice tasks to each respondent may be lower than \nthose from a single choice task format. While there are several possible interpretations for \nthis result, our models show that at least part of this difference is related to the ordering \nof cost levels over the sequence of choice tasks. In particular, the evidence points to a \n‘good deal / bad deal’ heuristic in which respondents revise their valuation of the good on \nthe basis of cost levels presented over the course of the sequence and/or a ‘weak cost \nminimisation’ strategy in which respondents might reject an alternative that is preferred \nto the status quo if a similar good was offered at a lower cost in a previous choice task.\n21 \nThese two behavioural explanations have quite different implications. The latter implies \n                                                           \n19 They were attended to more often in the RMN format as a means of discriminating between the two \nunderground power options presented in each choice task. \n20 Models accounting for reported attribute attendance did not improve the statistical significance of the \nsupply  reliability  attributes  either  because  there  were  insufficient  observations  of  attendance  to  those \nattributes or because the binary choice design did not induce the trade-offs necessary for the econometric \nmodels to isolate the role of these attributes in respondents’ choices. These models are not reported here, \nbut are available from the presenting author by request.  \n21 Response strategies may differ from one respondent to another, giving a mixed overall result. 32    B. McNair, J. Bennett, D. A. Hensher \n \ndivergence between stated and true preferences while the former does not. The design in \nthis study does not allow us to conduct a scope test to differentiate between the two. \nRegardless, the results are contrary to the standard assumption of truthful response with \nstable preferences. \nWe find no evidence to support the hypothesis that stated preferences in the first choice \ntask presented are affected by advance knowledge that four as opposed to one choice \ntasks will be presented. In fact, there is equivalence in the evidence on TWTP estimates \nfrom the first choice task in a sequence and a SB choice task.\n22 This goes some way to \njustifying  the  use  of  the  first  choice  task  in  a  sequence  as  an  incentive  compatible \ncomparator in studies such as Bateman et al. (2008). We expect that this equivalence \nwould be at least as strong where respondents are not informed about how many choice \ntasks will be presented. This could be confirmed by further research. \nThe cost attribute was particularly dominant in respondents’ choices in this study due to \nthe experimental design and the attribute processing strategies employed by respondents. \nSimilar goods were offered at quite different cost levels over the course of a sequence of \nchoice tasks, making opportunities for strategic response relatively obvious. We note that \nScheufele and Bennett (2010b), in their concurrent and similar study focussing on the \ncase of a pure public good, found similar results to this study using a survey in which the \ncost attribute was less dominant. The cognitive burden of the choice tasks was also low in \ntheir study with binary choices between alternatives described by one cost and two non-\ncost  attributes.  A  key  objective  for  future  research  will  be  to  establish  whether  the \nresponse  strategies  identified  in  these  studies  become  less  prevalent  as  the  cognitive \nburden  of  the  trade-offs  in  the  choice  task  (potentially  measured  by  the  number  of \nattributes attended to and the number of alternatives per choice task) is increased and \nopportunities for strategic response become less obvious. While conventional wisdom \nsuggests this would be the case, mechanism design theory suggests that further scope for \nstrategic response is created by presenting two as opposed to one alternative to the status \n                                                           \n22 The web-based questionnaire did not allow respondents to navigate back through the choice tasks. A \ndifferent result may be derived from a paper-based or other survey in which respondents can review all \nchoice tasks before finalising their responses. Strategic response to a sequence of discrete choice questions  33 \n \nquo  in  each  choice  task  (Satterthwaite  1975).  Further  research  by  these  authors  will \nutilise data collected from the RMN elicitation format in the survey described in this \npaper to examine these issues. It will be important for further research to consider not \nonly the presentation of similar goods at different cost levels, but also the presentation of \nvery different goods at similar cost levels over the course of a sequence. \nThe evidence from this study supports the notion that the analyst’s choice of elicitation \nformat should depend upon the requirements of the study. The SB choice format is best \nsuited to estimation of TWTP for a good with a fixed set of attributes (i.e., contingent \nvaluation).  Despite  its  desirable  incentive  properties,  this  format  appears  to  perform \npoorly when the objective is estimation of MWTP for multiple attributes of a good. Even \nwhen the sample size is very large, the single choice task may result in relatively high \nerror variance (due to the lack of institutional learning) and may not provide enough \ninformation  to  allow  estimation  of  heterogeneity  in  tastes  across  a  population.  An \nelicitation format with multiple alternatives to the status quo in each choice task and \nmultiple choice tasks per respondent may be required to estimate MWTP for multiple \nattributes of a good.  In these cases, analysts should be conscious of the potential for \nstrategic  response  to  a  sequence  of  choice  tasks  and,  if  possible,  report  on  any \nrelationship between cost sensitivity and question order or the cost levels presented in \nprevious choice tasks.  \n \nAcknowledgements    The authors would like to thank Gabriela Scheufele for valuable discussions and \nexchanges of ideas, David Graham of ActewAGL Distribution for allowing the publication of these results \nand Andrew Collins and Yang Lan of the Institute of Transport and Logistics Studies for their survey \nprogramming work. \n \nReferences \n \nAccent (2008) Expectations  of DNOs  &  willingness to pay for improvements in  service. A report for \nOFGEM, July \n____ (2003) Expectations of electricity DNOs & WTP for improvements in service: stage 1 quantitative \nresearch findings. A report for OFGEM, September 34    B. McNair, J. Bennett, D. A. Hensher \n \nAlfnes F and Steine G (2005) None-of-these bias in hypothetical choice experiments. Discussion paper DP-\n06/05,  Department  of  Economics  and  Resources  Management,  Norwegian  University  of  Life \nSciences, Aas,  \nArrow K, Solow R, Portney P R, Leamer E E, Radner R and Schuman H (1993) Report of the NOAA panel \non contingent valuation. Federal Register 58: 4601-4614 \nBaron D and Myerson R (1982) Regulating a monopolist with unknown costs. Econometrica 50: 911-930 \nBateman I J, Carson R T, Day B, Dupont D, Louviere J J, Morimoto S, Scarpa R et al (2008) Choice set \nawareness and ordering effects in discrete choice experiments. CSERGE Working Paper EDM 08-\n01  \nBoyle K, Morrison M and Taylor L (2004) Why value estimates generated using choice modelling exceed \ncontingent valuation: further experimental evidence. Paper presented at Australian Agricultural \nand Resource Economics Society Conference, Melbourne, 11-13 February \nBradley M and Daly A (1994) Use of the logit scaling approach to test for rank-order and fatigue effects in \nstated preference data. Transportation 21(2): 167-184 \nBraga J and Starmer C (2005) Preference anomolies, preference elicitation and the discovered preference \nhypothesis. Environmental and Resource Economics 32: 55-89 \nCameron T A, Poe G L, Ethier R G and Schulze W D (2002) Alternative non-market value-elicitation \nmethods:  Are  the  underlying  preferences  the  same?  Journal  of  Environmental  Economics  and \nManagement 44: 391-425 \nCameron T A and Quiggan  J (1994) Estimation using contingent  valuation data  from a \"dichotomous \nchoice with follow-up\" questionnaire. Journal of Environmental Economics and Management 27: \n218-234 \nCarlsson F and Martinsson P (2001) Do hypothetical and actual marginal willingness to pay differ in choice \nexperiments? Journal of Environmental Economics and Management 41: 179-192 \n____ (2006) How much is too much? An investigation of the effect of the number of choice sets, starting \npoint and the choice of bid vectors in choice experiments. Working Papers in Economics no. 191, \nDepartment of Economics, School of Business, Economics and Law, Göteborg University \nCarson K S, Chilton S M and Hutchinson W G (2008) Decision Rules and Demand Revelation in Decisive \nDouble Referenda. Paper presented at 16th Annual Conference of the European Association of \nEnvironmental and Resource Economists, Gothenburg, Sweden, 25-28 June \nCarson  R  T  and  Groves  T  (2007)  Incentive  and  informational  properties  of  preference  questions. \nEnvironmental and Resource Economics 37: 181-210 \nCarson R T, Groves T and List J (2006) Probabilistic influence and supplemental benefits: a field test of the \ntwo key assumptions behind using stated preferences. Manuscript,  \nCarson R T, Groves T and Machina M J (1997) Stated preference questions: context and optimal response. \nPaper presented at National science foundation preference elicitation symposium, University of \nCalifornia, Berkeley,  \nCaussade S, Ortuzar J d D, Rizzi L I and Hensher D A (2005) Assessing the influence of design dimensions \non stated choice experiment estimates. Transportation Research Part B 39: 621-640 \nFarquharson R (1969) Theory of voting. Yale University Press, New Haven \nFiebig D, Keane M, Louviere J J and Wasi N (2009) The generalized multinomial logit: accounting for \nscale  and  coefficient  heterogeneity.  Marketing  Science  published  online  before  print  July  23, \nDOI:10.1287/mksc.1090.0508 \nGreen J and Laffont J J (1979) Incentives in public decision making. North-Holland, Amsterdam \nGreen J R and Laffont J J (1978) A sampling approach to the free rider problem. In: Sandmo A (ed) Essays \nin public economics, Lexington Books, Lexington, MA \nHanemann W M, Loomis J and Kanninen B (1991) Statistical efficiency of double bounded dichotomous \nchoice \ncontingent valuation. American Journal of Agricultural Economics 73: 1255-1263 \nHensher D A (2009) Hypothetical bias, choice experiments and willingness to pay. Working paper ITLS-\nWP-09-01, Institute of Transport and Logistics Studies, The University of Sydney,  \nHensher D A and Greene W H (2003) The mixed logit model: The state of practice. Transportation 30(2): \n133-176 \n____ (2009) Valuation of travel time savings in WTP and preference space in the presence of taste and \nscale heterogeneity. Manuscript,  Strategic response to a sequence of discrete choice questions  35 \n \nHerriges J A and Shogren J F (1996) Starting point bias in dichotomous choice valuation with follow-up \nquestioning. Journal of Environmental Economics and Management 30: 112-131 \nHolmes T and Boyle K J (2005) Dynamic learning and context-dependence in sequential, attribute-based \nstated-preference valuation questions. Land Economics 81: 114-126 \nHurwicz L (1972) On informationally decentralized systems. In: McGuire C B and Radner R (ed) Decision \nand organisation, North-Holland, Amsterdam \nKPMG  (2003)  Consumer  preferences  for  electricity  service  standards.  A  report  for  Essential  Services \nCommission of South Australia, September \nLaffont  J  J  and  Tirole  J  (1993)  A  theory  of  incentives  in  procurement  and  regulation.  Massachusetts \nInstitute of Technology Press, Cambridge, Massachusetts \nLoeb M and Magat W (1979) A decentralized method for utility regulation. Journal of Law and Economics \n22(2): 399-404 \nLusk  J  and  Schroeder  T  (2004)  Are  choice  experiments  incentive  compatible?  A  test  with  quality \ndifferentiated beef steaks. American Journal of Agricultural Economics 86(2): 467-482 \nMcFadden  D  and  Leonard  G  (1995)  Issues  in  the  contingent  valuation  of  environmental  goods: \nMethodologies for data collection and analysis. In: Hausman J A (ed) Contingent Valuation: A \nCritical Assessment, North-Holland, Amsterdam \nMcNair B (2009) House prices and underground electricity distribution lines: the case of three selected \nsuburbs  in  Canberra.  Occasional  Paper  #13,  Environmental  Management  and  Development, \nCrawford School of Economics and Government, The Australian National University \nMirrlees J (1971) An exploration in the theory of optimal income taxation. Review of Economic Studies \n38: 175-208 \nNERA and ACNielsen (2003) Willingness to pay research study. A report for ACTEW Corporation and \nActewAGL, September \nPlott  C  R  (1996)  Rational  individual  behavior  in  markets  and  social  choice  processes:  the  discovered \npreference hypothesis. In: Arrow K, Colombatto E, Perleman M and Schmidt C (ed) Rational \nfoundations of economic behavior, Macmillan, London \nRacevskis L and Lupi F (2008) Incentive Compatibility in an Attribute-Based Referendum Model. Paper \npresented at American Agricultural Economics Association Annual Meeting, Orlando, FL, 27-29 \nJuly \nRose J M, Hess S, Bliemer M C J and Daly A (2009) The impact of varying the number of repeated choice \nobservations  on  the  mixed  multinomial  logit  model.  Paper  presented  at  European  Transport \nConference, Leeuwenhorst, The Netherlands, 5-7 October \nSamuelson P A (1954) The pure theory of public expenditure. Review of Economics and Statistics 36: 387-\n389 \n____ (1956) Social indifference curves. Quarterly Journal of Economics 70(1): 1073-1094 \nSatterthwaite  M  A  (1975)  Strategy-proofness  and  Arrow's  conditions:  Existence  and  correspondence \ntheorems for voting procedures and social welfare functions. Journal of Economic Theory 10(2): \n187-217 \nScarpa R and Rose J (2008) Design Efficiency for Non-Market Valuation with Choice Modelling: How to \nMeasure it, What to Report and Why. Australian Journal of Agricultural and Resource Economics \n52(3): 253-282 \nScarpa R, Thiene M and Train K (2008) Utility in willingness to pay space: a tool to address confounding \nrandom  scale  effects  in  destination  choice  to  the  Alps.  American  Journal  of  Agricultural \nEconomics 90(4): 994-1010 \nScheufele G and Bennett J (2010a) Effects of alternative elicitation formats in discrete choice experiments. \nPaper  presented  at  54th  annual  Australian  Agricultural  and  Resource  Economics  Society \nconference, Adelaide, South Australia, 9-12 February \n____ (2010b) Ordering effects and response strategies in discrete choice experiments. Paper presented at \nWorld Congress of Environmental and Resource Economists, Montreal, Canada, 28 June - 2 July \nSchleifer A (1985) A theory of yardstick competition. Rand Journal of Economics 16: 319-327 \nSpence M A (1975) Monopoly, quality, and regulation. The Bell Journal of Economics 6(2): 417-429 \nTrain K and Weeks M (2005) Discrete choice models in preference space and willingness-to-pay space. In: \nScarpa R and Alberini A (ed) Applications of simulation methods in environmental and resource \neconomics, Springer Publisher, Dordrecht ",
    "id": 6407572,
    "identifiers": {
        "doi": null,
        "oai": null
    },
    "title": "Strategic response to a sequence of discrete choice questions",
    "language": {
        "code": "en",
        "name": "English"
    },
    "publishedDate": "",
    "publisher": null,
    "references": [
        {
            "id": 15675379,
            "title": "Expectations of DNOs & willingness to pay for improvements in service. A report for OFGEM,",
            "authors": [],
            "date": "2008",
            "doi": null,
            "raw": "Accent (2008) Expectations  of DNOs  &  willingness to pay for improvements in  service. A report for OFGEM, July ____ (2003) Expectations of electricity DNOs & WTP for improvements in service: stage 1 quantitative research findings. A report for OFGEM, September 34    B. McNair, J. Bennett, D. A. Hensher Alfnes F and Steine G (2005) None-of-these bias in hypothetical choice experiments. Discussion paper DP06/05,  Department  of  Economics  and  Resources  Management,  Norwegian  University  of  Life Sciences, Aas, Arrow K, Solow R, Portney P R, Leamer E E, Radner R and Schuman H (1993) Report of the NOAA panel on contingent valuation. Federal Register 58: 4601-4614 Baron D and Myerson R (1982) Regulating a monopolist with unknown costs. Econometrica 50: 911-930 Bateman I J, Carson R T, Day B, Dupont D, Louviere J J, Morimoto S, Scarpa R et al (2008) Choice set awareness and ordering effects in discrete choice experiments. CSERGE Working Paper EDM 08-01 Boyle K, Morrison M and Taylor L (2004) Why value estimates generated using choice modelling exceed contingent valuation: further experimental evidence. Paper presented at Australian Agricultural and Resource Economics Society Conference, Melbourne, 11-13 February Bradley M and Daly A (1994) Use of the logit scaling approach to test for rank-order and fatigue effects in stated preference data. Transportation 21(2): 167-184 Braga J and Starmer C (2005) Preference anomolies, preference elicitation and the discovered preference hypothesis. Environmental and Resource Economics 32: 55-89 Cameron T A, Poe G L, Ethier R G and Schulze W D (2002) Alternative non-market value-elicitation methods:  Are  the  underlying  preferences  the  same?  Journal  of  Environmental  Economics  and Management 44: 391-425 Cameron T A and Quiggan  J (1994) Estimation using contingent  valuation data  from a &quot;dichotomous choice with follow-up&quot; questionnaire. Journal of Environmental Economics and Management 27: 218-234 Carlsson F and Martinsson P (2001) Do hypothetical and actual marginal willingness to pay differ in choice experiments? Journal of Environmental Economics and Management 41: 179-192 ____ (2006) How much is too much? An investigation of the effect of the number of choice sets, starting point and the choice of bid vectors in choice experiments. Working Papers in Economics no. 191, Department of Economics, School of Business, Economics and Law, Göteborg University Carson K S, Chilton S M and Hutchinson W G (2008) Decision Rules and Demand Revelation in Decisive Double Referenda. Paper presented at 16th Annual Conference of the European Association of Environmental and Resource Economists, Gothenburg, Sweden, 25-28 June Carson  R  T  and  Groves  T  (2007)  Incentive  and  informational  properties  of  preference  questions.",
            "cites": null
        },
        {
            "id": 15675381,
            "title": "Paper presented at National science foundation preference elicitation symposium,",
            "authors": [],
            "date": "2005",
            "doi": null,
            "raw": "Paper presented at National science foundation preference elicitation symposium, University of California, Berkeley, Caussade S, Ortuzar J d D, Rizzi L I and Hensher D A (2005) Assessing the influence of design dimensions on stated choice experiment estimates. Transportation Research Part B 39: 621-640 Farquharson R (1969) Theory of voting. Yale University Press, New Haven Fiebig D, Keane M, Louviere J J and Wasi N (2009) The generalized multinomial logit: accounting for scale  and  coefficient  heterogeneity.  Marketing  Science  published  online  before  print  July  23, DOI:10.1287/mksc.1090.0508 Green J and Laffont J J (1979) Incentives in public decision making. North-Holland, Amsterdam Green J R and Laffont J J (1978) A sampling approach to the free rider problem. In: Sandmo A (ed) Essays in public economics, Lexington Books, Lexington, MA Hanemann W M, Loomis J and Kanninen B (1991) Statistical efficiency of double bounded dichotomous choice contingent valuation. American Journal of Agricultural Economics 73: 1255-1263 Hensher D A (2009) Hypothetical bias, choice experiments and willingness to pay. Working paper ITLSWP-09-01, Institute of Transport and Logistics Studies, The University of Sydney, Hensher D A and Greene W H (2003) The mixed logit model: The state of practice. Transportation 30(2): 133-176 ____ (2009) Valuation of travel time savings in WTP and preference space in the presence of taste and scale heterogeneity. Manuscript,  Strategic response to a sequence of discrete choice questions  35 Herriges J A and Shogren J F (1996) Starting point bias in dichotomous choice valuation with follow-up questioning. Journal of Environmental Economics and Management 30: 112-131 Holmes T and Boyle K J (2005) Dynamic learning and context-dependence in sequential, attribute-based stated-preference valuation questions. Land Economics 81: 114-126 Hurwicz L (1972) On informationally decentralized systems. In: McGuire C B and Radner R (ed) Decision and organisation, North-Holland, Amsterdam KPMG  (2003)  Consumer  preferences  for  electricity  service  standards.  A  report  for  Essential  Services Commission of South Australia, September Laffont  J  J  and  Tirole  J  (1993)  A  theory  of  incentives  in  procurement  and  regulation.  Massachusetts Institute of Technology Press, Cambridge, Massachusetts Loeb M and Magat W (1979) A decentralized method for utility regulation. Journal of Law and Economics 22(2): 399-404 Lusk  J  and  Schroeder  T  (2004)  Are  choice  experiments  incentive  compatible?  A  test  with  quality differentiated beef steaks. American Journal of Agricultural Economics 86(2): 467-482 McFadden  D  and  Leonard  G  (1995)  Issues  in  the  contingent  valuation  of  environmental  goods: Methodologies for data collection and analysis. In: Hausman J A (ed) Contingent Valuation: A Critical Assessment, North-Holland, Amsterdam McNair B (2009) House prices and underground electricity distribution lines: the case of three selected suburbs  in  Canberra.  Occasional  Paper  #13,  Environmental  Management  and  Development, Crawford School of Economics and Government, The Australian National University Mirrlees J (1971) An exploration in the theory of optimal income taxation. Review of Economic Studies 38: 175-208 NERA and ACNielsen (2003) Willingness to pay research study. A report for ACTEW Corporation and ActewAGL, September Plott  C  R  (1996)  Rational  individual  behavior  in  markets  and  social  choice  processes:  the  discovered preference hypothesis. In: Arrow K, Colombatto E, Perleman M and Schmidt C (ed) Rational foundations of economic behavior, Macmillan, London Racevskis L and Lupi F (2008) Incentive Compatibility in an Attribute-Based Referendum Model. Paper presented at American Agricultural Economics Association Annual Meeting, Orlando, FL, 27-29 July Rose J M, Hess S, Bliemer M C J and Daly A (2009) The impact of varying the number of repeated choice observations  on  the  mixed  multinomial  logit  model.  Paper  presented  at  European  Transport Conference, Leeuwenhorst, The Netherlands, 5-7 October Samuelson P A (1954) The pure theory of public expenditure. Review of Economics and Statistics 36: 387-389 ____ (1956) Social indifference curves. Quarterly Journal of Economics 70(1): 1073-1094 Satterthwaite  M  A  (1975)  Strategy-proofness  and  Arrow's  conditions:  Existence  and  correspondence theorems for voting procedures and social welfare functions. Journal of Economic Theory 10(2): 187-217 Scarpa R and Rose J (2008) Design Efficiency for Non-Market Valuation with Choice Modelling: How to Measure it, What to Report and Why. Australian Journal of Agricultural and Resource Economics 52(3): 253-282 Scarpa R, Thiene M and Train K (2008) Utility in willingness to pay space: a tool to address confounding random  scale  effects  in  destination  choice  to  the  Alps.  American  Journal  of  Agricultural Economics 90(4): 994-1010 Scheufele G and Bennett J (2010a) Effects of alternative elicitation formats in discrete choice experiments.",
            "cites": null
        },
        {
            "id": 15675380,
            "title": "Probabilistic influence and supplemental benefits: a field test of the two key assumptions behind using stated preferences.",
            "authors": [],
            "date": "2006",
            "doi": null,
            "raw": "Environmental and Resource Economics 37: 181-210 Carson R T, Groves T and List J (2006) Probabilistic influence and supplemental benefits: a field test of the two key assumptions behind using stated preferences. Manuscript, Carson R T, Groves T and Machina M J (1997) Stated preference questions: context and optimal response.",
            "cites": null
        }
    ],
    "sourceFulltextUrls": [
        "http://purl.umn.edu/59102"
    ],
    "updatedDate": "",
    "yearPublished": "",
    "links": [
        {
            "type": "download",
            "url": "https://core.ac.uk/download/pdf/6407572.pdf"
        },
        {
            "type": "reader",
            "url": "https://core.ac.uk/reader/6407572"
        },
        {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/6407572/medium"
        },
        {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/6407572/large"
        },
        {
            "type": "display",
            "url": "https://core.ac.uk/outputs/6407572"
        }
    ],
    "abstract": "According to neoclassical economic theory, the only stated preference elicitation format that can feasibly be employed in field studies to which truthful response can be the dominant strategy for all respondents is a single binary choice between the status quo and one alternative. In studies where the objective is estimation of preferences for multiple attributes of a good, it is preferred (and, in some cases, necessary) based on econometric considerations, to present respondents with a sequence of choice tasks. Economic theory predicts that utility-maximising respondents may find it optimal to misrepresent their preferences in this elicitation format. In this paper, the effect on stated preferences of expanding the number of choice tasks per respondent from one to four is tested using a split sample treatment in an attribute-based survey relating to the undergrounding of overhead electricity and telecommunications wires in the Australian Capital Territory. We find evidence to suggest that presenting multiple choice tasks per respondent decreases estimates of total willingness to pay and that this effect is related to the ordering of cost levels presented over the sequence of choice tasks. Two behavioural explanations can be advanced - a weak cost minimisation strategy, which implies divergence between stated and true preferences, and a ‘good deal / bad deal’ heuristic, in which stated preferences reflect true preferences that change over the course of the sequence of choice tasks. Preferences stated in the first of a sequence of choice tasks are not significantly different from those stated in the incentive compatible single binary choice task. A key objective of future research will be to establish whether this effect becomes less prevalent as the number of attributes and alternatives per choice task are increased.Choice experiments, willingness to pay, incentive compatibility, strategic behaviour, order effects, underground electricity, Research Methods/ Statistical Methods,",
    "tags": [
        "preprint"
    ],
    "fulltextStatus": "enabled",
    "subjects": [
        "preprint"
    ],
    "oai": "",
    "deleted": "ALLOWED",
    "disabled": false,
    "journals": null,
    "repositories": {
        "id": "153",
        "openDoarId": 0,
        "name": "Research Papers in Economics",
        "urlHomepage": null,
        "uriJournals": null,
        "physicalName": "noname",
        "roarId": 0,
        "pdfStatus": null,
        "nrUpdates": 0,
        "lastUpdateTime": null
    },
    "repositoryDocument": {
        "id": 6407572,
        "depositedDate": null,
        "publishedDate": null,
        "updatedDate": "2014-10-24T12:43:31+01:00",
        "acceptedDate": null,
        "createdDate": "2012-07-06T03:45:13+01:00"
    },
    "urls": [
        "http://purl.umn.edu/59102"
    ],
    "lastUpdate": "2014-10-24T12:43:31+01:00",
    "setSpecs": []
}