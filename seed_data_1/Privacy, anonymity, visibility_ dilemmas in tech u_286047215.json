{
    "acceptedDate": "",
    "authors": [
        {
            "name": "Ganesh, Maya Indira"
        },
        {
            "name": "Deutch, Jeff"
        },
        {
            "name": "Schulte, Jennifer"
        }
    ],
    "contributors": [],
    "createdDate": "2020-01-05T04:24:20+00:00",
    "dataProvider": {
        "id": 603,
        "name": "IDS OpenDocs",
        "url": "https://api.core.ac.uk/v3/data-providers/603",
        "logo": "https://api.core.ac.uk/data-providers/603/logo"
    },
    "depositedDate": "",
    "documentType": "",
    "doi": "",
    "downloadUrl": "https://core.ac.uk/download/286047215.pdf",
    "fullText": "RESEARCH REPORT JULY 2016Maya Indira Ganesh, Jeff Deutch and Jennifer Schulte Privacy, anonymity, visibility:  dilemmas in tech use by  marginalised communities240Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities1 Making All Voices Count is a citizen engagement and accountable governance programme. It aims to harness the transformative potential of unusual partnerships and innovative applications of communication technologies to contribute to fundamental change in the relationship citizens have with the state. It focuses the majority of its work in six priority countries – Ghana, Indonesia, Kenya, the Philippines, South Africa and Tanzania. See page 40 for more information.AuthorsMaya Indira Ganesh has worked with the Tactical Technology Collective since 2010 and is the Director of Applied Research. She has a background in feminist activism, research and writing, and in media and technology studies. She is a doctoral candidate at Leuphana University, Lüneburg, Germany.Jennifer Schulte is a Human Rights Researcher and Sociologist with over a decade of experience working with human rights, aid and development organisations. She has led and advised on research and programme evaluations in 51 countries, and has facilitated training on responsible data, digital and holistic security, ethics and technology, gender-based violence prevention and response, and refugee child protection. Contact her via jenniferschulte.org, or at @schultjen on Twitter.Jeff Deutch is a Researcher at the Tactical Technology Collective and a Fellow at the Centre for Internet and Human Rights, Frankfurt (Oder), Germany. His research interests include the politics of data, online and offline privacy, and digital security as they pertain to marginalisation and social exclusion. CreditsEditors: Karen Brock (k.brock@greenink.co.uk) and Tim Woods (t.woods@greenink.co.uk), Green Ink Designer: Lance Bellers, lancebellers@btinternet.comAcknowledgementsThis work was supported by a grant from Making All Voices Count. It was conducted in 2014–15, and this report was prepared in February 2016, following external and internal reviews. We would like to acknowledge the participation of respondents in Nairobi, Cape Town and Johannesburg. We would like to thank Tanya Notley, Noortje Marres and Olumide Abimbola for their advice and support; Becky Faith and Nick Benequista for their reviews; and Koketso Moeti, Melissa Wainana, the Gay and Lesbian Coalition of Kenya, SERI South Africa, Sasha Kinney, Nick Hargreaves, Kate Tissington, Shireen Mukadam and Rumbidzai Dube for local research support and assistance. Questions about this project should be directed to Maya Ganesh: maya@tacticaltech.org Reference and copyrightIDS requests due acknowledgement and quotes from this publication to be referenced as: Ganesh, M.I.; Deutch, J. and Schulte, J. (2016) Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities, Brighton: IDS© The Institute of Development Studies 2016This work is distributed under the terms of the Creative Commons Attribution 4.0 International licence, which permits unrestricted use, distribution and reproduction in any medium, provided the original authors and source are credited. http://creativecommons.org/licenses/by/4.0/legalcodeFRONT COVER IMAGE: RESIDENTS OF THEMBELIHLE INFORMAL SETTLEMENT, SOUTH AFRICA, PROTEST AGAINST INADEQUATE SERVICES IN 2011/PHILLIP DE WET340Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesContentsExecutive summary 41. Introduction 52. The research: questions, context and design 6Putting the questions in context 6The flip side of technology in activism: the risk of exposure 7Unpacking visibility, anonymity, exposure and transparency 8Visibility: ‘being counted’ versus exposure 9Research design, methods and approaches 10Research design: Kenya 11Research design: South Africa 12‘Do no harm’ approaches to ethics and security in research 13Taking research back to the community 143. Research results: Kenya 15Being LGBTQ in Nairobi: the contours of marginalisation 15Social media practices and perceptions 16Using T4T&A tools to report violence 17Utunzi 18‘Speak out’ 204. Research results: South Africa 22The landscape of activism 22The housing list: applying T4T&A in movements and communities 23Technology practices among marginalised activists in Johannesburg 25Risks of and barriers to using T4T&A tools 26A lack of trust 275. Reflections and learnings 29Customise control over visibility: understand user practices 29Address differences across movements and communities of practice 31Put human rights first 33References 35440Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesExecutive summaryHow do marginalised communities use technology for transparency and accountability?This paper synthesises reflections and learnings from two studies, in Kenya and South Africa, about how marginalised communities – lesbian, gay, bisexual, trans  and queer (LGBTQ) people in Nairobi, Kenya, and economically marginalised housing and urban development rights activists in Johannesburg, South Africa – use technologies commonly applied in transparency and accountability work, and the limits of their use of these technologies. Technology for transparency and accountability (T4T&A) initiatives intend to make the public functioning of government visible, and states accountable to citizens for their actions. This research assumes that privacy and anonymity are important tactics for activists using technology, especially in transparency and accountability work that challenges institutions and authorities. However, privacy is practically impossible to maintain on popular, commonly available, proprietary platforms, many of which are deployed in T4T&A activities. Does this limit activists’ work with technology and if so, how? What are the other risks and barriers marginalised people face in their use of technology? Questions based on these concerns were clarified through formative interviews with 26 people, and fieldwork interviews with 37 people. The most significant reflections from both case studies are that: • marginalised users have different needs for privacy and security online, and T4T&A activities need to integrate these concerns • collaborations across and within technology and activist movements and communities must recognise their different histories of engagement with politics, technology and the state• without the full enjoyment of human rights, marginalised people’s participation in T4T&A activities is bound to be limited.540Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities1 Digital technology applications are increasingly popular tools employed in work around civic engagement, democratic participation and transparency and accountability in governance and public services. This is visible in open data and open knowledge movements, social media and map-based applications, and the combination of other open data, data journalism and visualisation for government transparency and public accountability.2  Maya Ganesh and Jeff Deutch worked on the Kenya research. Jennifer Schulte planned and conducted the fieldwork in South Africa, based on background work by Maya Ganesh who, with Jeff Deutch, also analysed the South African results and wrote the report findings. IntroductionThe Tactical Technology Collective (Tactical Tech) carried out two case studies that investigated how marginalised communities of activists in Kenya and South Africa use digital technology, and the limitations, risks and barriers they face in doing so. These studies were inspired by McGee and Carlitz’s questions about why the marginalised in a society do not use technology for transparency and accountability (T4T&A) applications1 – even if they have access to digital devices (McGee and Carlitz 2013). This report synthesises findings from the two studies, and frames them as reflections and learnings to inform future T4T&A activities.The two case studies are based on semi-structured fieldwork interviews with 37 respondents in two communities – lesbian, gay, bisexual, trans and queer (LGBTQ) people in Nairobi, Kenya, and economically marginalised housing and urban development rights activists in Johannesburg, South Africa2 – conducted over a six-month period. These two communities are marginalised by race, class, socio-economic status, gender and sexual identity – characteristics that overlap and intersect. The identification of fieldwork interview respondents, and the process and content of the fieldwork interviews, were shaped by 26 formative interviews with key informants in the two communities, carried out over the seven months preceding the fieldwork. The two case studies were initially focused on exploring the tension between anonymity and visibility for marginal populations online. They interrogated the anecdotal finding that increased online visibility for the issues faced by marginalised communities has the side effect of making individuals visible too – often to their detriment, because they are working in hostile local political contexts. The findings show that such individuals have a legitimate need for anonymity and privacy, because technology platforms do create negative exposure, but that threats tend to be local, lateral and personal, originating within families, communities and movements. This research confirms the nature and dynamics of this tension, and looks at the way that it affects use of digital technologies.The case studies refer to two very different communities in specific political, social, economic and historical contexts; thus they are not directly comparable, nor is that the intention of this report. Rather, it attempts to reframe what marginalised communities’ access to and use of digital technologies implies for T4T&A activities. It discusses the design and results of the research, before presenting a series of reflections to make sense of the findings in light of T4T&A activities. It also draws on conversations and inputs from members of both communities in Nairobi and Johannesburg who participated in outreach events in October 2015, where the study results were fed back for comment and discussion.640Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities2. The research: questions, context and designThe two studies this report is based on started with the observation that there is a tension between anonymity and visibility in the use of digital technologies: that while digital technologies – primarily social media and mobile phones – can help amplify and create visibility for marginalised activists’ issues, at the same time they make the activists themselves visible in ways that they often find they are unable to control. This inability to control their own visibility as activists presents risks to their work, particularly if their work deals with sensitive issues that directly challenge institutional power or corruption. The potential for different kinds of negative exposure were investigated in the context of technology use in activists’ work, and across the range of different risks and barriers they face. What did negative exposure mean for LGBTQ people in Nairobi, and low-income, black and mixed-race people working on housing and urban development rights in Johannesburg?The tension between anonymity and visibility is positioned within two broad frames of discussing T4T&A: the ‘open’ movement and T4T&A initiatives, which promote visibility and publicity for public information, public servants and processes; and the ‘data rights’ discourse, which is about anonymity and individual rights to privacy and freedom from surveillance. How are the two reconciled when the technologies that encourage openness and visibility – mobile phone-based applications, crowdmaps and freedom of information requests – also invite violations of privacy, and enable surveillance by their very architecture and technical specifications? Is there a middle ground between visibility and anonymity, and if so, how is it managed?Developing an argument based on this tension led us to frame it within the notion of risk to the work of marginalised people who are using technologies for transparency and accountability, as well as in their personal lives. In doing so, the research question expanded to look at how technology fits into the wider context of activists’ lives and into the political context of their activism, and what implications this has for activists’ engagement with T4T&A activities. Thus, this research has been developed in response to the question: how do digital technologies fit within the wider context of the lives of marginalised activists, and within the political context of rights in Kenya and South Africa, and what implications does this have for their engagement with T4T&A activities?To answer this question, the study addressed the following sub-questions:• How and for what purposes are marginalised activists using technology – personally, and in their activism?• How does this use vary according to socio-demographic differences within marginalised communities?• What are the risks and barriers marginalised activists face in using digital technologies in their transparency and accountability work?The following section provides context to these questions by describing the risks faced by activists in their use of technology. This is followed by a discussion of the different ways in which visibility, invisibility and anonymity can be unpacked in the context of transparency and accountability, and marginalised communities.Putting the questions in contextThis section provides a background to Tactical Tech’s work and how our engagement with activism informs our approach to these questions. We were curious about the limits of online activism enabled by digital technologies: how can citizens and governments engage in meaningful dialogue through technology when governments are actively persecuting or marginalising citizens through violence and criminalisation? What happens when these citizens are marginal in society and have few social safety nets and little social capital to protect themselves? How does their marginalisation play out in their use of digital technologies, and what 740The research: questions, context and designSection 23 “Mr Kaye observes that encryption and anonymity, separately or together, assist in shielding opinions from outside scrutiny (particularly important in hostile environments), empower individuals to circumvent censorship and other unlawful barriers to the free flow of information, and shield journalists, researchers, lawyers and civil society from unlawful surveillance and harassment. In this regard, encryption and anonymity provide individuals and groups with a zone of privacy online to hold opinions and exercise freedom of expression without arbitrary and unlawful interference or attacks” (Privacy International 2015).are the risks and limits to their use of technology? How can the promise of ‘visibility’ be unpacked to shed light on what it could mean for historically invisible communities?The flip side of technology in activism: the risk of exposureTactical Tech has been ‘bookmarking’ cases of how the Web 2.0 Internet is implicated in negative outcomes for activists and human rights defenders. Activists who are articulate and effective online can face a range of threats and harms from authorities, institutions and people they know who are threatened by their actions. Sometimes, activists, journalists and those working to expose corruption, injustice and violence in and by public institutions need to work anonymously to protect sources, whistle-blowers and themselves. This tends to affect people who are already marginalised in their societies most seriously. For example, the Kvinna till Kvinna Foundation’s work with women human rights defenders in precarious situations around the world documents the impact on them of online harassment and offline harms mediated through technology (Kvinna till Kvinna Foundation 2014).The struggle to control digital traces was an issue for activists in the Hong Kong protests of late 2014. For those protestors who had been underground for many years prior to the street protests, it was important to remain undetected; however, it was also an opportunity for these movements to become more active above ground. This tension was heightened by the promotion of a mobile phone application for activists to report on events on the ground, which was discovered to introduce malware into a user’s phone. Although a technology for transparency group, Code for Hong Kong, was named as having developed the application, they were not in fact responsible. Activists were therefore being spied on to track and record their movements and information (Boehler and Sam 2014).Jailed Egyptian activist Alaa Abd El-Fattah was awarded the Sakharov Prize for Freedom of Thought in 2014, but it was later rescinded when his tweets from two years prior were discovered, purportedly calling for ‘death to Jews’. It turned out that a selection of tweets about Zionist settlers   taking over Palestinian lands and the Israeli army’s attacks on Gaza had been taken out of context and misinterpreted (Muftah 2014).In the USA, the Los Angeles Times published the names of individuals who donated to support or oppose Proposition 8, an initiative in California to constitutionally define marriage as a union between a man and a woman (Minkhoff et al. 2014). By doing so, it exposed the people who cared enough to put money into supporting or opposing marriage equality, revealing their private affiliations before Proposition 8 went to the vote. One notable example of someone who got caught in the transparency net was Brendan Eich, the Chief Execuitve Officer of Mozilla, the company that makes the Firefox browser. His donation in support of Proposition 8 – against marriage equality (Ball 2014) – jarred with Firefox’s public image as an employer that supports LGBTQ equality in the workplace, as well as aligning itself with a pro-privacy position.Marginalised groups who become visible and identifiable may face a higher risk of offline violence or discrimination. For example, the Egyptian police uses Grindr, the dating application popular with gay men worldwide, to triangulate, identify and arrest LGBTQ users (Sheils 2014); similarly, in Lebanon, police are using WhatsApp to target and entrap gay men (Mamba 2014). Grindr recently removed its ‘show your distance’ option in response to privacy advocates raising concerns about the feature (Aravosis 2014), although it was later reintroduced.  In some countries, states are direct instigators of surveillance and the monitoring of activists and journalists. This raises the issue of the right to privacy and the importance of privacy in the work of activism, points recently made by Privacy International in their discussion of a report by the UN Special Rapporteur on Privacy, David Kaye.3 Serious forms of harassment, and the intimidation of activists and journalists by state and non-state actors is occurring around the world, in environments where activists, civil society organisations and non-governmental organisations (NGOs) are increasingly being criminalised (Ronan 2014); revelations by whistle-blower Edward 840The research: questions, context and designSection 2Snowden showed the world the scale of collusion between technology companies and intelligence agencies, and the use of surveillance on citizens globally. Across Africa, for example, there are significant levels of surveillance and monitoring of activists. The South African Right to Know network has a project and a recently published report on the monitoring and harassment of activists – some of whom were involved in the present study – by South African government intelligence (R2K 2015). The report indicates that there is an ongoing practice of creating informants within activist communities to get information.Citizenlab, a security research centre at the University of Toronto, Canada, found that surveillance malware developed by the Italian company Hacking Team was found in Ethiopia, Morocco, Nigeria, Somalia and Sudan (Marczak et al. 2014). In 2013, Angolan journalist and activist Rafael Marques was found to have been the target of surveillance by his government (Gunter 2014). Governments of some African countries are already censoring and monitoring citizen projects online, in addition to limiting freedom of the press and the protection of journalists (Sasaki and Rising Voices 2010).Thus activists engaged in progressive social change and justice work face risks associated with digital technology, from top-down surveillance to exposure through social media. This context served as a starting point and background for investigating the kinds of risks and barriers marginalised communities face in their use of technology in activism in Kenya and South Africa.Unpacking visibility, anonymity, exposure and transparencyThe two case studies are based on the argument that being unable to manage anonymity and visibility online is to risk exposure in the course of transparency and accountability work. Web 2.0 technologies, such as mobile applications, social media and maps – tools popularly used in T4T&A activities – do not guarantee privacy for the user, and therefore states or corporations that are threatened by use of these tools for transparency have the technical wherewithal to identify the citizens using them. This may pose more risks and liabilities for those who are already marginalised in their societies than it does for those who are more secure in their social status and social identity, limiting the use of applications for T4T&A activities. In order to develop some background to this, Tactical Tech wanted to unpack the idea of visibility through technology, alongside the movement for transparency through technology. In doing so, we found that the technical states of ‘visible’ or ‘anonymous’ can be considered along a continuum of visibility that has different symbolic and literal meanings for marginalised people, who seek to control and negotiate these states both online and offline. At first glance, visibility and transparency appear to be connected concepts. Transparency is to see through something that is otherwise opaque. The idea of ‘openness’ has also become associated with technology for transparency. Open data and knowledge are new technical tools that are believed to enable transparency. For example, a government department can be transparent when its functioning and practices are open to scrutiny; this may involve everyday, operational aspects such as the citizen oversight of government budgets, expense sheets and minutes of meetings. Dieter Zinnbauer (2012) questions this perspective when he suggests that technologies of transparency and openness allow governments to make claims that they are revealing their functioning, but may not actually be doing so. He uses the metaphor provided by parliament buildings, police booths or financial institutions in glass-fronted buildings. By opening up one part or aspect of government functioning, such as how international aid money is spent, others may become (or remain) conveniently obscured, such as the government’s purchase of malicious surveillance software to spy on citizen activists.Visibility, invisibility, transparency, openness and exposure are perhaps different philosophical and technical aspects of the demand for accountability from public institutions. They bear discussion because transparency is not an open-and-shut case. For example, it can have one positive or expected outcome in terms of government transparency, but mean something else for whistle-blowers who are at risk because they can be exposed by leaking information. We continue by describing some of these different aspects in the context of human rights defenders, activists and communities working on transparency and accountability issues.940The research: questions, context and designSection 24 In addition to not counting smaller ethnic groups, the final figures for the 2009 Kenyan census were never released. (BBC News 2009).5 Personal communication, Baerbel Heide Uhl, Berlin, Germany, March 2014.Visibility: ‘being counted’ versus exposureVisibility is about ‘being seen’ in the sense of being recognised or acknowledged, and hence ‘counted’. ‘Being visible’ is considered important because it allows the realities of injustice or violence against a particular marginal group or identity to be recognised and acknowledged. ‘Witnessing’ and documentation have therefore been two of the most popular and powerful ways in which digital technologies have enabled marginalised groups to make claims for rights and about rights violations. This is the intention of projects such as Harassmap, which provide evidence of public sexual harassment in Egypt, a topic that women do not readily discuss.Zanele Muholi’s years-long photographic documentation of queer black women in South African townships follows in this tradition of visibility as witnessing. Through intimate photographs, assembled into books and exhibitions called Faces and Phases, and more recently in 2015, Isibonelo: Evidence, Muholi’s work challenges the invisibility of this community, and raises awareness of the persistence of violence against queer black women in a country where homosexuality is legal.Another example of visibility as recognition or acknowledgement comes from Kenya. In 2007–08, post-election violence in Kenya was drawn along ethnic lines. While collecting ethnic data may pose the risk of exposing people from marginalised ethnicities by making them known, it also enables marginalised groups like smaller ethnic communities, which may not have been counted before, to be recognised.4 This means they can demand resource allocation and political representation (Nyambura-Mwaura 2009). Without such empirical evidence, these groups argue, it becomes almost impossible to document and monitor patterns of violence against them.Visibility can also imply exposure in a negative sense, of being exposed through mechanisms of surveillance that are embedded in institutional infrastructures. For example, in Europe, the migrant rights and sex-worker rights network KoK finds that continental databases like Euro-Sur are used to track and monitor movements of migrants into and through Europe.5 In Jordan, Syrian refugees are given cash handouts by the United Nations High Commission for Refugees only when they have had their irises scanned using a technology, Iris Guard, purchased by by the Cairo Amman Bank which administers the handouts (Vrankulj 2014). What happens to the refugees’ iris data is not known at this point. But Tactical Tech has found that British and US intelligence personnel are on the advisory board of Iris Guard.Marginalised communities have not only been the targets of surveillance, but also the community on whom social surveillance technologies are usually tested (Eubanks 2014). Virginia Eubanks’ work in the USA shows that concerns around visibility and surveillance are familiar to people who are socially marginal. Mothers on welfare, for example, get subsidies – but their spending is monitored by social service authorities who assume they will be wasteful, fraudulent or unreliable. People of colour invite surveillance through the Stop and Frisk programmes in New York City: “An analysis by the NYCLU [New York Civil Liberties Union] revealed that innocent New Yorkers have been subjected to police stops and street interrogations more than 4 million times since 2002, and that black and Latino communities continue to be the overwhelming target of these tactics. Nearly nine out of ten stopped-and-frisked New Yorkers have been completely innocent, according to the NYPD’s [New York Police Department] own reports” (NYCLU no date). At the same time, cameras worn by the police to monitor their interactions with people of colour have recently come to attention during considerations of the extent of police violence against this community (Stanley 2015).Worldwide, queer people as a marginalised group have historically been the subjects of surveillance as a way of identifying, naming, tracking and ultimately controlling them (Monahan 2009; Weeks 2000). At the same time, invisibility is part of the experience of being queer and amounts to not being acknowledged within society. In societies where being LGBTQ is criminalised, or where there is pervasive homophobia or transphobia, LGBTQ people have a need to remain undetected in the mainstream, but at the same time to remain visible to those that they would consider part of their own community. Tactics for passing as straight may include dressing and presenting oneself in a certain way, or having an opposite-sex partner to conceal one’s same-sex orientation. While passing for 1040The research: questions, context and designSection 2straight, a LGBTQ person may still use and respond to the speech and body language unique to their community. LGBTQ subcultures and communities around the world are also distinguished by unique terms, speech patterns and personal presentation styles (Tewksbury 1996). In the context of apartheid South Africa, visibility and invisibility were enabled by the application of bureaucracy as a technology of control and management. Here, an elaborate system of racial categorisation, fingerprinting, zoning, biometric identifiers of race, identity passbooks and over 160 laws were created to limit black and mixed-race people’s freedoms of assembly, movement, expression and association, and to deprive them of other human rights. These systems were fed and fired by a constant assertion of race; thus, anyone who was not white was made highly visible through these technologies, but at the same time made invisible in mainstream society because they were physically and symbolically excluded. Paul Edwards and Gabrielle Hecht present a rounded and complete picture of the ways in which narratives of technology and the development of national and social identity in apartheid and post-apartheid South Africa have had practical, material and symbolic outcomes:“The apartheid state aimed to manage its race-based identity registration – the hated passbooks and their related fingerprint databases – with computer technology, thereby muting the system’s oppressive character beneath a quest for bureaucratic efficiency through automation. Activists reacted by making the underlying technology itself an issue, connecting computers to military systems and political persecution by the police” (Edwards and Hecht 2010: 620). South Africa’s colonial and apartheid regimes were not the only ones to use technologies of bureaucratic management in this way. Michel Foucault coined the term ‘biopower’ to describe how modern nation states use various technologies, such as taxonomies and classificatory systems, to organise, manage and literally control large populations (Foucault 1976). Sharply honed as a tool of control in colonial contexts, European states used these tools at home to classify citizens, to identify those who were fit to drive modern industries and those who were unfit – the disabled, mentally ill, unwed mothers and other ‘social deviants’. Thus entire communities were created, by being made visible in this manner (Robertson and Travaglia 2015). The different ways in which visibility, invisibility, exposure and transparency intersect, sketched out in this section, raise two points for this research. First, the ‘tension between visibility and anonymity’ – implied by applications of privacy-enhancing technologies, or the risk of exposure through technology – is in fact only one aspect of this contradiction. For marginal and invisible communities, visibility is an important aspect of claims to rights and advocacy, and technology is a way of achieving this. But top-down bureaucracies that function to organise and manage society tend to make marginal communities visible and vulnerable. These perspectives form a backdrop against which to investigate the practices of marginal communities in using technologies, and how concerns about exposure, visibility, invisibility and anonymity play out in their own particular contexts.Research design, methods and approachesThe research used a qualitative methodology based on semi-structured interviews with a total of 37 LGBTQ activists in Nairobi, and housing and urban development rights in Johannesburg. Following formative, exploratory interviews in both cities prior to fieldwork, Tactical Tech developed an interview guide and sample determination exercises to ensure a robust sampling range. Tactical Tech does not work directly in either Kenya or South Africa, but has a history of partnerships, collaborations and networks with activists in both countries. While access to target populations was limited, these networks made it possible to sample potential respondents purposively through ‘snowball sampling’ – asking people we knew through pre-existing networks to refer us to others in their own networks. Respondents were therefore all associated with local, regional, national or international movements and networks. Moreover, given the sensitive nature of respondents’ work, which is sometimes confrontational to the state, we wanted to maintain a low profile and access our sample through known networks. There was a particular emphasis on ensuring that study respondents were not active users of T4T&A applications, in order to identify why this was so. However, what qualifies as a T4T&A application is up for question: is it custom-made, or based on mobile phone reporting, social media or 1140The research: questions, context and designSection 2crowdsourcing technologies? In the Kenyan context, it was harder to come across respondents who did not have access to any of these communication platforms: they were all familiar and in current use, with the exception of crowdmaps. In South Africa, there were more respondents from socio-economically weaker sections of society with less access to digital technologies, but every one of them was familiar with mobile phones and mobile applications.Research design: KenyaDesk researchAn initial review of background information on T4T&A included a review of the literature on information communication technology for development (ICT4D), as well as of the emerging T4T&A field. Literature concerning recent socio-political events in Kenya, and the status of LGBTQ rights, was closely followed during the research period. The close monitoring of popular discourses of transparency and accountability, technology, and LGBTQ rights issues was helpful in reflecting on and interpreting the analysis of research results.Formative interviewsIn October 2014, an exploratory visit to Nairobi was conducted with two objectives. The first was to carry out interviews with local respondents to clarify the research questions and methodology, to understand the context and ensure that the question was relevant, and incorporate feedback into project methodology and interview schedules. Sixteen interviews were conducted at this time with individuals from a range of organisations and backgrounds. More than half were associated with civic technology and T4T&A projects; the rest were a combination of activists from women’s rights networks, child rights networks, health and development NGOs, and LGBTQ networks.The visit revealed distinct class divisions within the NGO, civic technology and LGBTQ activist communities in Nairobi: it would be very easy to over-represent middle-to-upper class, educated gay men (and some lesbian women) from the city. During the exploratory visit, Tactical Tech was able to identify individuals and networks that could introduce them to working-class, female or trans respondents who would be less comfortable communicating in English. Interviews indicated the importance of taking an intersectional approach to marginalisation (Winker and Degele 2011); within this already marginalised community, the voices and experiences of working-class people, women and trans people tend to be hidden. As such, particular efforts were made to include these considerations in developing a sample that included as many different points of view as possible.The second objective of the visit was to identify networks of local respondents, potential partners and peers who could provide access to LGBTQ community networks beyond Tactical Tech’s existing networks, including points of access to reach the more marginalised. Gaining access to marginalised groups and building trust is often difficult, particularly for outside researchers and organisations. In some cases, funded NGOs and formalised activist groups are proxies for the wider community, and were a point of entry to locate marginalised populations. During the pilot visit, researchers were able to talk to local respondents about the best way of accessing a range of respondents; connections made at this time allowed us to develop enough trust to access these, making for a diverse sample. For this study, Tactical Tech partnered with a Nairobi-based umbrella organisation of smaller organisations throughout the country made up of, and / or representing the needs of, LGBTQ people in Kenya. The network provided logistical support in determining appropriate interview locations, and its reputation within the LGBTQ community was helpful in identifying potential respondents. However, the network was also seen by some as exclusionary and not representative of some sections of the community. To address this, researchers also met respondents through the networks of individuals outside the organisation. In this way, they worked to ensure adequate representation of all sexual orientation, gender identity and class groups.Sampling and sampleThe Kenya case study is based on responses from 20 individuals living in Nairobi, Kenya. The research did not explicitly ascertain their exact identities along the spectrum of LGBTQ, only that they closely associated with this broad and diverse community, either as individuals in a social network or as activists in paid and volunteer capacities. Respondents spanned a range of gender identities from male to female, were all aged between 18 and 40, and represented different socio-economic classes. The majority worked in voluntary or paid capacities in NGOs and LGBTQ coalitions, 1240The research: questions, context and designSection 2in addition to part-time work in other jobs; three women were college students, but there were also lawyers, film-makers, journalists, artists and self-employed people in the sample.Analysis is based on data from 20 fieldwork interviews. Sixteen formative interviews were also conducted, prior to fieldwork, both face-to-face in Nairobi and via Internet calls. This research was carried out between October 2014 (formative interviews) and March 2015 (fieldwork inverviews), with analysis and writing conducted between June and October 2015.Limitations of the studyLimited resources prevented primary research being conducted outside Nairobi. Although some respondents originate from outside Nairobi, and all efforts were made to interview a diverse sample with varied perceptions, there may be a bias in content analysis, with the experience of Nairobi residents over-represented. This, combined with a small sample size, implies that findings cannot be extrapolated for marginalised people outside the capital. Despite these limitations, the study methodology yielded important empirical insights, and the findings can be adopted to inform T4T&A interventions.Research design: South AfricaDesk researchThe research team conducted a review of the government transparency and accountability, T4T&A and ICT4D literatures. They also reviewed T4T&A projects in South Africa, and as part of the desk research, carried out three telephone / Internet call interviews with experts working on these issues in South Africa.Formative interviewsThe lead researcher travelled to South Africa in January 2015 to interview local experts, to shape the research questions and orientate the team in the current socio-political context. We listened to a range of opinions and experiences about technology applications for activism. Seven formative interviews were conducted during this trip, with an additional three via telephone / Internet calls. Respondents worked in parliamentary monitoring, citizen media and journalism, youth and education issues, housing and urban development rights, and freedom of access to information projects.Owing to scheduling issues, most of the formative interviews conducted at this stage were with people in positions of authority who were relatively privileged in terms of class and race. They did not reflect the intended sample, and therefore a specific effort was made to undertake a sampling exercise that would help identify a more diverse sample for the study. Nonetheless, some of the formative interviews resulted in insights borne of rich experiences of working with marginalised communities through applications of technology. The formative interviews also provided an opportunity to meet with a local research assistant and identify logistical, operational and security considerations for the upcoming research process.Sampling and sampleIn addition to the ten formative interviews described above, three more interviews were conducted with key female informants as part of a sample determination exercise; one of the respondents had already been interviewed. These three sample-focused formative interviews were with:• a Johannesburg-based white policy activist and researcher at a housing and lands rights policy organisation• a Johannesburg-based black T4T&A activist living and working in low-income communities• a Cape Town-based Indian-origin freelance security studies researcher and writer associated with the Right to Know movement.These sample-focused formative interviews were to determine the range of profiles of activists working in housing rights and urban development-related social movements. The results helped us identify socio-economically and politically marginalised organisations and groups, whose protests and dissent the government has tried to suppress. Weighing responses from our key informants, we developed a qualitative sampling strategy and purposively selected a range of profiles of Johannesburg activists, seeking maximum variation in perceptions and lived experiences. To that end, mixed purposive sampling approaches were used, including:• extreme-case sampling (identifying the extremes or poles of some characteristic and then selecting cases representing these extremes for examination)1340The research: questions, context and designSection 2• typical-case sampling (selecting what are believed to be average cases)• critical-case sampling (selecting what are believed to be particularly important cases)• negative-case sampling (selecting cases that disconfirm the researcher’s expectations and generalisations)• opportunistic sampling (selecting cases when the opportunity arises).The different kinds of activist communities identified through the sampling exercise allowed us to ensure that we were indeed reaching out to the marginalised, whose voices are rarely heard in mainstream media, public debates or government policy discourses. We focused mainly on the following types of key respondents from working-class, mass-based movements living in informal settlements often far from the city centre, and from formal NGOs or academia in Johannesburg’s main business district and city centre:• staff of NGOs and community-based organisations (CBOs) working on socio-economic rights and legal aid• CBO members• activists in the housing and socio-economic rights movements.We reached out to several people in each category to schedule fieldwork interviews, and received nine negative responses, for a range of reasons. For the final fieldwork sample, we interviewed 17 respondents from across all three categories.Sampling and data collection were strengthened by a local research assistant who is well trusted in both informal settlement communities and urban development NGOs, and who facilitated access to marginalised activists for fieldwork interviews in secure locations.Limitations of the studyAt the start of each formative and fieldwork interview, the researcher followed an informed consent process to ensure that respondents made a conscious decision on whether or not the transcript of their interview would be recorded. Eight respondents, concerned about potential inadvertent privacy and confidentiality risks, did not consent to recording, and these fieldwork interviews were documented through note-taking; nine consented to their fieldwork interview being recorded. Some explained that surreptitious recordings of activists speaking in group meetings have been later edited out of context, and published without consent in the press, attributing to them inaccurate and discrediting statements. Among the eight who did not consent to digital recording for transcription purposes, five were marginalised black women activists who have faced harassment and threats in the past for speaking out against rights violations and oppression.For the unrecorded fieldwork interviews, detailed notes captured key concepts and voluminous direct quotes. Still, the results of the content analysis and code frequencies could be marginally skewed as a result of a dataset that combines interview notes with full transcripts. It is unlikely, though, that the extent of skewing is substantively significant, as the results otherwise are reliable and valid given the sampling approach, variation in respondent perceptions, and triangulation of descriptions relevant to key elements of the research questions.‘Do no harm’ approaches to ethics and security in researchOne of the key aspects shaping the development of this research was the location and identity of the implementing organisation. As an organisation that has worked with activist communities for more than a decade, Tactical Tech is known for providing capacity building and training workshops around digital campaigning, privacy and security. This work has made the organisation sensitive to the implications of engaging and intervening in a community; therefore, the need to maintain relationships over time, in order to build and sustain networks, has become a part of its core values and practices. As a direct result of this, Tactical Tech had pre-existing networks of collaboration and trust in Kenya and South Africa. It has also been involved in supporting the practices of communities of activists around the world, in some cases dealing with sensitive experiences of safety, security and well-being.Such an organisation faces ethical considerations in the course of research. For example, if respondents are discussing risks and threats as an active, ongoing situation in an interview, how can the researcher use this knowledge without placing the respondent at risk? If a respondent mentions that she is struggling to manage her social media profile and is worried about social censure and 1440The research: questions, context and designSection 26 The complete research reports of each case study spell out the specific logistical steps undertaken as part of the ethical practice of doing research in these contexts.visibility because of social media, how should the researcher respond during the interview without diluting purpose or introducing bias?In this research, Tactical Tech also had to consider what publishing the findings might mean for (state and non-state) adversaries of LGBTQ people. Would publication inadvertently expose something about LGBTQ digital practices? As a consequence of internal and external discussions on these issues, this report does not include details that may risk exposing local respondents, their organisations and networks.Notley et al. (2015) find that developing an ethical framework and principles within which to evaluate NGO practices is complex, given the kind of work that NGOs do in close collaboration with groups over lengthy periods of time. Their action research evaluated the impact of video advocacy projects within a global network, Video for Change. They found that most measures of outreach tend to determine impact, whereas the processes and practices of video advocacy, participation and engagement with communities – and accountability to those communities – form a matrix of ethical issues in such work. They say:“This focus on defining the kind of participation that matters across the full video-making cycle critically differentiates Video for Change from more traditional forms of documentary practice, which often keep communities and social movements at arm’s length, either because they do not know how to engage people using participatory methods, or they do not value participation, or because they feel they want to fall in line with more traditional journalistic ethics in order to make claims about objectivity” (Notley et al. 2015: 10).For networks like Video for Change and Tactical Tech, relationships with communities are not kept at an objective distance; the strength of our work comes from participation, sharing and engagement. Tactical Tech has been funded to provide groups like those interviewed in this study with training and capacity-building support, and it is part of our organisational mandate to provide these services to communities around the world. Thus, accountability to these organisations and communities constitutes part of our ethical practice in this work.One of the principles which has been used in this study and other interventions at Tactical Tech is ‘do no harm’, a principle that emerged from conflict and post-conflict transformation work and is relevant to many community-based interventions and research. Do no harm involves working through the risks and opportunities presented by an intervention and prioritising the well-being and security of participants. The do no harm principle suggests that any intervention becomes part of the context it wants to change, and inadvertently produces negative impacts alongside the positive ones (Anderson 1999). The desire to minimise any potential source of harm and to maximise positive impacts was a guiding influence that shaped this study. In a practitioner setting, this approach – perhaps as one of many – serves as an ethical guideline in the absence of external ethical review boards or committees.The desire to minimise any potential source of harm and to maximise positive impacts was a guiding influence that shaped this study. Do no harm principles were applied in both research contexts in terms of physical and logistical considerations, and practices of data collection, management and analysis.6Taking research back to the communityOnce all the interviews were finished and draft versions of the two reports completed, in October 2015, Tactical Tech organised two day-long workshops Nairobi and Johannesburg with the communities and partners originally involved in the research. The events were organised in order to generate interest in the research, and to have the communities discuss and review the findings, helping to clarify content and verify the analysis. They were also an opportunity to bring together T4T&A actors in both cities with the members of the communities directly involved in the research, although many members of the T4T&A community were absent, despite invitations. 1540Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesBeing LGBTQ in Nairobi: the contours of marginalisationHomosexuality is still very much a taboo subject in Kenya. Surveys conducted by the Pew Research Center (2013) indicate that 88% of Kenyans view homosexuality as unacceptable, 3% find it acceptable, and the remaining 9% do not view it as a moral issue. This places Kenya among the ten countries in the world least accepting of homosexuality. LGBTQ people in Nairobi face physical violence, ostracism, homophobia, social exclusion, and structural and interpersonal discrimination. As part of this, the fear of blackmail, extortion and entrapment is justifiably high. The majority of respondents in this research hide at least some aspects of their lives, and the threat of being exposed is real and potentially deeply damaging.LGBTQ people in Nairobi face risks and barriers online connected to the barriers and risks they experience offline. While all LGBTQ people face marginalisation and discrimination in Kenya by virtue of the criminalisation of homosexuality, there are different levels of marginalisation within the community, stratified by ethnicity, class and gender. It is perhaps most relevant for those who are working class and do not enjoy the safety provided by social status and wealth; poverty is the factor that connects those respondents who feel most marginalised.However, marginalisation is also particularly relevant for lesbian, bisexual and queer (LBQ) women. When interviewed, many LBQ women spoke of the Kenyan LGBTQ space being dominated by gay men, and the relative invisibility they experience, both within the movement and in the few safe, public spaces that exist. Similarly, a growing trans movement has put the issue of trans invisibility and violence high on the agenda for the LGBTQ movement. One respondent said “everyone wants to see a Kenyan lesbian”, implying that both in the mainstream media and in activist circles, there exists a high degree of exclusion of LBQ women, and a sense that Kenyan lesbians might not even exist.Women respondents perceived LGBTQ issues in Kenya as often being framed in terms of the risk of HIV (human immunodeficiency virus) infection. As a result, men who have sex with men (MSM) and gay men are highly visible through a number of funded collectives, NGOs, CBOs and events. One LBQ respondent who spoke about this asked: “Is there one problem that all lesbians face?”, meaning that one easily identifiable problem – like the threat of infection by HIV – is perhaps what LBQ women in Kenya need in order to be visible. The problem ROBIN HAMMOND/PANOS PICTURES‘B’, a 32 year old gay man from Kenya, who fled to South Africa in fear of his life.The problem of invisibility itself is not visible: it lacks a particular hook or focus for funding or other supportive efforts.3. Research results: Kenya1640Research results: KenyaSection 37 However, one respondent flagged that there are still people, particularly in the slums, who remain outside of the social media bubble. While efforts are made on the part of activists and NGOs to reach them, the fact that they are not online can mean that they are not even aware that there are communities of people out there who are like them.of invisibility itself, she said, is not visible: it lacks a particular hook or focus for funding or other supportive efforts. This invisibility is compounded by the fact that, as other LBQ respondents pointed out, the fear of violence or negative consequences for being visible prevents them from being publicly known as LBQ. Recent documentation from Kenya (CAL and GALCK Kenya 2016), published after the fieldwork for this study was completed, describes the extent of violence faced by LBQ women, documenting the damaging effects of pervasive, structural and social homophobia and sexism. Though many LBQ women have been invited to speak in mainstream media forums, not one woman has chosen to respond, leaving the voice of middle-class Kenyan gay men to speak for all Kenyan queers. LBQ respondents in this sample made it a point to mention that for upper-class or wealthier LBQ women in Nairobi, who do not have to use public transport and can live in fairly homogenous and secure environments, the problem of invisibility was not the same.Social media practices and perceptionsWhile a vast majority of people in Kenya have mobile phones, the question of access to digital technology and social media presents itself in multiple and layered ways. Airtime is relatively cheap, but phones themselves may not be, and laptops and tablets remain out of reach for many people. Digital literacy is also an issue; the question is not just about having a phone or smartphone, but also how a person uses it, what they know about how it functions, whether they have the knowledge to make informed decisions about how to use it effectively and to feel sure of what is safe and what is not. Despite low digital literacy, respondents have evolved specific responses to managing and mitigating the threats they face.Given the criminalisation and high level of marginalisation that the LGBTQ community faces in Kenya, both from the state and from society, there is a tension between the necessity of maintaining individual anonymity in activism, and developing a visible community in resistance to the invisibility of LGBTQ people in Kenyan society.Fieldwork interviews showed that social media, primarily Facebook, was the most used and accessible online space for the LGBTQ community, where “everyone is connected – low income or high income”.7 Social media serves not just to connect people, but also to provide space for knowledge sharing and support. One respondent reported that “every day we pose a question [online] – whether it’s on substance abuse, violence, trauma from assault or whatever queer women in general are going through. We have created visibility that way.”However, while the use of social media is widespread, nearly all respondents maintain two accounts on Facebook because of high levels of lateral surveillance: a ‘straight’ account using their real name, where they connect with their family, straight friends and church community; and a queer account under an adopted name where they connect with others in the LGBTQ community. The use of an adopted queer name is widespread and may be used in offline contexts too – particularly while establishing trust in new relationships. Nevertheless, the two accounts can result in dangerous situations; respondents described being accidentally outed to their families after being tagged under their real name in a photo attending a LGBTQ gathering. Cases of surveillance also include family members actively seeking out queer accounts to expose users.Having two accounts requires a considerable degree of management and negotiation. LGBTQ Kenyans often use their adopted Facebook names “Every day we pose a question [online] – whether it’s on substance abuse, violence, trauma from assault – whatever queer women … are going through. We have created visibility that way.”1740Section 3 Research results: Kenyaboth in the online and offline contexts within the LGBTQ community; someone who meets a Facebook friend offline will only refer to them by their adopted name, not actually knowing the person’s real name. But LGBTQ individuals who come across the ‘straight’ account of an LGBTQ friend often will not add them as a connection. Harry explained: “I’ve seen my queer friends have two accounts, and I’ve gotten to see their straight account. I usually don’t add their straight account because they haven’t added me on it.” While the online world offers freedom as well as risks, respondents in the sample indicate that they create their own risk mitigation measures. These included particular methods for managing visual images online, captioning and tagging of visuals, admitting people into social media groups, and verifications of identity for admittance to parties. Some respondents indicated a careful use of privacy mechanisms. For example, Thomas said that LGBTQ people will not put photos of themselves as their profile pictures, that queer accounts more often have “pictures of random people, like Rihanna or whoever. You don’t use your face on that account.”The use of multiple social media accounts to escape exposure finds a parallel in Pakistan. Emrys Schoemaker finds a practice of multiple social media accounts among lower-middle income men and women in smaller towns in Pakistan where a practice of ‘digital purdah’ is used by men with two Facebook accounts to ‘protect their culture’; two accounts allow them to have one for male friends outside the family, and another account for family members (Schoemaker 2015). The rationale for these two accounts is that they do not want pictures of their female family members accessible to men outside the family. Women who are already segregated and in purdah actually remain there in the online world. So having two accounts, in both the Kenyan and Pakistani contexts, concerns people selectively hiding and revealing themselves because of social norms and values. However, this revealing and hiding only serves to maintain the status quo: both the Pakistani women who have been veiled, and the Kenyan LGBTQ people who have been closeted, remain hidden.The tension between anonymity and visibility is not just about being seen or not being seen. Visibility and anonymity take on different meanings depending on the context in which the digital is being used. LGBTQ people experience the digital both as personal individuals and as engaged, political actors and activists. There is a desire for personal anonymity to the hostile outside world, and visibility in participating in the local LGBTQ community; at the same time, there is a desire for visibility as a community and for LGBTQ rights through the medium of the digital, at the same time as a need for privacy as a community when it comes to offline events and activities.However, the study shows that anonymity is difficult to maintain. It demands attention and a constant awareness of the leakage of digital traces – through changes in the settings of social media platforms, and through the actions or inactions of others – and how these may put a user at risk of exposure. The social media platforms where these different states play out are unable to contain the shifting positions and needs of individuals to use and manage the technology they have access to.Discussion of social media platforms was dominated by Facebook. Twitter, for instance, is not as popular as platforms which connect only friends and known groups; it is perceived as being a tool to connect with communities that are global, and thus less interesting to the LGBTQ community here. Active Twitter use was mentioned by only one respondent, an activist working for a NGO and engaged in national, regional and international discussions on gender and sexuality rights. For others working in NGOs, Twitter was occasionally used to publish organisational updates.Using T4T&A tools to report violenceLGBTQ people interviewed in this study listed experiences of facing interpersonal violence, which they attribute to being socially ostracised and marginalised: ostracism or estrangement from family, street harassment for appearing different, bullying, assault, eviction from housing, public humiliation and shaming, corrective blackmail, extortion, sexual harassment at the workplace, and coercive sex. The threat of physical violence and attacks on LGBTQ NGO offices have led respondents to employ strategies to secure their physical spaces through the use of closed-circuit television at office entrances, physical security, sign-in / sign-out books, and so on.The scale and extent of this violence in a climate where there is no recognition of LGBTQ people’s 1840Section 3 Research results: Kenyarights makes reporting it extremely difficult. Study respondents said that there is no point in talking about these incidents or attempting to address them, because they do not trust any institution or individual to actually respond positively. Could anything come of reporting violence? The rest of this section describes the origins and reception of Utunzi and Speak Out, two T4T&A applications to report on violence faced by LGBTQ people.UtunziTwo Nairobi-based developers wanted to do something to support the LGBTQ community because of its relative invisibility in Kenyan society, and the fact that violence and discrimination against LGBTQ people often goes unseen or unnoticed because of a lack of empirical evidence. So they developed Utunzi, a crowdmap to report violence. Several hundred individuals submitted reports to the platform during Utunzi’s initial launch, but after this early interest the number of reports dwindled significantly. When investigating why individuals are not likely to use such a platform, several key issues emerged.No connection with the communityLGBTQ people sampled for this study – that is, potential users of Utunzi – were not even aware that it existed. There was limited sensitisation or capacity building within the LGBTQ community on how the platform works, or about why reporting violations against LGBTQ people is necessary. So, even if the tool was known, there were no mechanisms through which to engage the community and popularise the tool. Jeremy says:“In an ideal world, it’s best that it has organisations’ complete buy-in. Like right now I have a case, which I should have reported to Utunzi, but I didn’t report it … because I don’t even know if it exists anymore. So we need to have a space where people can know that immediately [when] you post something in this space, a solution comes on board. Even if it’s someone who is coming up with a tool, engage the organisations in developing it. And let them understand this is a space, then they will take up the responsibility to take it to the community members and tell them.”However, the developers and people associated with the project insist that there was discussion with the LGBTQ community. It is possible that the sample of respondents interviewed here were not connected to the developers or involved in their discussions with the LGBTQ community about the development of Utunzi. LGBTQ respondents in this case study were asked about their awareness of Nairobi’s thriving non-profit and social justice technology community; it was found that there was almost uniformly no awareness of this work or community. Through the research, and in the workshop held to share findings, it emerged that there was little or no connection between LGBTQ communities and the T4T&A communities. There is, generally, limited support for NGOs and activists in their use of technology.Also, LGBTQ respondents do not feel they have access to skilled and sensitive people that they can turn to for inexpensive solutions and support to meet their tech needs. For example, a member of a LBQ women’s art collective in Nairobi said that simple tech support to build a website that would not be trolled or defaced in any way was not available; they could pay for a commercial web developer if they had the money, but were uncomfortable sharing sensitive information such as administrative access to their infrastructure to someone who could be homophobic.An easier interface and accessibilityAs a web-based platform, Utunzi required individuals to use a computer, introducing an entry-level barrier. While many individuals in Kenya have a phone with a data plan, computer ownership rates remain low. Several respondents suggested that an app-based tool would be more effective and have higher uptake than a web-Individuals did not necessarily trust that the data they were submitting in a report would be used for the purposes stated on the website.1940Section 3 Research results: Kenya8 A popular mobile money transfer service in Kenya.based platform. Respondents also found the tool complicated, and said they need something easier. “For us it’s too complex. It needs to be simplified. As simple as possible. Not all of us are technologically ‘chop-chop’. It’s simplifying it. WhatsApp is very simple. You type something and it’s done.” Activists in this sample recommended a mobile app or an app-based hotline where users were not required to access a website, and could get an immediate response to an immediate crisis.Low trustRespondents in this sample said that there was a significant issue of trust associated with this, and similar platforms. The issue of trust plays out in the following ways.Individuals did not necessarily trust that the data they were submitting in a report would be used for the purposes stated on the website. Despite security measures put in place by platform developers, respondents felt that they did not know that data would be communicated securely. There was little indication of a known or trustworthy organisation behind the platform and, due to a culture of social stigmatisation, blackmail and extortion of the LGBTQ community, many people do not feel secure in sharing personal details. Alfie stated: “People are also very reluctant to post. This is because of the fear of backlash. If I post there and my friend who’s not gay sees, what will happen? He or she might start rejecting me. People are afraid the information might get out.”Similarly, another respondent, Grace, stated:“I know somebody who went through some sort of ... bad stuff happened to her and I tried to convince her to report it both using a tool and also to police but she was not willing to do it. I honestly don’t know why. Maybe they’re afraid that information will get somewhere out ... It’s virtual ... by the time you get there it’s already done. Nothing happens after that information is collected. It’s put in a basket. People feel like, what’s the point of doing it?”Respondents indicated a general sense of distrust with any kind of app or platform, with the exception of M-Pesa,8 and an overwhelming sense of scepticism for platforms addressing socio-political issues in Kenya. This finds resonance in a recent Global Consumer Trust Report, which found that in Kenya and other parts of Africa, user trust has declined in downloading and using apps because of the lack of protection for personal information and the threat of malware (MEF 2014).Although it was actually independently developed by two local technologists, only receiving support from an international organisation during its second phase of redevelopment, Utunzi was assumed by respondents to be funded by an international NGO. Many said that they were suspicious of the motivations and actions of international NGOs that engaged a community in a new project without anything positive accruing for individuals or the community. During the research we heard respondents asking what the benefits of participating in a research project would be for them or their community, on more than one occasion.Respondents said that those people who did submit reports to Utunzi – who overcame the obstacles of access, trust and awareness – did not receive any response from NGOs or platform administrators. When people did hear back, it was often many days later, long after the emergency had been addressed elsewhere. It is not surprising that responses were delayed; Utunzi was not structured as an emergency-response platform, even though users thought it was. So, there was a fundamental misconception about the purpose of this crowdmap. The lack of response from NGOs and organisations maintaining Utunzi further damaged trust in this platform. One respondent likened the platform to desks at police stations for reporting gender-based violence: a good idea in theory but not in practice. While present at all police stations, ‘gender desks’ are seldom used due to victims feeling that police do not take reports seriously or do not adequately follow incidents up after they have been reported.Utunzi repurposedThe Utunzi example indicates that if the violence faced by LGBTQ people were to be addressed through a crowdmap, it would require far more engagement with the community and its networks; interfaces need to be easy to navigate and there needs to be an assurance of impact and beneficial outcomes for individuals. These learnings were shared with a funding organisation that implements projects for and with LGBTQ networks in Kenya. At the time of conducting fieldwork in Nairobi, a fieldwork interview was conducted with the project 2040Section 3 Research results: Kenya9 ‘Speak out’ is not the real name of the platform. Information requests about the service can be directed to Maya Ganesh at Tactical Tech.manager, George, who works at an international donor agency that is managing the redevelopment of Utunzi, and has a history of working in LGBTQ NGOs. The donor organisation George works for has been supporting an emergency response project for coalitions serving LGBTQ communities on the border with Uganda. Following the criminalisation and active persecution of LGBTQ people there, there has been increased vigilance and anxiety on the part of Kenyan LGBTQ groups. This work, and reports from LGBTQ people in Nairobi, indicated a need for a coordinated emergency response to address the violence the community was facing and reporting. Emergency requirements in these cases include medical services, legal aid and psycho-social support and counselling. When it became clear that Utunzi was not working as a crowdmap for individuals to report violence, George and his colleagues took a decision to make it a specialised site for sending reports of violence to a network of vetted first responders. According to George, these revisions in Utunzi were intended to create an efficient response, not necessarily a direct response. Although the phone number called from or the Internet protocol (IP) address from which an online report is sent are logged, the full report of the case is not stored on the site’s servers. Information about a case will be carefully documented. The case will be verified by whoever within the network of first responders receives the call, to make sure it is legitimate. There is a roster of first responders, so if one cannot respond for some reason, there are others who can take on the case. Other changes to Utunzi include:• a focus on a specific region, with attention directed to supporting responders there• cases are documented more thoroughly, and data are analysed every month.The story of Utunzi offers some valuable lessons, the simplest and most critical of these being that technology applications for a community need to be developed in consultation with them and in response to their needs.Speak outOne of the other T4T&A projects that emerged from the Nairobi case study was ‘Speak Out’,9 a platform comprising a Facebook page and a Twitter feed. It was started by an individual whose identity is known to the LGBTQ community in Nairobi, but who was not interviewed for the research. Thus, this research reflects on Speak Out through interviews with its users and supporters. Speak Out was developed through technical support and strategic development with an international NGO and therefore is not as entirely ‘homegrown’ as some respondents described it. Closeted MSM (men who have sex with men) and gay men are particularly vulnerable to blackmail and extortion. The internet – social media, dating sites and mobile dating apps like Grindr – is a popular way for MSM and gay men to meet each other away from the gaze of mainstream society. Blackmailers and extortionists also spend time on these sites posing as potential dates, sexual partners or lovers. It is common practice to talk for a while online, sharing seemingly benign yet sensitive personal information such as occupation, address, personal details before meeting in person. Meeting in person is considered to be more revealing; graduated anonymity is considered to be a protective mechanism that closeted gay men / MSM have employed for their own security.However, this is an instance of a security tactic that can backfire: blackmailers use this extended period of online communication to extract information about a gay man / MSM. When blackmailers (often part of an organised gang) believe they have enough information, they reveal their real intention: extortion. They threaten to out the individual to his family or employer unless they pay. Respondents described their friends (never themselves) as sometimes being caught in the act as blackmailers burst into the room, or out of the closet, taking photos on a phone. These photos and the online exchanges are used as leverage for blackmail.One human rights lawyer interviewed here who represents LGBTQ people said that the most common cases they get are of blackmail, and that being underground and closeted is extremely dangerous for gay men / MSM. Those gay men / MSM who are open about their sexuality are less likely to be blackmailed, although it is not uncommon to face other forms of discrimination and /or violence.Thus the approach of Speak Out is simple: given the scale of blackmail and extortion suffered, 2140Research results: KenyaSection 3particularly within the closeted gay community, Speak Out serves to expose the extortionists. Described as an online platform to monitor human rights abuses against sexual and gender minorities, Speak Out invites people to submit the names and addresses, handles and online aliases of blackmailers and extortionists which, after careful verification, are then published on Speak Out’s pages as a warning system for other closeted gay men. Speak Out also verifies and documents cases of violence against the LGBTQ community. It is well respected within that community and by the respondents. It serves as a symbol of resistance that is based on familiar, known platforms and provides an active service to the community, allowing them to secure their own online and offline spaces.ConclusionsBoth Utunzi and Speak Out offer valuable insights into how the development and uptake of T4T&A projects have occurred in this community. Both were imagined as a response to the struggle to manage visibility and anonymity. In the case of Utunzi, a crowdmap was used to make violence visible, and this visibility was assumed to be key in claim for rights and acceptance in Kenyan society; however, the development of the project needed more investment in user research and the context of uptake by the LGBTQ community. Speak Out works in the opposite way, to expose the perpetrators of violence through the productive use of the online exchanges and materials that are used to extort and harass a vulnerable community.Speak out serves as a symbol of resistance that is based on familiar, known platforms and provides an active service to the community, allowing them to secure their own online and offline spaces.2240Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities4. Research results: South AfricaThis section presents results from the case study of how marginalised communities in South Africa engage with technology, and what inhibits them from using T4T&A tools. The findings are from fieldwork interviews with activists working on housing, land and urban development rights in Johannesburg, South Africa. This work is described here alongside a set of formative interviews in Cape Town, held five months prior to the fieldwork, with activists, lawyers and academics working on similar issues. Both the formative interviews and the fieldwork interviews presented diverse and rich insights into technology usage and applications across a broad continuum of actors; it is for this reason that they are presented here together, and both inform the analysis of the findings from South Africa. The results describe the particular instance of how communities of activists use Freedom of Information Act requests to obtain ‘the housing list’, and what this means for a broader view of T4T&A activities. They also describe how low-income communities use technologies in mobilising and organising, and the issues of trust, violence and marginalisation that emerge from this.The landscape of activismIn the landscape of South African activism and engagement with housing and urban development issues, a rich tapestry of this country’s history of struggle emerges. One of the findings from the formative interviews is that within the social movement for housing and urban development rights, activists can be clustered according to their socio-economic status, age and location, reflecting differing histories of privilege and oppression. This grouping helps contextualise diverse activists’ perceptions of the uses and practices of technology in their daily lives and activism. Both the formative and fieldwork interviews served to define the different kinds of actors in this space, which include: ‘NGO activists’, ‘legal NGOs’, ‘urban development NGOs’, ‘housing researchers’, ‘old-school land rights and housing activists’ (as opposed to A drone-mapping image of Kya Sands informal settlement (right) and Bloubosrand suburb, Gauteng, illustrating the spatial dynamics of housing inequality in Johannesburg, South Africa.JOHNNY MILLER / MILLEFOTO, WWW.UNEQUALSCENES.COM2340Research results: South AfricaSection 4‘younger activists’), ‘mass-base NGOs’, ‘community development forums’ and ‘building committees’.What this diversity of actors implies is that the practices, uses, risks and barriers of using technology are specific to each group, serving different functions in each case. The class, racial, ethnic and gender backgrounds of individual activists determine what their engagement with technology and activism is, and what sorts of approaches they will adopt. Those who work in formal NGOs engaged in ‘development’ in the urban setting position themselves and function quite differently from those in working-class movements based in informal settlements. The sample also includes older and younger activists, and the most distinctive aspect of this age divide is that the older activists all have a history of being involved in anti-apartheid struggles, which shapes their perceptions and practices concerning technology use. Respondents noted distinctions between their two cities, saying very pointedly technology projects and data-based advocacy manifest differently in Cape Town and Johannesburg. Johannesburg respondents perceived NGO activists in Cape Town, many of whom are white, to be more data savvy and technologically advanced, and to be using open data. Two linked interactions during the formative interview stage of the research revealed some of these differences in geography, race and class. In Cape Town, a Right to Know advocate said in a formative interview that “secrecy has destroyed South Africa ... We need to end secrecy and everyone and everything should be transparent … No one should be invisible … Privacy should only be for journalists and their sources who need to be protected.” When pushed to clarify, he said that he believed that privacy was not essential to other activists.This quote, with the identity of the source withheld, was presented to a different respondent in a formative interview. The respondent in this interview was a black woman activist in Johannesburg, a passionate champion of applications of technology for social justice. She told her story of coming from an impoverished province and working to expose corruption and injustice. Her house was burnt down for blogging about campaigns against corporations; she has been threatened for writing about whistle-blowers. She was scathing about the idea of complete transparency. “Complete transparency is a nice idea for white men in the suburbs ... Whiteness protects people in South Africa and it is a white lens through which this idea of transparency is seen. It is also a gendered lens … I need to speak anonymously sometimes.”These divisions were not necessarily discussed in a negative sense; rather, respondents used them as a way of pointing out that it is important not to view either activists or movements as monolithic, and that T4T&A activities must be sure to engage with the right kind of actors. If they do not, there is the risk of launching activities in communities that are not well resourced, and do not have either the capacity or the support to engage in activities.The housing list: applying T4T&A in movements and communitiesSouth Africa has a progressive constitution that guarantees housing to its citizens, along with the right to services, to not be evicted, and to be free of arbitrary searches that were common during apartheid. However, while the state is responsible for providing housing for its citizens, it falls short of meeting this responsibility. According to academic Marie Huchzermeyer (2013), the 2013 UN Habitat report ranks Johannesburg as the world’s most unequal city, and the number of shacks and informal settlements is only continuing to grow. During apartheid, communities were forcibly removed from their places of residence and had to live with others of the same race. While the post-apartheid era has brought de jure equality to South Africans, the state’s neoliberal policies continue to sustain economic inequalities, particularly across racial lines. In South Africa, the state has failed to provide housing or do away with corruption, and there is a lack of transparency in housing allocation, spatial inequality, an absence of pro-poor planning and insecurity of tenure.Three of the formative interviews discussed ‘the housing list’, which describes the schedule and order of housing allocations, and is considered to be a kind of holy grail for housing-rights activists because it can be used to monitor the state practice in allocating housing to citizens. These interviews highlighted the structural and philosophical issues about applying technological tools to support housing claims. 2440Research results: South AfricaSection 4The housing list is particularly relevant and important for households and whole communities that have been evicted (‘temporarily relocated’) and must wait for permanent housing to be allotted to them. Lawyers working with such communities in Cape Town use paper-based freedom of information requests, known as PAIAs (Promotion of Access to Information Act), both to identify when they can expect to be relocated and as a pressure tactic on the state that keeps them in temporary housing, sometimes for as long as ten years. The Right to Know movement is an active partner in this. One of the three respondents, a lawyer, said: “The understanding around housing delivery is that there is a ‘waiting list system’ which constitutes a housing queue, and that people must wait patiently until their name comes up in terms of a rational process of ‘first come, first served’ … This is why the list is important.” Once the list is finally made available, however, people find their names and details of new housing on it, but they also find that the actual process of allocation does not proceed rationally or logically. The respondent continues: “People have been on waiting lists, but their homes never materialise, or people who came after them [on the list] get houses first. So the focus tends to be on the immediate need (rightfully so), but at the expense of sustainably or meaningfully addressing the problem of housing ... The list isn’t everything.” Research from the Socio-Economic Research Institute of South Africa (Tissington et al. 2013) finds that the housing list and its promises of ordered and equitable allocation are a myth because of the array of opaque policies and bureaucratic details surrounding the list itself, which impede housing allocation, and government corruption.Respondents shared the learning that mechanisms to access information are just one, early stage in the process of housing allocation, but that they need to be integrated into campaigning, or used as a piece of a broader advocacy strategy. “Access is one thing, but then what?” asked another respondent, also a lawyer, before going on to point out that the step after access is legibility. This refers to the ability to make information part of a campaign, to use it strategically as leverage in engaging with a bureaucracy, and to understand how it works and where it comes from. There are people who know how to do this, and those who do not: the respondent described the difference between them as a “data divide”. Formative interviews underlined the importance of distinguishing between “intermediaries” who are considered to be more adept in the use of technologies, and “communities” who are seen as being on the “receiving end” of T4T&A applications and activities.When communities do have access to information with which to hold the government to account, the respondents discussed how it is difficult for them to engage with or negotiate with government actors: “Even if people do get access to technology and the information they need, they don’t really know how to engage with power.” To illustrate her point, this respondent took out her notepad and drew two circles on the opposite ends of the page. She labelled one ‘state’ and the other ‘community’. Within the circle representing the community, she drew some smaller circles. “Communities have gatekeepers, power centres,” she said, of these smaller circles. “How they make sense of information and technology is crucial.” She then drew even smaller circles, between state and community but closer to community, and labelled them ‘intermediaries’. “There is the mistaken assumption,” she said, “that putting some wires between states and communities will have them talking to each other.” She went on to note that for a community engaging with the state through its bureaucrats and functionaries, there is a learning curve to “talking with and through” data and technology. These two respondents also stated that there are assumptions underlying how a community will use the information and technology it has access to. If there is a data exchange with the state – perhaps taking the form of spreadsheets, maps, short message service texts (SMSs), statements or visuals – data is assumed to be something rational, that will be understood in a rational manner. But, said one respondent, “data only reveals patterns, and there is no piece of data that a community can actually use. It has to be made sense of by someone for them … Who is this someone?”This particular interaction must be read as a distillation of reflections from an intermediary support organisation working with low-income and marginalised communities, over a number of years, based on the use of different tools and information to hold local government to account. The interaction articulates the need for a theory of change to accompany the application of T4T&A 254010 In a workshop in Johannesburg in October 2015 where research results were shared, Wits University professor Indra de Lanerolle discussed the project and details such as the use of Unstructured Supplementary Service Data (USSD) codes to report information, which enabled users of legacy and ‘dumb’ phones to participate at no extra cost.Research results: South AfricaSection 4tools in community work, as well as highlighting the importance of recognising the dynamics of different communities and movements.There are examples of successful collaborations across different communities to learn from. For example, formative interview respondents referenced a strong example of collaboration, the Our Toilets Are Dirty mobile phone-based social audit of toilets in Khayelitsha township in Cape Town (Ukwazi 2014). This was significant because people associated with the audit felt that the collaboration was positive and beneficial, and there was an application of technology that was inclusive.10Technology practices among marginalised activists in JohannesburgThe fieldwork interviews in Johannesburg – with 17 activists who are from, or working with, low-income housing rights and urban development organisations – resulted in information about their technology use and practices, and the limitations and barriers they face in using technology. Mobile phones were reported to be the most widely used device for activism and community development work. However, airtime tariffs are particularly high in South Africa and only 62% of South Africans use a mobile every day; far fewer, just 22%, report using the Internet on a daily basis (de Lanerolle 2012). This is compounded by the fact that to get a mobile, it is necessary to have a registered address and identification, which poses a large barrier to undocumented migrants from neighbouring countries. Some respondents from NGOs viewed mobile phone use as “ubiquitous”, but responses from local community activists suggested otherwise.The same factors which place mobiles out of reach for some community members, place computers and tablets even further out of reach, particularly on an individual level. Instead, computers are associated with offices and tend to be used more in the context of NGOs than community activism. Computers may be accessed for specific purposes, such as research or emailing, but this is likely to require a trip into the city centre to an NGO office or Internet cafe. And access, even in this limited sense, is shaped along lines of gender and age. Email has very low levels of uptake in the activist community and is used more for official communication than for informal communications within a social group.While mobile use might be prevalent among activists themselves, members of low-income communities, especially women, have very limited access to mobiles; in some cases, women must ask community leaders – mostly men – to make calls for them, even in emergencies. Furthermore, unreliable electricity supply can mean that people are unable to charge their phones. Nevertheless, poorer, black activists often use phones to allow them to conduct meetings from afar, to avoid having to travel into the city centre, saving time and money. Voice calls, SMS and WhatsApp are the most used features for activism and organising, as well as to listen to and participate in local radio shows.WhatsApp is favoured by activists as it uses minimal data, and group chat features make it appealing for social organising and mobilising. It is also ‘reshaped’ for uses it was never created for, such as recording the minutes of group meetings and creating virtual newsrooms.Police that monitor these activist communities are aware that WhatsApp is popular and central to activists’ organising. Some respondents report that police claim to have intercepted activists’ WhatsApp messages and have told them so, resulting in a fear of surveillance. However, local experts claim that the police do not have the technical capacity for WhatsApp interception, and are only saying so to intimidate activists and obscure the fact that they rely on informants, which is not unusual in South Africa. A theme that emerged in discussions of the use of WhatsApp is that it is a space where movement dynamics and hierarchies are reinforced. Women activists talked about how community WhatsApp groups are used to make sexist or harassing comments. Community group leaders also use WhatsApp to play power games with senior leaders, publicly shaming them. This makes it difficult for other activists to engage, because they are reluctant to voice their opinions in group chats due to the fear of public shaming.Neither Facebook or Twitter were popular with this activist community. The cost of data is an issue and neither of these platforms were thought to be essential.2640Research results: South AfricaSection 4Risks of and barriers to using T4T&A toolsCost is one of the primary issues inhibiting our respondents’ use of technology. When asking about T4T&A applications, one respondent said “people would rather have airtime to contact you in an emergency than use it to report corruption”. Language is another issue. Respondents from low-income communities said that social media and T4T&A platforms tend to be predominantly in English, as well as perhaps Afrikaans and Zulu, but in a nation with 11 national languages, and where socio-economic divisions have implications for education and literacy, this can exclude large communities. Third, and linked to educational disparities and age, is the issue of digital literacy. Low digital literacy acts both in barring people from using tools as effectively as possible, and in preventing them from being able to assess the risks and possibilities of a particular tool.Respondents reported that violence occurs as a result of activists’ work being politically challenging and sensitive, and includes verbal and sexual harassment, physical attack, sexual assault, theft and destruction of data and devices, blackmail, and surveillance. According to the findings of this study, all forms of violence, including psychological, physical, sexual, economic and state-perpetrated, continue to affect black South Africans disproportionately.Police monitoring, crowd control and the excessive use of force against black working-class residents of Johannesburg’s informal settlements, continue to reduce activists’ capacities to participate securely in protest actions. A black male activist explained that police or informants may monitor activist events and “take steps to prevent the march, or sabotage the march, or try to prevent the march by harassing organisers, arresting them on spurious grounds, taking them out, or whatever”. Black activists in the informal settlements also expressed feeling mostly powerless to protect themselves in protests due to gaping power disparities between themselves and the police, noting repeatedly that they only have stones to try to protect themselves when a protest turns violent, while the police have guns and other firearms, and use them against protesters.South African activists’ concerns about ‘lateral surveillance’ (Andrejevic 2005) have to do with the fear of intimate partners, family, friends, comrades and informants infiltrating activist groups. One black South African male activist spoke about how some activists use intentional misinformation in WhatsApp groups to prevent police infiltrators or criminals from joining their demonstrations. While no respondent offered examples of actual instances that infiltration had occurred, many voiced fears that it could happen. One black male activist respondent gave the hypothetical situation of “venting my anger through WhatsApp or Facebook, then someone else with his / her own intention, having access to this [finger snap], can expose me that I’m in a very unstable marriage, and stuff like that”. Lateral surveillance of his personal communications could be used by infiltrators to discredit him as a movement leader. Fears of surveillance tend to be stronger among the older generation, particularly those in black and mixed race and poorer communities who experienced high levels of surveillance first-hand during the anti-apartheid resistance. Younger respondents and those working in NGOs tended to view digital risks more in terms of privacy than security. Fears of online surveillance push some younger activists to re-adopt ‘old-school’ techniques, including having sensitive meetings and conversations in offline spaces.Black women activists raised issues of sexual predation and harassment, not only by police and state authorities, but also in the CSOs where they work. A black woman activist who is well connected The cost of airtime inhibits the use of T4T&A tools: “People would rather have airtime to contact you in an emergency than use it to report corruption.”2740Research results: South AfricaSection 411 Respondents were referring specifically to a project by Code for South Africa and Ndifuna Ukwazi to use mobile phones to report broken toilets in the Cape Town township of Khayelitsha. The toilets were paid for by the government and were supposed to be maintained through local government support. The project encouraged citizens to report on broken toilets so that the information could be taken back to the government.to different communities in Johannesburg – from city-based development NGOs to slum-based popular movements – said that women working in CBOs, movement groups, networks and NGOs face daily risks of gender-based violence. Black and low-income women are more at risk, with fewer resources to respond to and recover from incidences of violence.In more conservative rural areas, women activists reported facing retaliation and social ostracism when reporting corruption, particularly whistle-blowing about land and housing allocation fraud. One black woman activist explained that “as a woman, to be outspoken can be so complicated. And also to implicate a man in corruption, you would be shunned.” She explained that traditional community leaders are sometimes in collusion with government officials or private sector companies in giving away land and selling houses meant for internally displaced people. For a woman to speak out against a man, and particularly one quite senior and respected within the community, was fraught with risk of serious repercussions. Women activists on community-based and activist WhatsApp groups tend to move from one-on-one chats to group chats due to receiving sexist comments from male activists in a one-on-one forum. Thus, there tends to be a perception that while WhatsApp is a useful organising and mobilising tool, it does not foster debate or discussion within a community.A lack of trustTrust, or the lack thereof, emerged as a theme that appears that impede the work of communities and movements. This is multifaceted. One aspect of this relates to the fact that people do not necessarily trust that the information they submit to a platform – such as, for example, a a platform for reporting broken toilets – will be handled in a way that is secure, transparent and free from corruption – or that it will actually have any visible impact.11Respondents also articulated the absence of trust in the government to respond to them, or that they will ever receive the basic services they deserve; they even described a lack of trust in their own movements and fellow activists. For example, their concerns include local government ward councillors’ duties and abuses managing administrative lists of government-provided housing applications: respondents felt there is corruption and opacity in the allocation of housing. Additionally, low-income respondents said that they do not trust that city and state authorities will respond in a timely manner, report corruption, or call for emergency help. Black activists interviewed here and living in informal settlements estimated that an ambulance might come only three or four times out of ten. They explained that they think emergency services workers are afraid to enter the settlements due to stereotyped media coverage of residents as troublemakers and criminals using gratuitous violence.Trust issues emerged in a different form for low-income respondents who had experienced the violent legacies of apartheid, and who continue to participate in the complex, ongoing, nationwide struggle to fashion a post-apartheid South Africa. For older members of this sample, this history puts them in a low-trust and oppositional relationship to the state, and they do not feel things have changed since 1994. It is not much different for younger members, who do not have the same historical experience yet feel they have not received their dues either in terms of resources, opportunities or People do not necessarily trust that the information they submit to a digital platform will be handled in a way that is secure, transparent and free from corruption – or that it will actually have any visible impact.284012 This is an ongoing movement of students and academics that began as protests against the increasing costs of university education for black and historically marginalised communities in South Africa. The University of the Witwatersrand in Johannesburg is a centre of coordinated activities (www.feesmustfall.joburg) as well as University of KwaZulu Natal, Durban University of Technology, Tshwane University of Technology and movements such as Rhodes Must Fall at the University of Cape Town.13 Rhodes Must Fall is a movement that started on the University of Cape Town campus with a demand to remove the statue of Cecil Rhodes; this was, however, part of a larger demand (which was eventually met) to dismantle the institutionalised racism in higher education in South Africa (http://rhodesmustfall.co.za/).14 Personal communication with Koketso Moeti (January 2016) and Achal Prabhala (January 2016). Research results: South AfricaSection 4rights as equal South African citizens. The strong ground-up student movement, Fees Must Fall,12 and the success of Rhodes Must Fall13 in 2015, are clear examples of their unhappiness at how, 20 years after the de jure end of apartheid, historically marginal communities continue to live in poverty and face discrimination. Media reports indicate that there have been violent clashes between students of the Fees Must Fall campaigns and police (Al Jazeera America 2015), and universities have brought in private security and threatened academic staff who are supporting student activism.14 The state’s use of violence to challenge the right of its citizens to protest, and the maintenance of secrecy and surveillance, indicates a mistrust of activism. This serves to shrink the space for activism and dissent generally, and this study documented this in the context of low-income and marginal communities around Johannesburg. An example is Thembelihle, a residential neighbourhood where citizens protesting lack of services have faced violence, and people’s protests have been actively repressed by authorities (Clark 2014). The attacks on and surveillance of protesting citizens of Thembelihle, and the activists of shack dwellers’ movements, point to the criminalisation of activists and movements.The incidents and experiences reported by respondents, and the current climate of activism in South Africa, point to deeply fractured communication between the state and citizens, which will have to be addressed, and rid of violence, before it improves.2940Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities5. Reflections and learningsThis section presents reflections and analysis based on the case studies to inform the strategies and approaches of communities engaged in T4T&A activities. The two case studies describe very different contexts. Bringing them together in this report does not imply similarities between them; rather, the intention here is to distil lessons from both and present them together, and to find points of similarity that reinforce learnings about applications of technology.The two case studies began as a question about how and if the inability to guarantee privacy and anonymity online introduced risks in marginalised activists’ use of technology tools in their advocacy and activism. As Seda Guerses notes, anonymity is an end rather than a means, which enables – among other things – participation, a collective voice and a distributed message (Guerses 2012). Tactical Tech’s work has shown that the use of mobile phones and social media has put activists, and marginalised communities, at risk. Yet limiting the risks of using technology is also complex and challenging, and requires particular skills and training. In framing a question around these concerns, this study began with activists’ technology use and the risks and barriers they faced, so as to contextualise it within their actual practices and realities of work on transparency and accountability in their societies.The two cases show that there is a legitimate need for anonymity and privacy, because technology platforms do create negative exposure; but that threats tend to be local and ‘lateral’ – that is, from within families, communities and movements. This research confirms the nature and dynamics of this tension for these communities and how it affects their use of digital technologies, and presents the following additional issues:• Low levels of trust between communities of activists and institutional authorities affect the kinds of dialogue intended to be inspired by T4T&A.• Marginalisation is reinforced and replicated within already-marginalised communities, perpetuating inequality and invisibility, and creating new centres of power.• Violence at interpersonal, community and social levels is a common feature of the lives of marginalised people; institutionalised and pervasive homophobia, sexism and racism also serve as barriers and limitations.• Social movements use technologies in organising and mobilising, and these can be a powerful way to motivate and reach out to marginal communities; movements are, however, shaped by their histories, and are complex, dynamic systems in flux. Thus, the introduction of technology is never straightforward, predictable or easy.• A significant gap exists between T4T&A communities and marginalised activist communities, and must be bridged if T4T&A applications are to be successfully integrated into social justice work.Customise control over visibility: understand user practicesThe documentation of marginalised people’s inability to control negative exposure online suggests that the language of openness, transparency and visibility needs to be rephrased with, and for, marginalised communities that may be facing a range of threats from being online. Something that is ‘open’ may on occasion need to be closed, and visibility may need to be restricted for those who are perceived to be threatening, or merely outsiders. The extent of the homophobia faced by LGBTQ Kenyans implies the need for security and privacy, yet there is also an equally strong need to connect with others in their community, to have a sense of community, a social, emotional and sexual life, and to be visible as activists who are engaged in political work around human rights. None of this is any different from what other activists do elsewhere in the world.Reviewing the tactics and approaches taken by LGBTQ Kenyans who are online, it can be said that anonymity and visibility are negotiated positions, constantly shifting in response to threats. Anonymity is intentional and purposeful in hiding to evade exposure, a tactic that is familiar to this community and continues offline and online. It is 304015 The work of the Women’s Rights Program of the Association for Progressive Communications since 2009 (http://erotics.apc.org/) and recent research from Women, Action and Media about harassment on Twitter (Matias et al. 2015); (http://womenactionmedia.org/cms/assets/uploads/2015/05/wam-twitter-abuse-report.pdf) are significant in this regard.16 Tactical Tech’s Security in a Box has custom ‘community guides’ available: https://securityinabox.org/en/lgbti-mena and https://securityinabox.org/en/lgbti-africa and https://securityinabox.org/en/women-hrdshope17 For example: www.defendingwomen-defendingrights.org/wp-content/uploads/2015/12/WHRD-IC-Gendering-Documentation-Manual-1.pdf and https://tech.safehubcollective.org/cybersecurity/ https://gendersec.tacticaltech.org/wiki/index.php/Main_Page18 There is recent work by Women, Action and Media, the Association for Progressive Communications and NGOs to directly lobby social media corporations to take a more active role in addressing online harassment and the restrictions on freedom of speech and expression online. Sustained advocacy against Facebook’s real name policy, and its questionable content-moderation practices, are already well documented and have been undertaken by various Internet governance and policy organisations.Reflections and learningsSection 5also a tactic to foster a sense of community. Those who work on direct support to LGBTQ people facing homophobic violence, and MSM or gay men who are closeted are more likely to face direct threats, violence or surveillance. For South African activists, the tension between visibility and anonymity has to be managed in the context of offline surveillance, primarily through the use of informants who report on fellow activists’ plans to the police. Protestors and the right to protest and dissent is particularly under attack in South Africa, notably in response to student-led movements. There is also a history of surveillance of activists that persists from the apartheid era and affects those who are especially vocal on state secrecy, housing issues, land redistribution and human rights (R2K 2015). Results show that communities appropriate and reshape technology to suit their own ends, such as the two-account tactic employed by LGBTQ Kenyans, or the use of WhatsApp to record meeting notes and mobilise by South African housing activists.Some technology skills development organisations and networks, of which Tactical Tech is one, support activists in learning about how to be secure and private in online communications. This can be invaluable for individuals or organisations facing surveillance and monitoring by governments or corporate actors. Particular tactics and digital skills may be required by women activists, journalists and advocates who face harassment and harm online; the harassment they face is explicitly gendered and sexualised.15 Tactical Tech’s work has also documented the need for particular tactics online and offline by marginalised communities, such as LGBTQ people in the Middle East, North Africa and Sub-Saharan Africa, and women human rights defenders and activists online.16 There has also been a mushrooming of similar projects and resources to mitigate the online harassment of women activists and journalists.17These resources and projects attempt to support marginalised groups online to be skilled in the control of their visibility and anonymity in their use of social media as a response to negative exposure: outing, harassment, revenge porn, threats and so on. Control and responsibility are both placed on the individual, a theme that privacy scholars may say is unfair at best and untenable at worst (Kazansky 2015). NGOs and policy advocacy groups are also working on influencing technology platforms to improve their functionalities to support freedom of speech and expression online.18 User research and use-experience design are important fields that recognise both the need for customisation of technology platforms and interfaces based on users’ particular contexts, as well as the ways in which users reshape technology platforms. Designer Caroline Sinders (2015), for example, is attempting to resist online harassment and violence through redesigning platforms.The redesign of entire platforms is not something that T4T&A advocates and technologists need to do. However, the development of technology applications does need to recognise user contexts, and users’ own productive reshaping of technology to meet their needs. T4T&A applications could also adopt user-experience research approaches and practices to understand individual community practices associated with technology use. The case of the crowdmap, Utunzi, underscores the Marginalised and activist communities appropriate and reshape technology to suit their own ends3140Reflections and learningsSection 5value of user research and understanding what kind of visibility a community needs and wants. Community participation in the technology development process is an obvious solution, but more valuable perhaps is a deeper appreciation of difference and diverse actors within a community, and their roles.As the South African case indicates, women are in greater need of controlling their visibility, and in some cases feel secure in speaking out under the cover of anonymity; it is very different for a white, male Right to Know activist to demand complete transparency than it is for a black, female, community-based housing activist. How can technology applications respond to the contextual differences between different groups of users, or within a group of users?It is also important for technologists to understand what is not working. Why did people start and then abandon a platform or tool? How can their patterns of use inform the development of future applications? Innovations to address infrastructural limitations associated with technology use and applications in resource-poor settings are now common; the two case studies indicate that personal, community and socio-technical contexts limit the use of technology – particularly social media – and this needs to be acknowledged and addressed as well.Address difference across movements and communities of practiceThere are limited connections between the different communities that work on T4T&A and the marginalised groups that participated in the two country case studies. Different approaches to change and rights evolve against varying historical contexts of discrimination / privilege, marginalisation / inclusion, and activism.An instance where the outcome of different communities working together was not positive – but was eventually turned around – was that of Utunzi. In parallel, there is the social media feed, Speak Out, that is for and about the LGBTQ community’s own needs for transparency and collective security. There is a note of pride in people’s voices, and a sense of community ownership, when they talk about it. It is an obvious statement that people from outside a community, who see a problem and create a solution for it without the engagement of that community, will often find that they solved the wrong problem.In the South Africa case study, the sampling determination exercise revealed the challenge in identifying a robust sample that was representative of the different communities working on housing and urban development rights. The list of actors in this space included policy researchers and academics to shack-dwelling activists. While this was a valuable input to the sampling process, it was also an important finding. Although there were exceptions, there was some segregation by race, class and city of different actors who might ostensibly be considered part of the same movement. Formative interviews from South Africa also strongly highlighted the role of intermediaries, often with reference to T4T&A actors who are involved in promoting civic technology applications for communities to engage with the state.Movements can offer a dynamic arena within which to engage with communities, but they also come with their particularities which must be factored in before engaging in T4T&A activities. Brendan Halloran and Walter Flores, writing for the Transparency and Accountability Initiative, introduce a series on movements and their role in accountability practices and activities (Halloran and Flores 2015), which suggests a ‘movements approach’ to transparency and accountability actions. Our research seems to support that, but with a careful consideration of the nature of The social media feed, Speak Out, is for and about the LGBTQ community’s own needs for transparency and collective security. There is a note of pride in people’s voices, and a sense of community ownership, when they talk about it.324019 Tactical Tech offered some reflections and lessons based on a two-year project with sex-worker communities in India and Cambodia that had to negotiate some of these issues (Slater et al. 2015) Section 5 Reflections and learningsmovements and to integrate with them sensitively given the many differences that exist within them.Movements are not monolithic and carry diverse histories, politics and communities within them. They also have their own power dynamics and create their own centres of power and margins, creating new contours of marginalisation. Both case studies show evidence of this, and of the particular marginalisation of women. Women and people identifying as women could be encouraged and supported to take on more leadership roles within movements as key actors in T4T&A activities, and with the recognition that this would be the first time for many of these individuals and groups to have this sort of agency.Fostering spaces for technologists and community-based advocates to work together and learn about each other could result in technical people learning more about the needs of communities for whom T4T&A applications are built, and for the development of custom solutions and community ownership on T4T&A projects. Technologists need to work in partnership with activist communities and movements in developing T4T&A tools that reflect the needs and experiences of proposed end-users. This could, in theory, increase the trust among potential end-users, and have a positive knock-on effect on the adoption and diffusion of T4T&A projects.This may, however, require the assimilation of very different approaches to technology, development, human rights, and transparency and accountability. How different communities come together and collaborate, despite the vast differences between them, is not an issue easily addressed in this discussion; however some connections are offered here.19 Andrew Schrock (2016) traces a history of ‘civic hacking’ in the USA, making connections between technology movements – such as ‘hacktivism’ – and transparency movements such as open data and freedom of access to information. He discusses the particular origins of ‘civic hacking’ and applications of technology to address the opacity of public institutions, and says that civic hackers are ‘Utopian realists’. How ‘Utopian realism’ merges with the human rights focus and local activisms of the marginalised actors interviewed here is beyond the scope of this discussion, but is a question that surfaces through the results. The distance between communities ‘on the ground’ and external ‘experts’ has an uncomfortable legacy, from colonial dominance and missionary work, to more recent development projects. Efforts to bridge communities must recognise these different histories, and the history of engagement with technologies in colonial times, and in post-colonial nation-building, and in moments of crisis, conflict and revolution. Miriyam Aouragh and her colleagues (2015) write about some of these entanglements between ‘activist’ and ‘techie’ movements by investigating web-based campaign sites that claim to bridge the existing gap between social justice activists and progressive techies. The authors “share[d] a curiosity about the pursuit of fundamental change that takes place at different political temporalities alongside techno-inventions” (2015: 209) and “attempted to develop a vocabulary and offer a snapshot that could help us attend to the naturalised divisions of labour and the delegation practices of technology that manifest themselves between activists for social justice and activists for just technologies” (2015: 229). They found troubling replications of universalist ideas about technology that concealed the politics and locations of different actors. They recommend vigilant critiques of these associations and of the languages, mechanisms and assumptions of change folded into them.The work of Kavita Philip, Lily Irani and their collaborators to develop “post-colonial computing” as a newer approach to digital divides, economic disparities and varying cultural epistemologies is another fruitful resource for T4T&A design and development projects (Irani et al. 2010; Philip et al. 2012).Philip, Irani and Dourish say that post-colonial computing is “a way of asking questions, a mode of investigating and a form of conversation ... an approach to familiar areas of research that could too easily slip into simple, rigid patterns, achieving closure and canonicity at the expense of discovery and experimentation ”(2012: 21).The post-colonial computing discourse does not start with ‘development’, but is “centered on the questions of power, authority, legitimacy, participation, and intelligibility in the contexts of 3340Reflections and learningsSection 5cultural encounter, particularly in the context of contemporary globalisation” (Irani et al. 2010: 1). By re-reading the scripts of techno-scientific development projects, such as One Laptop Per Child, post-colonial computing approaches reformulate cultural difference positively as new, creative possibilities. This approach challenges dualisms of developed / underdeveloped, or traditional / scientific, and decolonises the production of knowledge about post-colonial locations. It suggests that computational design practices and approaches are created transnationally, in situ, rather than from predetermined, fixed locations of users and agentic designers; and evolve as a function of relationships between designers, developers and users, local contextual forces (Philip et al. 2012: 5–7). Philip et al. say that: “This assemblage includes not only the dreams of design but the messiness of manufacture as well. It links materials sourcing, the context of making, and legal regimes, with the historical fields of discourse that make computational design possible today. Just as STS [science and technology studies] has highlighted the need to examine the socially situated and contingent nature of scientific practice, so we want to draw attention to the dynamics and contingencies of design methods, in order better to understand how they might be subject to new forms of translation, transformation, and reconfiguration“ (2012: 6).The results of the Utunzi case and the use of PAIAs to get access to the housing list in South Africa, offer additional insights and reflections about how race, class and gender differences matter in applying T4T&A. The awareness of varying histories and ambitions should not be a gratuitous indulgence of difference per se; it should be used to productively shape and inform mechanisms for articulating shared, and divergent, theories of change through the application of T4T&A. Different ideas of change through technology and data originate in particular histories of engagement with the state; so, those who believe in ‘connecting citizens to states through wires and expecting them to talk to each other’ may need to verify these assumptions with target communities. Or, if certain users and practitioners within a movement require greater privacy than others, how can that be factored in?Schrock (2016) points out that within the historical evolution of civic hacking and the move from information to data in the transparency movement, the objective may well be the receipt of information from the state, but not a plan for what is done with that information, as respondents in this study have noted. He ends by saying that new mechanisms and approaches may be needed beyond just applications of technology, as has been discussed here:“Systemic social disparities are often intractable. The route to alleviate them has never been detachment or abandonment. Looking forward, we should pay attention to how data activism and advocacy might result in meaningful systematic change beyond the usual claims of ‘transparency.’ To fulfil the possibilities for meaningful social change hinted at in their history, civic hackers might have to coordinate around specific mechanisms for change and articulate a deeper sense of democracy than the language of technology provides” (Schrock 2016: 15).Put human rights firstResults from this paper are filtered into reflections on the need to engage users and user practices in the development of T4T&A applications; and to productively address the differences within and across movements in these engaged collaborations. However, this study concludes with the obvious statement that for such communities to be involved in T4T&A activities beyond organising, mobilising and developing a community identity, they need to feel more confident and assured that their engagement will result in positive change and not be penalised.The LGBTQ activists from Kenya, and the low-income black and mixed-race activists in South Africa, are in states of significant marginalisation, and criminalisation by the state. The facts of marginalisation and lack of rights cannot be ignored, and perhaps have to be the primary subject of T4T&A activities and engagement. This is not to suggest that T4T&A activities cannot happen until poverty or marginalisation are eradicated. Rather, it is to suggest that a government that may be transparent about aid flows or the repair of public toilets, yet does not address the violence against its queer citizens, or continues to use violence and surveillance 3440Reflections and learningsSection 5to squash dissent by marginalised citizens who simply need basic services, is an example of the selective transparency that Dieter Zinnbauer has spoken of. It is this institutionalised selective transparency that allows for the perpetuation of marginalisation in society; it is perhaps this selective transparency that should be the focus of T4T&A activities.There is a pervasive misconception about the benefits of technology in bringing about social change. Technology platforms do not bring about change themselves and quite often just replicate the inequalities and divisions which exist in the offline world. Nevertheless, many online tools are used within the community, and to great effect. While digital and Web 2.0 technologies have the ability to access or generate data that could hold governments to account, what is perhaps required is the ability to know how to use that data in advocacy and campaigning; it is not an end-point in itself. Marginal groups perhaps need to learn how to engage with information as strategic leverage in advocacy for their rights. Of course, for this to be successful, members of marginalised groups need to feel that their rights are respected and they will not be punished for demanding them.In a 2007 paper that reported on interaction with low-income, marginalised women living in a transitional home facility, Virginia Eubanks offered compelling insights to what it could mean for such people to use technology and become part of the “high tech equity agenda” (Eubanks 2007: no page). She used the concept of the digital divide and asked women in the facility what it would take for people like them, the ‘have-nots’, to become ‘haves’. Through a drawing exercise, the women created a vision of what it would take for them to become more active users of technology to address their marginalisation. None of these drawings were about building new skills or resources. The barriers they identified were structural inequality, systemic inequality, racial prejudice, greed, classism, economic exploitation, basic needs, education, and other social supports. The way to bridge the divide, Eubanks concluded, was not to focus on the users themselves, but on the structural inequalities they face. The women in the study recommended stronger networks that connected people to each other as a way of bridging a range of divides: social, economic and infrastructural. It was only through people’s connections to, and empathy for, each other that these women believed technology would have any valuable role. There is a pervasive misconception about the benefits of technology in bringing about social change. Technology platforms do not bring about change themselves. Quite often, they just replicate the inequalities and divisions which exist in the offline world.3540Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesReferencesAl Jazeera America (2015) Chaos at South Africa Parliament as Police Clash with Protesting Students, 21 October, http://america.aljazeera.com/articles/2015/10/21/south-african-police-students-clash-at-parliament.html (accessed 30 May 2016)Aouragh, M.; Gürses, S.; Rocha, J. and Snelting, F. (2015) ‘Let’s First Get Things Done! On Division of Labour and Techno-political Practices of Delegation in Times of Crisis’, The Fibreculture Journal 26: 208–235, http://twentysix.fibreculturejournal.org/fcj-196-lets-first-get-things-done-on-division-of-labour-and-techno-political-practices-of-delegation-in-times-of-crisis (accessed 3 June 2016)Anderson, M. (1999) Do No Harm: How Can Aid Support Peace or War? Boulder: Lynne Rienner PublishersAndrejevic, M. (2005) ‘The Work of Watching One Another: Lateral Surveillance, Risk, and Governance’, Surveillance & Society 2.4: 479–497, www.surveillance-and-society.org/articles2%284%29/lateral.pdf (accessed 3 June 2016)Aravosis, J. (2014) ‘“Grindr” Gay Smartphone App Turns off “Distance” Option in Face of Privacy Concerns’, AMERICAblog, 1 July, http://americablog.com/2014/09/gay-grindr-smartphone-app-turns-distance-option-privacy-complaints.html (accessed 3 June 2016)Ball, J. (2014) ‘Mozilla CEO Insists He Won’t Resign Over ‘Private’ Support for Gay Marriage Ban’, The Guardian, 2 April, www.theguardian.com/technology/2014/apr/01/mozilla-ceo-brendan-eich-refuses-to-quit (accessed 3 June 2016)BBC News (2009) ‘Kenya Begins Contentious Census’, 24 August, http://news.bbc.co.uk/1/hi/world/africa/8217637.stm (accessed 1 June 2016)Boehler, P. and Sam, C. (2014) ‘Fake “Occupy Central” App Targets Activists’ Smartphones with Spyware’, South China Morning Post, 1 October, www.scmp.com/news/hong-kong/article/1594667/fake-occupy-central-app-targets-activists-smartphones (accessed 3 June 2016)CAL and GALCK (2016) Research on the Lived Experiences of Lesbian, Bisexual and Queer Women in Kenya, Johannesburg: Coalition of African Lesbians; Nairobi: Gay and Lesbian Coalition of Kenya, https://issuu.com/galckkenya/docs/research_on_the_lived_experiences_o (accessed 3 June 2016) Clark, M. (2014) An Anatomy of Dissent and Repression: The Criminal Justice System and the 2011 Thembelihle Protest. Johannesburg: Socio-Economic Rights Institute of South Africa, www.seri- sa.org/images/Thembelihle_FINAL_web.pdf (accessed 3 June 2016)de Lanerolle, I. (2012) ‘‘The New Wave’: Who Connects to the Internet, How they Connect, and What they Do When they Connect’, South Africa Network Society Project, Johannesburg: University of Witwatersrand, www.worldinternetproject.net/_files/_Published/_oldis/413_wip_south_african_2012.pdf (accessed 3 June 2016)Edwards, P.N. and Hecht, G. (2010) ‘History and the Technopolitics of Identity: The Case of Apartheid South Africa’, Journal of South African Studies 36.3: 619–639Eubanks, V. (2014) ‘Big Data and Human Rights’, in S.P. Gangadharan (ed.) Data and Discrimination: Collected Essays, Washington DC: New America FoundationEubanks, V. (2007) ‘Trapped in the Digital Divide: The Distributive Paradigm in Community Informatics’, The Journal of Community Informatics 3: 293–318, http://ci-journal.net/index.php/ciej/article/view/293/318 (accessed 3 June 2016)Foucault, M. (1976) The History of Sexuality, Volume 1, Paris: Hachette3640Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesGuerses, S. (2012) ‘The Spectre of Anonymity’, Vous Etes Ici: The Online Guide to Seda-think, http://vous-etes-ici.net/wp-content/uploads/2014/02/SedaAnonymityMute.pdf (accessed 3 June 2016)Gunter, J. (2014) ‘Digital surveillance in Angola and Other “Less Important” African Countries’, Global Voices, 26 February, http://advocacy.globalvoicesonline.org/2014/02/26/digital-surveillance-in-angola-and-other-less-important-african-countries (accessed 3 June 2016)Halloran, B. and Flores, W. (2015) ‘Mobilizing Accountability: Citizens, Movements and the State’, Transparency and Accountability Initiative Think Piece, http://transparencyinitiative.theideabureau.netdna-cdn.com/wp-content/uploads/2015/05/Movements-and-Accountability-Final.pdf (accessed 3 June 2016)Huchzermeyer, M. (2013) ‘Humanism, Creativity and Rights: Invoking Henri Lefebvre’s Right to the City in the Tension Presented by Informal Settlements in South Africa Today’, Inaugural Lecture, School of Architecture and Planning, University of the Witwatersrand, 12 November, http://abahlali.org/wp-content/uploads/2013/11/Marie.lecture.pdf (accessed 3 June 2016)Irani, L.; Vertesi. J.; Dourish, P.; Philip, K. and Grinter, R.E. (2010) ‘Postcolonial Computing: A Lens on Design and Development’, Proceedings of the ACM Conference on Human Factors in Computing Systems CHI 2010, Atlanta, Georgia, 1311–1320, www.dourish.com/publications/2010/chi2010-postcolonial.pdf (accessed 24 June 2016)Kazansky, B. (2015) ‘Privacy, Responsibility and Human Rights’, Fibreculture Journal 26: 189–207, http://twentysix.fibreculturejournal.org/fcj-195-privacy-responsibility-and-human-rights-activism (accessed 3 June 2016)Kvinna till Kvinna Foundation (2014) Femdefenders: The Hatred against Women Human Rights Defenders Online and Offline, Johannesburg: Kvinna till Kvinna Foundation http://kvinnatillkvinna.se/en/files/qbank/d863d5ec458b0dc3b46cba96d9d49ac3.pdf (accessed 3 June 2016)Mamba (2014) ‘Police Using WhatsApp to Entrap Gay Men’, Mamba Online, 28 August, www.mambaonline.com/2014/08/28/police-using-whatsapp-entrap-gay-men (accessed 3 June 2016)Marczak, B.; Guarnieri, C.; Marquis-Boire, M. and Scott-Railton, J. (2014) ‘Mapping Hacking Team’s ‘Untraceable’ Software’, Research Brief, Toronto: University of Toronto Munk School of Global Affairs, https://citizenlab.org/wp-content/uploads/2015/03/Mapping-Hacking-Team%E2%80%99s-_Untraceable_-Spyware.pdf (accessed 3 June 2016)Matias, J.N.; Johnson, A.; Boesel, W.E.; Keegan, B.; Friedman, J. and DeTar, C. (2015) Reporting, Reviewing, and Responding to Harassment on Twitter, Cambridge, MA: Women, Action and the Media, http://womenactionmedia.org/cms/assets/uploads/2015/05/wam-twitter-abuse-report.pdf (accessed 3 June 2016) McGee, R. and Carlitz, R. (2013) Learning Study on ‘The Users’ in Technology for Transparency and Accountability Initiatives: Assumptions and Realities, Brighton: IDS, www.ids.ac.uk/publication/learning-study-on-the-users-in-technology-for-transparency-and-accountability-initiatives-assumptions-and-realities (accessed 3 June 2016)MEF (2014) MEF Global Consumer Trust Report 2015 , San Francisco: Mobile Ecosystem Forum, http://now.avg.com/mef-global-trust-report-2015(accessed 3 June 2016)Minkoff, M.; Moore, M.; Poindexter, S. and Welsh, B. (2014) ‘Proposition 8: Who Gave in the Gay Marriage Battle?’ Los Angeles Times, http://projects.latimes.com/prop8/ (accessed 3 June 2016)Monahan, T. (2009) ‘Dreams of Control at a Distance: Gender, Surveillance and Social Control’, Cultural Studies ↔ Critical Methodologies 9.2: 286–305 Muftah (2014) ‘Egyptian Activist, Alaa Abd El-Fattah, Penalized by Sarkhov Prize Nominating Committee for Speaking Out Against Israel’, 8 October, http://muftah.org/sarkhov-freedom-thought-prize-nomination-rescinded-egyptian-activist-alaa-speaking-israel/#.V3qBZZN97BI (accessed 3 June 2016)3740Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesNotley, T.; Lowenthal, A. and Gregory, S. (2015) Video for Change: Creating and Measuring Social Impact. Working Paper, Video4Change Network, www.v4c.org/en/impact_working_paper (accessed 3 June 2016)Nyambura-Mwaura, H. (2009) ‘Ethnic Question in Kenya Census Stokes Suspicions,’ Reuters, 25 August, www.reuters.com/article/2009/08/25/ozatp-kenya-census-idAFJOE57O0GP20090825 (accessed 3 June 2016)NYCLU (no date) Stop and Frisk Campaign: About the Issue, New York Civil Liberties Union, www.nyclu.org/issues/racial-justice/stop-and-frisk-practices (accessed 3 June 2016) Pew Research Center (2013) The Global Divide on Homosexuality, Washington DC: Pew Research Center, www.pewglobal.org/2013/06/04/the-global-divide-on-homosexuality (accessed 3 June 2016)Phillip, K.; Irani, L. and Dourish, P. (2012) ‘Postcolonial Computing: A Tactical Survey’, Science, Technology and Human Values 37.1: 3–29Privacy International (2015) Encryption and Anonymity Create a “Zone of Privacy” Online, says UN Special Rapporteur’, 17 June, https://privacyinternational.org/?q=node/600 (accessed 3 June 2016)R2K (2015) Big Brother Exposed: Stories of South Africa’s Intelligence Structures Monitoring and Harassing Activist Movements, Salt River: Right to Know, http://bigbrother.r2k.org.za/wp-content/uploads/Big-Brother-Exposed-R2K-handbook-on-surveillance-web.pdf (accessed 3 June 2016)Robertson, H. and Travaglia, J. (2015) ‘Big Data Problems We Face Today can be Traced to the Social Ordering Practices of the 19th Century’, LSE Impact Blog, 13 October, http://blogs.lse.ac.uk/impactofsocialsciences/2015/10/13/ideological-inheritances-in-the-data-revolution/ (accessed 3 June 2016)Ronan, E. (2014) ‘Kenya Shuts Down 500 groups in Anti-terrorism Crackdown’, Al Jazeera, 16 December, www.aljazeera.com/news/africa/2014/12/kenya-closes-down-hundreds-ngos-20141216124722577348.html (accessed 3 June 2016)Sasaki, D. and Rising Voices (2010) Technology for Transparency: The Role of Technology and Citizen Media in Promoting Transparency, Accountability and Civic Participation, Cape Town: Technology for Transparency Network, www.right2info.org/resources/publications/technology-for-transparency (accessed 3 June 2016)Schoemaker, E. (2015) ‘Facebook Domestication’, Tanqeed, July, www.tanqeed.org/2015/07/Facebook-domestication (accessed 3 June 2016)Schrock, A. (2016) ‘Civic Hacking as Data Activism and Advocacy: A History from Publicity to Open Government Data’, New Media and Society 1.19: 1–15Sheils, C. (2014) ‘Egyptian Cops Using Grindr to Hunt Gays’, CairoScene, 1 September, www.cairoscene.com/LifeStyle/Egyptian-Cops-Using-Grindr-To-Hunt-Gays (accessed 3 June 2016)Sinders, C. (2015) ‘I Was on One of Those Canceled SXSW Panels’, Slate, 29 October, www.slate.com/articles/double_x/doublex/2015/10/sxsw_canceled_panels_here_is_what_happened.html (accessed 3 June 2016)Slater, D.; Ganesh, M. and Martini, B. (2015) ‘Leave your Potatoes at Home: Working with Marginalised Communities on Using Data and Tech in Advocacy’, Visualising Information for Advocacy Blog, 17 April, https://visualisingadvocacy.org/blog/leave-your-potatoes-home-working-marginalised-communities-using-data-and-tech-advocacy (accessed 30 May 2016)Stanley, J. (2015) ‘Police Body-mounted Cameras: With Right Policies in Place, a Win for All’, American Civil Liberties Union, www.aclu.org/police-body-mounted-cameras-right-policies-place-win-all (accessed 3 June 2016)Tewksbury, R. (1996) ‘Cruising for Sex in Public Places: The Structure and Language of Men’s Hidden Erotic Worlds’, Deviant Behavior 17: 1–19Tissington, K.; Munshi, N; Mirugi-Mukundi, G. and Durojaye, E. (2013) “Jumping the Queue” Waiting Lists and Other Myths: Perceptions and 3840Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesPractices around Housing Demand and Allocation in South Africa, Johannesburg: Community Law Centre and Socio Economic Rights Institute of South Africa, www.seri-sa.org/images/Jumping_the_Queue_MainReport_Jul13.pdf (accessed 3 June 2016)Ukwazi, N. (2014) Our Toilets are Dirty: Report of the Social Audit into the Janitorial Service for Communal Flush Toilets in Khayelitsha, Cape Town, Cape Town: International Budget Partnership and Social Justice Coalition, http://nu.org.za/wp-content/uploads/2014/09/Social-Audit-report-final.pdf (accessed 3 June 2016)Vrankulj, A. (2014) ‘UNHCR adopts IrisGuard technology for refugee registration’, Biometric Update, www.biometricupdate.com/201402/unhcr-adopts-irisguard-technology-for-refugee-registration (accessed 3 June 2016)Weeks, J. (2000) Making Sexual History, Cambridge: Polity PressWinker, G. and Degele, N. (2011) ‘Intersectionality as Multi-level Analysis: Dealing with Social Inequality’, European Journal of Women’s Studies 18.1: 51–66Zinnbauer, D. (2012) ‘Fighting Corruption Where and When It Happens – Ambient Accountability’, in D. Offenhuber and K. Schechtner (eds) Accountability Technologies - Tools For Asking Hard Questions, Berlin: Ambra3940Privacy, anonymity, visibility: dilemmas in tech use by marginalised communitiesPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities4040About Making All Voices CountMaking All Voices Count is a programme working towards a world in which open, effective and participatory governance is the norm and not the exception. This Grand Challenge focuses global attention on creative and cutting-edge solutions to transform the relationship between citizens and their governments. The field of technology for Open Government is relatively young and the consortium partners, Hivos, the Institute of Development Studies (IDS) and Ushahidi, are a part of this rapidly developing domain. These institutions have extensive and complementary skills and experience in the field of citizen engagement, government accountability, private sector entrepreneurs, (technical) innovation and research.Making All Voices Count is supported by the UK Department for International Development (DFID), the US Agency for International Development (USAID), the Swedish International Development Cooperation Agency (SIDA) and the Omidyar Network, and is implemented by a consortium consisting of Hivos, IDS and Ushahidi. The programme is inspired by and supports the goals of the Open Government Partnership.Research, Evidence and Learning componentThe programme’s research, evidence and learning contributes to improving performance and practice, and builds an evidence base in the field of citizen voice, government responsiveness, transparency and accountability (T&A) and technology for T&A (Tech4T&A). This component is managed by IDS, a leading global organisation for research, teaching and communication with over 30 years’ experience of developing knowledge on governance and citizen participation.About Tactical TechTactical Tech is a non-profit organisation, working since 2003 to advance the use of information and digital technologies by advocates and activists worldwide. Based in Berlin, Tactical Tech works with an international network of partners and collaborators to help rights, accountability and transparency advocates and the communities they work with to use information and digital technologies effectively in their work, empowering them to effect progressive social, environmental and political change. Its work – developed out of a decade of direct capacity building worldwide – seeks to practically develop the specialised information and technology skills and strategies of those working to defend and advance fundamental freedoms and to advance critical thinking, methodology and best practice within the sector.Disclaimer: This document has been produced with the financial support of the Omidyar Network, SIDA, DFID and USAID. The views expressed in this publication do not necessarily reflect the official policies of our funders.Web www.makingallvoicescount.orgEmail info@makingallvoicescount.orgTwitter @allvoicescountImplemented by:IDS_Master Logo",
    "id": 286047215,
    "identifiers": {
        "doi": null,
        "oai": "oai:opendocs.ids.ac.uk:20.500.12413/12110"
    },
    "title": "Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities",
    "language": {
        "code": "en",
        "name": "English"
    },
    "publishedDate": "2016-07-15T01:00:00+01:00",
    "publisher": "'Institute of Development Studies - The Impact Initiative'",
    "references": [],
    "sourceFulltextUrls": [
        "https://opendocs.ids.ac.uk/opendocs/bitstream/20.500.12413/12110/4/TacticalTech_Online_FINAL3.pdf"
    ],
    "updatedDate": "",
    "yearPublished": "2016",
    "links": [
        {
            "type": "download",
            "url": "https://core.ac.uk/download/286047215.pdf"
        },
        {
            "type": "reader",
            "url": "https://core.ac.uk/reader/286047215"
        },
        {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/286047215/medium"
        },
        {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/286047215/large"
        },
        {
            "type": "display",
            "url": "https://core.ac.uk/outputs/286047215"
        }
    ],
    "abstract": "Making All Voices Count Research ReportThis paper synthesises reflections and learnings from two studies, in Kenya and South Africa, about how marginalised communities – lesbian, gay, bisexual, trans and queer (LGBTQ) people in Nairobi, Kenya, and economically marginalised housing and urban development rights activists in Johannesburg, South Africa – use technologies commonly applied in transparency and accountability work, and the limits of their use of these technologies.Omidyar NetworkSIDADFIDUSAI",
    "tags": [
        "Series paper (non-IDS)",
        "Rights",
        "Sexuality and Development",
        "Technology"
    ],
    "fulltextStatus": "enabled",
    "subjects": [
        "Series paper (non-IDS)"
    ],
    "oai": "oai:opendocs.ids.ac.uk:20.500.12413/12110",
    "deleted": "ALLOWED",
    "disabled": false,
    "journals": null,
    "repositories": {
        "id": "603",
        "openDoarId": 0,
        "name": "IDS OpenDocs",
        "urlHomepage": null,
        "uriJournals": null,
        "physicalName": "noname",
        "roarId": 0,
        "baseId": 0,
        "pdfStatus": null,
        "nrUpdates": 0,
        "lastUpdateTime": null
    },
    "repositoryDocument": {
        "id": 286047215,
        "depositedDate": null,
        "publishedDate": "2016-07-15T01:00:00+01:00",
        "updatedDate": "2024-02-11T02:29:57+00:00",
        "acceptedDate": null,
        "createdDate": "2020-01-05T04:24:20+00:00"
    },
    "urls": [
        "https://opendocs.ids.ac.uk/opendocs/handle/20.500.12413/12110"
    ],
    "lastUpdate": "2024-02-11T02:29:57+00:00",
    "setSpecs": []
}