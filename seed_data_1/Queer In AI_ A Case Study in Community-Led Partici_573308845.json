{
    "acceptedDate": "",
    "authors": [
        {
            "name": "Organizers Of QueerInAI, ."
        },
        {
            "name": "Ovalle, A"
        },
        {
            "name": "Subramonian, A"
        },
        {
            "name": "Singh, A"
        },
        {
            "name": "Voelcker, C"
        },
        {
            "name": "Sutherland, DJ"
        },
        {
            "name": "Locatelli, D"
        },
        {
            "name": "Breznik, E"
        },
        {
            "name": "Klubicka, F"
        },
        {
            "name": "Yuan, H"
        },
        {
            "name": "Hetvi, J"
        },
        {
            "name": "Zhang, H"
        },
        {
            "name": "Shriram, J"
        },
        {
            "name": "Lehman, K"
        },
        {
            "name": "Soldaini, L"
        },
        {
            "name": "Sap, M"
        },
        {
            "name": "Deisenroth, MP"
        },
        {
            "name": "Pacheco, ML"
        },
        {
            "name": "Ryskina, M"
        },
        {
            "name": "Mundt, M"
        },
        {
            "name": "Agarwal, M"
        },
        {
            "name": "Mclean, N"
        },
        {
            "name": "Xu, P"
        },
        {
            "name": "Pranav, A"
        },
        {
            "name": "Korpan, R"
        },
        {
            "name": "Ray, R"
        },
        {
            "name": "Mathew, S"
        },
        {
            "name": "Arora, S"
        },
        {
            "name": "John, S"
        },
        {
            "name": "Anand, T"
        },
        {
            "name": "Agrawal, V"
        },
        {
            "name": "Agnew, W"
        },
        {
            "name": "Long, Y"
        },
        {
            "name": "Wang, ZJ"
        },
        {
            "name": "Talat, Z"
        },
        {
            "name": "Ghosh, A"
        },
        {
            "name": "Dennler, N"
        },
        {
            "name": "Noseworthy, M"
        },
        {
            "name": "Jha, S"
        },
        {
            "name": "Baylor, E"
        },
        {
            "name": "Joshi, A"
        },
        {
            "name": "Bilenko, NY"
        },
        {
            "name": "Mcnamara, A"
        },
        {
            "name": "Gontijo-Lopes, R"
        },
        {
            "name": "Markham, A"
        },
        {
            "name": "Dong, E"
        },
        {
            "name": "Kay, J"
        },
        {
            "name": "Saraswat, M"
        },
        {
            "name": "Vytla, N"
        },
        {
            "name": "Stark, L"
        }
    ],
    "contributors": [],
    "createdDate": "2023-07-24T10:07:09+01:00",
    "dataProvider": {
        "id": 118,
        "name": "UCL Discovery",
        "url": "https://api.core.ac.uk/v3/data-providers/118",
        "logo": "https://api.core.ac.uk/data-providers/118/logo"
    },
    "depositedDate": "",
    "documentType": "",
    "doi": "",
    "downloadUrl": "https://core.ac.uk/download/573308845.pdf",
    "fullText": "Queer In AI: A Case Study in Community-Led Participatory AIOrganizers Of QueerInAI, Anaelia Ovalle, Arjun Subramonian, Ashwin Singh, Claas Voelcker,Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klubička, Hang Yuan, Hetvi J, Huan Zhang,Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria LeonorPacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx McLean, Pan Xu, A Pranav, RajKorpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, ST John, Tanvi Anand, Vishakha Agrawal,William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, MichaelNoseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, RaphaelGontijo-Lopes, Alex Markham, Evyn Dǒng, Jackie Kay, Manu Saraswat, Nikhil Vytla, Luke StarkQueer in AIABSTRACTQueerness and queer people face an uncertain future in the face of evermore widely deployed and invasive artificial intelligence (AI). These tech-nologies have caused numerous harms to queer people, including privacyviolations, censoring and downranking queer content, exposing queer peo-ple and spaces to harassment by making them hypervisible, deadnamingand outing queer people. More broadly, they have violated core tenets ofqueerness by classifying and controlling queer identities. In response to this,the queer community in AI has organized Queer in AI, a global, decentral-ized, volunteer-run grassroots organization that employs intersectional andcommunity-led participatory design to build an inclusive and equitable AIfuture. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design andintersectional tenets started and shaped this community’s programs overthe years. We discuss different challenges that emerged in the process, lookat ways this organization has fallen short of operationalizing participatoryand intersectional principles, and then assess the organization’s impact.Queer in AI provides important lessons and insights for practitioners andtheorists of participatory methods broadly through its rejection of hierarchyin favor of decentralization, success at building aid and programs by and forthe queer community, and effort to change actors and institutions outsideof the queer community. Finally, we theorize how communities like Queerin AI contribute to the participatory design in AI more broadly by fosteringcultures of participation in AI, welcoming and empowering marginalizedparticipants, critiquing poor or exploitative participatory practices, andbringing participation to institutions outside of individual research projects.Queer in AI’s work serves as a case study of grassroots activism and partic-ipatory methods within AI, demonstrating the potential of community-ledparticipatory methods and intersectional praxis, while also providing chal-lenges, case studies, and nuanced insights to researchers developing andusing participatory methods.1 INTRODUCTIONArtificial intelligence (AI) has seen enormous developments in recent years,such as substantial advances in protein modeling, drug discovery, weatherprediction, and personalized medicine [81, 127, 160]. The ubiquity of unreg-ulated AI within socio-technical systems, however, often produces discrimi-natory outcomes and harms marginalized communities globally [9, 11, 80].For queer people in particular, machine learning models learn brittle, toxicrepresentations that cause representational and allocational harms, frommisgendering to healthcare discrimination [35, 40, 84, 155]. Identifying andmitigating harmful outcomes has led to the development of computationaland socio-technical methods for achieving fairness [14, 32, 103], includingautomatic evaluation and unfairness mitigation techniques [17, 44, 103].While such approaches have the potential to mitigate harms for queer peoplein domains like fighting online abuse, health, and employment [155], compu-tational techniques generally encode narrow conceptualizations of fairnesswhere queer identities are assumed to be known, observable, measurable,discrete, and static [98]. By locating the source of unfairness in individ-uals or in specific design decisions [162], computational approaches tofairness can reinforce existing power relations [38, 82], including marginal-ized communities only in predatory ways [62] or as “ethics washing” [140](cf. Appendix A for an extended critique of computational approaches tofairness).Participatory methods address some of these limitations. Involving usersas co-designers holds great potential for dismantling power relations andempowering marginalized communities that are disproportionately im-pacted by AI [10, 89, 148]. Reflexivity in participatory methods encouragestransparency during the design process itself, as opposed to a detrimental“innovate first, fix later” approach to building trustworthy AI [53]. By es-tablishing the value-laden nature of technologies, it can prevent personalbiases, beliefs and values from seeping into AI systems unexamined.Unfortunately, there are many challenges to incorporating participatoryapproaches across top-down structures, such as corporations that operatewithin capitalism. Popular modes of participation within AI suffer fromextractive and exploitative forms of community involvement or “partici-pation washing” [140]. For example, a recent report [118] sheds light onhow OpenAI used exploitative labor practices to make ChatGPT less toxic,subjecting Kenyan workers to psychologically distressing content1 withoutsufficient provision for mental health support. Gray and Suri [66] also un-covers many exploitative labor practices performed by minorities to powerAI systems.More fundamentally, we question whether marginalized communitiesshould engage in designing with the creators of harmful AI systems thatprioritize profit over their safety. Even in projects where communities areinvolved, engagement is too often limited in scope and time. Contrary toparticipation being controlled by the corporations and states the designand own AI, we argue in the favor of shifting power towards marginalizedgroups and centering their experiences. We call for a culture of participationin AI to address this, one that enables deep and long-term participation inAI research, institutions, and practices.Over the years, the AI community has witnessed several community-led efforts from marginalized communities, each tackling issues of in-equality that arise along various axes of marginalization; these includeBlack in AI [13], LatinX in AI [93], Women in Machine Learning [166],Masakhane [101], Widening NLP [163], Diversity in AI [39], Indigenousin AI [77], Queer in HCI [37], the Indigenous Protocol and AI WorkingGroup [95], the Deep Learning Indaba [34], Khipu [87], North Africansin ML [109], {Dis}Ability in AI [76], Te Hiku Media [51], and Muslims in1This content included examples of sexual abuse, hate speech, violence, murder, childabuse, rape, animal abuse, torture and self-harm.arXiv:2303.16972v3  [cs.CY]  8 Jun 2023Organizers of QueerInAI, et al.Community ResponseGraduate School ApplicationFinancial Aid ProgramInclusive ConferenceGuideTrans-Inclusive PublishingAdvocacyWorkshops& SocialsTensions and ChallengesHierarchy AccessibilityFundingCore PrinciplesDecentralizedOrganizing IntersectionalityCommunity-LedInitiativesOutcomesEquity InclusivityCommunity Role ModelsFigure 1: Overview of Queer in AI’s core principles, community responses, programming outcomes, and tensions and challenges.ML [105]. These organizations have worked in AI ethics, advocated againstAI harms, provided longstanding venues and visibility for AI ethics researchwithin major ML and NLP conferences, resolved inclusion issues with thosevenues, and developed community-led datasets, models, and other technol-ogy. Most importantly, they have advanced participation by marginalizedcommunities in AI research and development at large, nurturing countlessresearchers and practitioners with community, mentorship, financial aid,and innumerable other forms of help with the many barriers marginalizedpeople face in AI. These groups have made AI much more diverse, andstrengthened the voices of marginalized people within AI.In this work, we argue that AI ethicists who value participatory methodsas a means for making ethical AI should engage with participatory andcommunity-lead AI ethics organizations, and study their organizational,strategic, and administrative work through which they are advancing par-ticipation and building cultures of participation. This often difficult processinvolves navigating the complexities of combining inquiry with praxis, andsheds light on differences between participatory approaches.To this end, we offer a case study analyzing Queer in AI, a grassrootsorganization that aims to raise awareness of queer issues in AI/ML, foster acommunity of queer researchers and celebrate the work of queer scientists.Operating primarily as an online community over Slack, the organizationruns various programs and initiatives towards fulfilling its mission. Weanalyze and critique its principles, methodology, initiatives, and impactover the years as a case study of community-led participatory methods inAI.Our key contributions are:• We document salient forms of marginalization and oppression thatparticularly affect queer people (§2).• We present the organizing principles and programs of Queer in AI(§3), including how they started, major changes, and qualitativeand quantitative analyses of impacts (§4).• We analyze challenges and shortcomings of Queer in AI (§5).• We present an argument for conducting more and valuing AI ethicsresearch that combines inquiry and praxis (§6).Positionality Statement Most authors of this paper are formally trainedas computer scientists, with some also having training in gender theory orrelated fields. All authors have informal training in queer studies throughactivism and advocacy. Our backgrounds influence this work’s design, deci-sions, and development. We do our best to position our work in a globalcontext, with authors from Asia, Europe, South Africa, South America, andNorth America.2 MARGINALIZATION OF QUEER PEOPLE INSTEM AND AIHegemonic forms of AI focus on classifying complex people and situationsinto narrow categories at the cost of context, and are often built to supportsurveillance, prediction, and control – designs which are fundamentallyincompatible with queer identities rooted in the freedom of being [85]. Theframing and use of common AI systems that interact with gender are thusoften problematic, and inherently cisnormative and heteronormative, sothat even well-meaning, purportedly inclusive AI projects are prone to “de-signing out” certain queer lives [70]. Documented harms across various AIapplications are numerous, and sometimes life-threatening. These includephysiognomic and phrenologic applications such as computer vision to(falsely) infer gender and sexuality [4, 84, 86, 97, 133, 134, 146]. AI-enabledsurveillance systems, in conjunction with surveillance of online spaces suchas dating apps by states, corporations, and even individuals have outed queerpeople, compromising their privacy and safety [23, 74, 111, 117]. Onlinespaces, especially social media platforms, have insufficient and poorly ex-plained privacy and security tools, requiring community education and adap-tation to meet the needs of queer people [36, 63, 119]. Their moderation en-ables widespread censorship of queer words and identities [33, 46, 139, 141],while also subjecting queer communities to disproportionate online harass-ment and hate speech [120, 157]. Some of these harms can be traced to largelanguage models (LLMs) trained on datasets containing hate speech andcensored queer words, leading search systems to avoid queer content andcontent moderation systems to more often tag it as suspect [40, 65]. LLMsalso overwhelmingly fail to account for non-binary genders and pronouns,contributing to erasure of these identities [18, 35].In the US, queer people are (at least) 20% less represented in STEM thanin the national population, and experience higher levels of “career limita-tions, harassment, and professional devaluation” [20]. Consequently, queerscientists often face “systematically more negative workplace experiencesthan their non-LGBT colleagues” [21], and “leave STEM at an alarming rate”[59]. The exclusion of queer people from science comes with significant con-sequences, both for queer scientists and queer people further marginalizedby fields that do not understand or care about them. The medical profes-sion’s response to the HIV/AIDS crisis was fatally slow until pressured byheroic activism [136]; a medical field that had included and empoweredqueer people may have saved many queer lives. Similarly, the AmericanPsychiatric Association classified homosexuality as a mental illness until1973, greatly contributing to the stigmatization of queer people around theworld, until queer activists pressured the group for change [41]. Recentinitiatives have inverted this dynamics, centering queer communities indescisions about mental healthcare [89].One hurdle in understanding the marginalization of LGBTQIA+ peoplein STEM is a lack of demographic data on sexual orientation and genderidentity [59]. The US’s National Science Foundation has delayed the collec-tion of such data for years, despite the urging of queer scientists [92]. Takingmatters into its own hands, Queer in AI administers an annual survey ofits global community to uncover the demographics and challenges facedby queer researchers in AI (discussed in detail in Appendix B). In Queer inAI’s 2021-22 community survey (𝑁 = 252), 74% of members reported a lackof role models and 77% reported a lack of community as obstacles in theirjourney of becoming an AI practitioner.There is a dire lack of studies and data on queer scientists’ experiencesin the Global South, where colonial histories have led to the criminalizationof queerness [1–3]. Queer in AI organizers from Turkey, Colombia, andIndia have shared that much queer activism in these countries focuses onQueer In AI: A Case Study in Community-Led Participatory AIsurvival and gaining basic human rights, recognition and respect in society,amid high levels of discrimination, violence, and psychological distress [24].They perceive being out and working towards queer visibility in STEMfields to be beyond luxuries, especially given the dominant (cisnormative,heteronormative) view that identity and profession should be “kept sepa-rate.” Barriers to acceptance are only amplified for queer individuals alsomarginalized on intersecting axes like class or caste.3 CORE PRINCIPLES OF QUEER IN AIThree governing principles drive Queer in AI’s mission to raise awarenessof queer issues in AI and foster a community of queer researchers: (i) decen-tralized organizing, (ii) intersectionality, and (iii) community-led initiatives.Overall, Queer in AI’s decentralized operations allow for swift community-led initiatives towards its mission (§3.1), which center on intersectionalityas critical inquiry and praxis (§3.2). In doing so, it acknowledges and contin-uously works to account for “the complexities of multiple, competing, fluid,and intersecting identities” [68]. Queer in AI’s primary approach consistsof including people with diverse lived experiences in participatory schemes(§3.3).3.1 Participation and DecentralizationFor its first two years, Queer in AI had a hierarchical structure, with apresident and officers. However, organizing and governance of grassrootscommunities, and especially queer communities, presents unique challenges.Queer people are incredibly diverse, and choosing one or even a group ofqueer people to represent the community as a whole is reductive and im-possible. This is also difficult for the organizers, with high-profile queer ac-tivists and organizers frequently facing targeted harassment campaigns, andQueer in AI organizers frequently reporting lack of time, external support,or recognition for volunteering (Figure A16). Queer in AI thus adopted adecentralized organizing structure, to encourage broad participation. Queerin AI minimizes distinctions between organizers and members to encouragethe entire community to participate in organizing. Most volunteer coordina-tion occurs in the same Slack channel as is used for community discussion,calls for help or feedback on programs mixed with memes, introductions,personal news, and discussions of travel or pets. Of the 49 active Slackchannels only 4, where personally identifiable information is discussed,are not public. Openness and embedding in the community increase trans-parency and accountability: any community member can view organizingdiscussions and join in, with no more barrier to entry than joining a Slackchannel. It also helps provide the connection and joy for which 75% of itsorganizers joined Queer in AI (Figure A15). Fluidity between member andorganizer also makes it easier for community members’ areas and levels ofengagement to ebb and flow over time without losing their connection tothe community.3.2 Participation and IntersectionalityOver five years, Queer in AI’s community has grown to about 870 members,geographically distributed across more than 47 countries (cf. Figure 2). Thecommunity members have diverse identities across axes such as ethnicity,gender, class, disability, and caste. About 20.3% of respondents identifiedas transgender, and 34.4% identified as non-cisgender; 34.9% identified asBlack, Latinx, indigenous or a person of color; less than 2% identified asintersex. Membership spans academia and industry, with about 16% ofmembers pursuing an undergraduate degree, 21% in an industry role, and64% in academia, all with varying degrees of seniority (cf. Appendix B foradditional details of community demographics). As a result, Queer in AIhelps naturally bridge otherwise insular aisles of power and social contexts.As the queer community consistently experiences discrimination, stigma-tization, and inequity [19, 104], Queer in AI uses the lens of intersectionalityas a means of critical inquiry to identify how interlocking forms of oppres-sion, such as racism and sexism, co-construct and exacerbate social andstructural disparities [27]. To proactively dismantle injustices, Queer in AIcenters the experiences of its members so that active participation in theQueer in AI community results in the co-creation of initiatives, which re-flect of tackling such barriers, including economic (§5.3), educational (§4.1),and social (§4.2) ones. By prioritizing fighting intersectional oppression,Queer in AI attempts to empower its most marginalized members to shapeand control its programming, addressing key challenges of participatorydesign such as the exclusion of marginalized people from participation [83],community power-sharing [28] and the co-formation of knowledge [49].In doing so, Queer in AI works towards a system of resistant knowledgefirmly grounded in intersectionality’s critical praxis [26, Chs. 3 & 4].3.3 Participation and Community Leadership3.3.1 Research. Various forms of community-engaged research guide thedissemination of knowledge both within and outside of Queer in AI and existacross a continuum, from community-informed to community-involved tocommunity-led. Community-informed research consists of researchers invit-ing the community to incorporate lived experience to guide research ques-tions, data collection, or data interpretation [71]. Towards more community-involved research, community members may be more involved in decision-making processes and research planning [71, 131]. At the highest levelof engagement, community-driven approaches such as community-basedparticipatory action research (PAR) centers shared collaborative decision-making between researchers and community members across researchdesign, knowledge creation, intervention development, and policy-making[29, 99, 158]. In practice, entities outside of the organization may partnerwith Queer in AI community members to form relationships designed tohelp objectives oriented towards investigating and supporting “the pursuitof answers to the questions of their daily struggle and survival” [151]. In-dividuals are often members of both other entities as well as of Queer inAI so that members may operate from the role of an external entity (e.g.researcher from a company) and at various depths of community engage-ment. The resulting knowledge production is such that is “by the people,for the people” in which research is not only seen as a process to createknowledge but to also educate and mobilize for action [29, 67]. By “puttingcommunity first”, the distinction between participant and researcher is re-moved. Community-based participatory action research thus also serves asa decolonizing epistemological framework which inherently interrogatespower and privilege [50].3.3.2 Response & resilience. Within Queer in AI, community resilienceoperates across dimensions including but not limited to the social, political,and economic. Advocacy efforts operate across domains, tasks, resources,and activities within the organization [90]. Resources and activities arestructural means towards tasks and domains that reflect the Queer in AImission. Specifically, resources and activities are dedicated to raising aware-ness of queer issues in AI/ML. Financial, educational, and social avenuesare created within the organization as a form of creating resilience and ad-vocacy in the face of oppressive sociotechnical barriers. Operating across 47countries, Queer in AI primarily organizes through Slack, Zoom, a dedicatedmailing list, and social media platforms. Doing so makes room for rapidand adaptive situational awareness within the online community [145].Besides the “internal” milieu of an organization, Queer in AI is responsiveto events in both reactive and proactive forms. Digital volunteer effortsemerge as self-organizing responses to external factors [25, 45]. This workfurther details examples of how responses to acute external factors andlarger efforts against oppression manifest as Queer in AI initiatives.Organizers of QueerInAI, et al.Figure 2: Country of origin of the respondents to the Queer in AI’s 2021–2022 demographic survey.Table 1: Self-reported ethnicity, gender, and sexual orientation of the respondents to the Queer in AI’s 2021–2022 demographicsurvey. Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories (see§B.8). “Unaggregated” refers to responses that could not be adequately described with any subset of other categories; however,responses in this group may overlap with the remaining categories. For options with fewer than 4 responses, exact values areomitted for privacy.Ethnicity Gender Sexual OrientationCaucasian 127 Man 108 Queer 90South Asian 34 Woman 95 Gay 89East Asian 17 Non-binary 61 Bisexual 87Black/African/African-American 13 Genderqueer 29 Pansexual 42Latinx 13 Gender non-conforming 22 Lesbian 30Mixed 12 Genderfluid 19 Asexual 26Jewish 8 Agender 17 Unaggregated 29Middle Eastern 8 Questioning 16Southeast Asian 6 Unaggregated 16West Asian ≤ 3Central Asian ≤ 3Hispanic ≤ 3Unaggregated 64 QUEER IN AI INITIATIVESThe structure of Queer in AI is decentralized and includes volunteers, coreorganizers (extensive organizing experience with Queer in AI) and a diver-sity, equity and inclusion admin (DEIA, a core organizer who has a moreactive role in administrative duties). Most of Queer in AI’s communicationis mediated by its Slack workspace.A key aspect of Queer in AI’s organizing lies in the transparency of itsoperations and associated information exchanges, which predominantlytake place over public Slack channels. There are only four private chan-nels on the workspace, which exist to preserve privacy while facilitatingdiscussions around personally identifiable information. The workspacehas included the exchange of over 133,000 messages (including individ-uals’ one-to-one private messages), of which over 25,000 have been sentin public channels, accounting for the majority (57%) of total views. Thistransparency, in conjunction with regular updates and outreach on Slack,keeps community members involved in ongoing events and initiatives.Many of Queer in AI’s initiatives have emerged from conversations andthreads on public channels about discriminatory experiences with differentinstitutions. For example, discussion around exclusionary gender collectionpractices on conference registration forms led to the creation of an inclusiveconference guide (covered in more detail in §4.3) and substantial improve-ments to relevant conferences’ practices. Similarly, significant advocacyagainst deadnaming in citations and conference proceedings (§4.4) beganfrom discourse on public channels. Thus, as a space, Queer in AI’s Slackis effective at mobilizing community-led initiatives through decentralizedorganizing. Moreover, the emergence of these initiatives from diverse yetintersecting shared queer experiences grounds them in global contexts ofsocial inequality and injustice. For instance, Queer in AI’s graduate schoolapplication financial aid program (§4.1) and workshops and socials (§4.2)target several particular challenges rooted in non-Western contexts, center-ing otherwise-marginalized experiences. The organizational and volunteerwork that constitutes the administration of all these initiatives is thus deeplyintersectional.We now examine four major initiatives in detail; Appendix C furtherdescribes efforts in policy advocacy.4.1 Graduate School Application Financial AidProgramQueer folks report a lack of community and queer role models due to the un-derrepresentation of senior queer folks in academia. Thus, supporting queerand low-income scholars financially helps bring more marginalized voicesQueer In AI: A Case Study in Community-Led Participatory AITable 2: The Queer in AI Graduate School Application Fee Aid Program budget and impact per academic year, in USD.Academic year Aid per applicant No. aid recipients Total aid Budget2020/2021 up to $750 31 $16,689 $20,0002021/2022 up to $1,250 81 $70,607 $73,7682022/2023 (at time of writing) up to $1,250 48 $40,476 $41,711Table 3: Gender, sexual orientation, romantic orientation and continent of scholarship recipients who filled the optionalfeedback survey (𝑛 = 46 out of 𝑁 = 160 total recipients). For options with fewer than 4 responses, exact values are omitted forprivacy.Gender Sexual Orientation Romantic Orientation ContinentWoman 20 Gay 18 Homoromantic 21 Asia 19Man 18 Queer 16 Biromantic 13 North America 14Genderqueer 7 Bisexual 12 Demiromantic 5 Africa 5Non-binary 6 Lesbian 9 Grayromatic 5 Europe ≤3Gender non-conforming 6 Asexual 4 Alloromantic ≤3 South America ≤3Agender ≤3 Pansexual 4 Aromantic ≤3Genderfluid ≤3 Demisexual ≤3 Heteroromantic ≤3Questioning ≤3 Questioning ≤3into STEM academia, creating more opportunities for participatory researchand technology design. To address this, Queer in AI launched the GraduateSchool Application Fee Aid Program to improve queer representation andmake graduate programs accessible.4.1.1 Financial challenges. The costs for graduate school applications pre-vent many low-income and international scientists from accessing graduateprograms, well before they can benefit from many of the fellowships andneed-based scholarships intended to address exclusion. This process iscostly: between the application fees (∼$50–$150 USD per program in NorthAmerica and parts of Europe), costs of required tests (e.g. GRE), test resultsand transcript delivery fees, and test preparation expenses, one round ofapplications can easily amount to over $1,000 USD. International appli-cants may be further required to pay for language proficiency tests (e.g.TOEFL), translation services, and third-party credential vetting. Althoughsome schools offer fee waivers, they vary widely from school to school, areoften very limited in applicability, and can require onerous documentation.The majority of applicants apply to North American schools. This islikely caused by the cultural dominance of Anglo-American schools in theAI/ML space and the common practice of requiring extensive standardizedtests and application fees at these schools.2 Standardized tests like the GREclaim to level the playing field for applicants, they institute barriers toindividuals from the Global South and reify colonialism under a veneer offairness. Additionally, fees make these exams wholly inaccessible to manyin the Global South: the GRE costs three times the average monthly salaryin Ethiopia [12]. Data collected from Queer in AI’s surveys have been usedto argue that departments should eliminate the GRE and application fees.These financial challenges are particularly likely to be insurmountablefor queer scientists, who may be cut off from familial financial support,might pay out of pocket for gender-affirming healthcare, and often incuradditional expenses managing oppression and trauma. Queer people thussuffer from increased student loan debt [100] and high rates of housinginsecurity [164]. A complete critique of the graduate application processand its socio-economical context is out of the scope of this paper. Queer inAI believes it is nonetheless important to provide concrete aid right now toapplicants faced with the current system.4.1.2 Mutual aid design. The design of the aid program is decentralized,community-led constituting volunteers with a diverse range of experiences2While fees and standardized tests are the norms at many prominent institutions,there are examples of alternative paths, such as the ELLIS PhD Program, a Europeaninitiative for AI/ML PhD programs, which requires neither [47].with graduate school admissions [142]. This initiative keeps minimum bar-riers to receiving the aid by not seeking to decide who is “deserving” of aid,avoiding imposing excessive requirements for documenting eligibility andproviding timely mentorship and help to the applicants for their submis-sions. Although, the payment pipeline often disadvantages applicants fromcountries and territories where PayPal is not available or restrictions areimposed on receiving transfers from the US.4.1.3 Participatory learnings. Each aid applicant is treated as a memberof the community with a valuable perspective of their own – the initiativeactively seeks feedback from aid recipients and encourages them to volun-teer in the future, which would both help improve the program and keepit sustainable. This feedback indicated that aid recipients’ demographicswere more diverse than Queer in AI’s organizing team (Table 3), whichhelps Queer in AI recruit more diverse volunteers and community mem-bers by first directly, meaningfully helping them. Also, the feedback surveyillustrates widespread deficiencies in existing admissions fee waivers: suchas lack of fee waivers (67%), unable to produce adequate documentation(14%) and the fear of outing themselves (10%). This aid program allowedrecipients to take admissions tests (56%), avoid skipping essential expenses(54%) and avoid skipping groceries or bills (40%). The vast majority of recipi-ents reported the scholarship enabled them to apply to additional programs(around 6 on average).4.1.4 Critical Reflections. The program operates with a tension betweenopening opportunities to marginalized people from all over the world andreinforcing the exclusionary practices of these powerful institutions. In addi-tion to funding influential and rich academic institutions, the program alsoindirectly supports the standardized testing industry. The limited amountof funds and barriers to sending the money internationally often pose chal-lenges between the organizers and the aid recipients. In spite of that, Queerin AI believes that it is crucial to provide timely aid regardless of thesebarriers, even if doing so reinforces undesirable structures.4.2 Workshops and SocialsIn STEM disciplines, conferences can be a hostile setting for minoritizedgroups [102, 130, 167]. Queer in AI members in 2022 rated how welcomethey felt attending AI conferences at 3.38 on average (𝜇1/2 = 3) on a five-point Likert scale (§B). Recognizing this need, Queer in AI has organizedworkshops and networking events since its very first informal meetup atNeurIPS 2017: as of submission, 13 workshops and 35 social events in totalOrganizers of QueerInAI, et al.(Table 4), with a cumulative attendance of hundreds of participants.3 Theseevents provide an opportunity to connect and network with other queerscientists, spotlight work by members of Queer in AI, host talks on topicsrelevant to its members, and arrange panels where experts discuss topicsat the intersection of AI, fairness, ethics, and the queer community. Thefollowing subsections cover how Queer in AI’s principles influence eventplanning and enable them to overcome challenges in the process.4.2.1 Workshop Organizing. Queer in AI workshops and socials are typ-ically organized by members of the community planning to attend theconference; no prior academic or organizing experience is required. Junioror new members of the community are often encouraged to lead these ini-tiatives while being mentored by more experienced organizers throughoutthe process. Organizers, DEIAs, and Queer in AI’s financial stewards coor-dinate to secure logistical, monetary and other miscellaneous needs of theevent. These include renting equipment to support accessibility, honorariafor speakers, scholarships for attendees, refreshments for socials, onlineoutreach and promotion of the event, and so on. All of this communica-tion takes place asynchronously over Slack, or in Zoom meetings scheduledacross organizers’ time zones. This decentralized approach also helps enableQueer in AI members spanning different sub-fields in AI to tailor eventsto represent and serve the needs of their sub-community. When promptedto rate how welcome they felt at these workshops, the response was over-whelmingly positive, with about 47% of queer attendees rating it five out offive on a Likert scale (𝜇=4.16, 𝜇1/2=4) (§B.6).4.2.2 Panels and Talks at Workshops. Panels and talks at Queer in AI arecrucial as they help in amplifying queer voices and concerns in our field.Many topics presented in the panels and keynotes have later served abigger impact in the AI field, such as talks on conference inclusivity andname change policies. Queer in AI encourages a participatory approach toworkshop design: by soliciting topics and speaker ideas from communityworkspace. This approach has allowed Queer in AI to host panels andtalks on intersectional topics that often do not have a presence at majorAI/ML venues (for just one example, a discussion on the intersection ofqueerness, caste and AI at NeurIPS 2021 [122]). Queer in AI organizersspend tremendous effort by making the workshops as inclusive as possibleby providing fair honoraria to the speakers and organizing the events inonline, hybrid, and in-person settings.4.2.3 Barriers and Challenges in Participation. AI conferences are oftennot accessible for a sizable portion of queer researchers, especially thosebelonging to other marginalized backgrounds or from countries with lowerpurchasing power or higher rates of discrimination towards queer peo-ple [159]. Primary reasons includes high registration and travel costs. Outof all Queer in AI members who reported being unable to attend conferencesowing to lack of funding, 88% identified as one of Black, indigenous, personof color, transgender, neurodivergent, or disabled (§B.6). While Queer in AItries to work with conference organizers to use DEI funds for increasing theattendance of queer scientists, in many cases conference organizers refuseto engage with Queer in AI’s requests. Queer in AI thus often provides acombination of travel grants, registration waivers, and reimbursement forconference-related expenses to queer AI researchers. In other cases, unof-ficial social events4 near the conference venue and online virtual socialson gather.town are organized to accommodate excluded time zones andovercome both financial and geographical access barriers. Other barriers3An exact count could not be obtained: to maintain attendees’ privacy, Queer in AIdoes not require signups for most events, and deletes names immediately after eventswhen they are required.4These events are not officially included within the conference program but promotedover Queer in AI’s Slack and mailing list as well as social media. A recent example isAAAI 2023 where the conference fees was exorbitantly high and negligible effort wasput into provision for registration waivers.specific to the conference location, such as unsafe legal and social climates 5for queer people or exclusionary visa processes, continue to significantlylimit queer participation within AI spaces. Finally, for conferences which arepoorly equipped in their support for disabled people, Queer in AI provideslive captions for all in-person and virtual events, and secures equipment tocreate accessible spaces.4.3 Advocacy for Improving Queer Inclusivityin ConferencesAs conferences moved online in response to the COVID-19 pandemic, Queerin AI organizers noted a series of operational failures that could cause queerattendees to feel unsafe or unwelcome. Registration platforms demandedattendees to provide their legal names, thus potentially deadnaming them;the use of pronoun badges for speakers and attendees was rarely encouraged,or platforms did not support displaying pronouns; virtual chat softwareblocked common queer terms such as “queer” or “lesbian”, thus preventingqueer attendees from communicating freely. Queer in AI organizers workedclosely with many conferences to resolve these issues, as they had in priorsettings (§4.2), and ultimately decided to collect recommendations aimedat highlighting best practices to ensure safety, privacy, and accessibilityfor queer attendees at academic conferences in AI in a collected guidancedocument.6These recommendations began based on existing best practices andexperience with conference organizers, but were refined through extensiveiterative feedback from members of Queer in AI and other affinity groups,incorporating many opinions and ultimately achieving consensus among abroad group of contributors. The guide has recently been expanded to alsocover in-person events as conferences move to hybrid or in-person formats.This queer advocacy to improve inclusivity covers two aspects: improvingqueer safety and increasing queer representation.4.3.1 ImprovingQueer Safety: As in any public space, queer conference-goersmight face discrimination based on their gender and sexual orientation.Therefore, it is paramount for attendees to be able to control what informa-tion they wish to disclose to the organizers and attendees of a conference.Queer in AI advocates mechanisms to (i) respect attendees’ identities bycollecting gender and pronoun information in a manner that does not mis-represent or erase queer identities, by creating forms with inclusive gendercategories and disclosing the data usage [132] (ii) minimize the amount ofpersonal information queer individuals have to disclose [7] (for example,only collecting legal names when absolutely necessary, and using responsesabout the gender and sexuality of attendees only for statistical purposes andin anonymized form); and (iii) ensure that mechanisms to report disruptiveor harmful behaviours are swift and effective. Queer in AI recommendsadopting a code of conduct (e.g., [123, 165]) to not only establish communi-cation norms, but also describe how policy violations are handled [42].4.3.2 IncreasingQueer Representation and Participation: Queer researchers’needs are regularly ignored in many aspects of the research community:challenges include lack of academic support, hostility from colleagues andadvisors, inflexible name change policies, lack of representation in theresearch itself, and more [22]. Stronger inclusion efforts, both for repre-sentation and participation, can work towards addressing a lack of queercommunity and role models [135]. To increase representation, Queer in AIstrongly encourages conference organizers to invite queer keynote speak-ers and panelists, prioritizing those from marginalized backgrounds (e.g.,BIPOC or non-cisgender) [43]. Queer in AI recommends fair and equal5EMNLP 2022 (in Abu Dhabi) predatorily included Queer in AI to obtain their approvalfor conference safety measures; Queer in AI rejected this, due to the conferenceoperating at a different domain of power for trans people and the power inherent inspeaking for the entire queer community.6The guide, originally published as [125], is a living document available atqueerinai.com/how-to-make-virtual-conferences-queer-friendly.Queer In AI: A Case Study in Community-Led Participatory AITable 4: Workshop and events organized by Queer in AI in 2017–2022 across conferences in AI. Events marked with p were heldin person, v indicates virtual-only events, and h refers to events that occurred in a “hybrid” format.Year 2017 2018 2019 2020 2021 2022Workshops - 1NeurIPSp2ICMLp NeurIPSp2NeurIPSv ICMLv3EMNLPv † ICMLv NeurIPSv5FAccTh ‡ ICLRv ICMLhNAACLh NeurIPShSocial Events 1NeurIPSp1NeurIPSp5ACLp CVPRp ICMLpNAACLp NeurIPSp11AAAIp AACLv ACLv CogScivCOLINGv CORLv EMNLPv FAccTpICLRv ICMLv NeurIPSv10AAAIv ACLv CoRLv EACLvEMNLPv ICLRv ICMLv NAACLvNeurIPSv SIGIRv7AAAIv AAMASv ACLh ICLRvICMLh NAACLh NeurIPSh† at EMNLP 2021, Queer in AI co-hosted a workshop with WiNLP.‡ at FAccT, Queer in AI hosted two CRAFT sessions.compensation based on effort rather than seniority for all speakers [60, 129].As noted in previous sections, financial accessibility and a lack of commu-nity were the main barriers for queer folks to feel included at conferences.Queer in AI strongly advocates setting up spaces for queer folks to networkand socialize with privacy measures and also providing subsidies for queerresearchers to attend virtual or in-person events.4.3.3 Critical Reflection. This guide and advocacy are not without theirlimitations. Most recommendations are still focused on virtual spaces andcurrently written guide lacks in-depth accessibility recommendations. Queerin AI needs to collaborate with disabled folks with a wider range of disabil-ities to document best practices regarding accessibility accommodations.Most significantly, despite organizers’ efforts the guide has seen relativelymodest adoption.4.4 Trans-inclusive Publishing AdvocacyFor many transgender, non-binary, and gender-diverse scholars (as wellas others), the continued circulation of a previous name in publishing isa significant source of trauma [152]. Referring to an author by a previousname without consent (deadnaming) may effectively out their identityagainst their will. Queer in AI has worked along with the Name ChangePolicy Working Group [106] to advocate name change policies in AI venues,helping to establish the name-change policies and procedures now adoptedby most AI-related venues [5, 6, 15, 16, 75, 94, 107, 153] (cf. §C for moreabout Queer in AI’s advocacy and impact).Even publishers with functional name change policies are often woefullyslow to implement them, and search engines can index outdated informationlong after its correction [143, 144]; moreover, authors often use outdatedbibliographic entries long after relevant publications and search tools havebeen updated [149]. It is thus vital to check the correctness of citations insubmitted papers to avoid propagating incorrect information. QueerInAIhas thus developed a tool to check paper PDFs for mistaken citations. Itsearches the ACL Anthology, DBLP, and arXiv for a close paper title match,and prompts a correction if the paper’s author list disagrees with that source,detecting both deadnaming and incomplete or outdated author lists. DBLP inparticular provides better name change support than many other platforms,via ORCID [115]. This toolkit has been integrated into ACL publicationcamera-ready systems [121], and Queer in AI hopes to expand it to otherconferences. A demo is available at qinai-name-check.streamlit.app.Additionally, Queer in AI advocates publishers to promptly grant namecorrection requests in any format, without unnecessary barriers or doc-umentation requirements. Such changes should remove all instances ofauthors’ previous names from all records, or (at the author’s discretion) adddisclaimers for media that cannot be updated (e.g., audio or video recordings).As the result of this advocacy, Queer in AI has helped institute effectivename-change processes at NAACL and EMNLP; and has worked with theAssociation for Computational Linguistics [55] to implement a name changeprocess, proactive measures to prevent the deadnaming of trans authors,and protocols to handle authors’ requests to keep their videos private.5 TENSIONS AND CHALLENGESAs reflexivity is a core tenet of intersectionality [26], this section criticallyexamines the tensions and challenges that emerge in the operationalizationof Queer in AI’s principles within its initiatives. From the issues with Queerin AI initiaitves discussed in the previous section, we find three common,root themes of hierarchy, accessibility, and funding. We argue thatthese are not only critical challenges for Queer in AI, but deep challenge-sany participatory or community-lead AI organization must address to besuccessful.5.1 HierarchyDecentralized organizing plays a vital role in minimizing power distanceand distinctions between members of Queer in AI. Even so, there are notabledistinctions between members who participate in organizing, core organiz-ers, and the DEIAs as paid contractors. Queer in AI’s core organizers andDEIAs help sustain the growth of the organization through mentorship ofnew volunteers and institutional memory. In addition, they form a relativelylarge and diverse group for deliberating on rare decisons that cannot bediscussed openly, such as those involving PII. Their existence does, how-ever, pose challenges in accessibility for people unfamiliar with navigatingunstructured social networks, and can be non-transparent to newer or lessinvolved members. The core organizers also assume a more active role,sharing considerable power in steering the direction of its initiatives. Queerin AI helps address these tensions by setting a fixed one-year tenure forDEIAs, and inducting organizers who have been active throughout the pre-ceding year as core organizers. Resolving tensions between decentralizationand hierarchies created by knowledge and experience, or forced by privacyconcerns, nonetheless remains an open problem within Queer in AI.5.2 AccessibilityDespite global participation, Queer in AI’s structure and operational designcan discourage participation for many queer scientists. First, participationin a volunteer-run community not only requires organizers to have incomethat allows them to perform free labor but also have access to computers,internet, and other resources required to even connect with Queer in AI.Second, while Queer in AI strives to be intersectional, it severely lacksaccess to queer networks in countries from the Global South. It originatedand primarily operated within a Western context during its initial years,which led to the inadvertent creation of barriers that limit its outreach.For example, because Queer in AI organizers are best connected with USand European institutions, its events are often co-located at conferencesattended mainly by scientists residing in the Global North. Further, itsmeetings often occur at times best aligned with European and Americantime zones, at the expense of much of Asia. Finally, all Queer in AI activitiesrequire English proficiency.While recent community and focused outreach efforts have reducedsome of these barriers, significant work lies ahead in establishing trulyglobal ways of participation, especially for countries where queerness isOrganizers of QueerInAI, et al.criminalized. Third, participation in Queer in AI exerts a toll on mentalhealth and exhaustion of its organizers (Figure A16). This is partly due toQueer in AI’s lack of formal structure, instead relying on individuals self-coordinating on initiatives of their choice. While efficient, this approach canmake joining and keeping track of ongoing efforts challenging for newcom-ers and neurodivergent members of the community. Past organizers havealso shared anecdotes of experiencing exhaustion, fatigue, and anxiety dueto a lack of accommodation of different working styles and falling behind onpersonal schedules while undertaking operational work for Queer in AI (seeFigure A16). This disproportionately impacts disabled and neurodivergentmembers and is compounded for intersecting marginalized identities.Even after years of critical reflection and significant investment of vol-unteer time, money, and other resources, Queer in AI is still inaccessibleto many. While accessibility to everyone should always be the goal, inpractice, no single community or participatory initiative will be able toinclude everyone in that community. Therefore, participatory researchersaspiring to broad inclusion should consider the pluralities of communitiesand participatory initiatives with radically different structures.5.3 FundingFunding and payments are where Queer in AI struggles most to meet itscommitments to decentralization, intersectionality, and community lead-ership. Queer in AI relies on sponsorships, donations, and contributionsfrom its parent organization oSTEM to fund its activities. In 2022, Queer inAI expenses (rounded to the closest integer) totaled US$100,658: the grad-uate application fee scholarship program (§4.1) spent $40,435; two DEIAcontractors were paid a total of $33,220; speaker honoraria totaled $14,500;$6,941 went to travel grants, room and board, and conference registrationfees; emergency microgrants for queer people totaled $5,000. Income com-prised $78,000 in corporate sponsorship, $13,711 in donations, and $5,000 ingrant revenue (cf. Appendix B.9 provides income and expenses for previousyears.).Queer in AI’s reliance on corporate sponsorship may call into questionits independence and community-lead ideal. Corporate sponsors receiveaccess to opt-in resume books, short speaking opportunities, and eventrecruiting booths. A large part of Queer in AI’s funding still comes from bigtech corporations that are complicit in oppression and genocide globally,such as the policing of Palestinians. Queer in AI has nonetheless droppedand turned down many sponsors for ethics concerns, including a mutualdecision with Black in AI in 2021 to drop Google [79], costing $20,000 inlost sponsorship per year. While Queer in AI has been growing donations,many in the Queer in AI community are students or early in their careerswith very limited capacity to give. Opportunities for grants are limited, asmany scientific funding bodies such as the US’s NSF exclude queer peoplefrom many of their D&I initiatives [58].Queer in AI sends honoraria, scholarships, and travel grants to peoplein many different countries, primarily through PayPal and wires. Paymentdisbursal in Queer in AI is highly centralized; for reasons of security oSTEMonly allows one Queer in AI organizer to send PayPal payments. All wiresand credit card payments must be sent by the oSTEM CEO. Additionally,payments strain Queer in AI’s intersectional values. PayPal does not workwell in China, India, many countries in Africa, and some countries in SouthAmerica, forcing reliance on slower and more administratively difficultwire transfers. Moreover, U.S. law requires people receiving honoraria andother types of payments to pay US taxes above a certain threshold, whichrequires a lengthy registration process or significant fees and overhead fromQueer in AI. Payments also frequently trigger spurious fraud alerts andinvestigations, which require even more time from and stress on organizers.In summary, marginalization prefigures Queer in AI’s funding options,legal and security concerns exert a strong centralizing pressure on financialadministration, and the financial system regards many payments, especiallyto non-Western countries and those making them, with suspicion by default.6 CONCLUSIONParticipatory methods have the potential to address issues of power andinclusion in AI, but their benefits and challenges in practice are still unclearbecause few organizations have deeply engaged with them. In this paperwe studied Queer in AI as a case study of a grassroots participatory AIorganization. We explored how they designed their organization to enableparticipation, and how initiatives addressing intersectional marginalizationarose from andwere continuously refined by this participation.We theorizedhow Queer in AI’s numerous socials, workshops, and other events havecontributed to a culture of participation in AI by bringing queer people intoAI conferences and research and industry settings and resisting predatoryinclusion.We hope this case studywill inform theoretical study and practicaldesign of participatory initiatives. In particular, we encourage considerationof Queer in AI’s reinforcing principles of decentralization, communityleadership, and focus on intersectionality, and urge care for mitigatingthe ways hierarchy, inaccessability, and funding can subvert participatorymethods.6.1 Future DirectionsQueer in AI will continue to grapple with the tensions and alleviate thechallenges addressed in §5. To dismantle hierarchies among organizers cre-ated by knowledge, experienced Queer in AI organizers will host structuredtrainings to onboard new organizers onto finance & sponsorships and work-shops. Queer in AI additionally plans to supplement its 2023 communitysurvey with community interviews about accessibility, towards gleaningactionable insights about mitigating barriers to participation. Furthermore,Queer in AI’s organizers will work with its community to refine its spon-sorship policies and identify less precarious mechanisms for transferringfunds. All of these activities are motivated and will be guided by our coreprinciples of decentralization, intersectionality, and centering community.Queer in AI will further communicate its activities and their implicationsfor equity and inclusivity via accessible media, e.g., blog posts, zines.ACKNOWLEDGMENTSThis workwould not have been possible without the activism and organizingefforts of the Queer in AI community. We would also like to thank KattaSpiel and Os Keyes for their insightful feedback on the earlier versions ofthe paper.REFERENCES[1] 2015. Some African Countries Are Trying to Use Science toMake Homophobic Laws, Now African Scientists are Pushing Back.https://www.smithsonianmag.com/smart-news/africans-scientists-speak-out-against-homophobic-laws-180955579/[2] 2020. A constant uneasy state: Trans people in STEM in India. https://thelifeofscience.com/2020/11/09/transgender-people-in-science/[3] 2022. Brazil LGBTQ activists, HIV/AIDS service providers fear Bolsonaro re-election. https://www.washingtonblade.com/2022/05/19/brazil-lgbtq-activists-hiv-aids-service-providers-fear-bolsonaro-reelection/[4] Blaise Agüera y Arcas, Margaret Mitchell, and Alexander Todorov. 2017. Phys-iognomy’s New Clothes. https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a[5] ACL Anthology. (n.d.). Requesting Corrections. https://aclanthology.org/info/corrections/ [Accessed Feb 2023].[6] arXiv. 2021. arXiv Proceedings: Name Change Policy. https://blog.arxiv.org/2021/03/11/update-name-change-policy, Name Change Policy blog.[7] Alison Barclay and Melissa Russell. 2017. A guide to LGBTIQ-inclusive datacollection. https://meridianact.org.au. https://meridianact.org.au/wp-content/uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf[8] Solon Barocas, Moritz Hardt, and Arvind Narayanan. 2019. Fairness andMachineLearning. fairmlbook.org. http://www.fairmlbook.org.[9] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and ShmargaretShmitchell. 2021. On theDangers of Stochastic Parrots: Can LanguageModels BeToo Big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability,and Transparency. 610–623.Queer In AI: A Case Study in Community-Led Participatory AI[10] Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz,Madeleine Clare Elish, Iason Gabriel, and Shakir Mohamed. 2022. Power to thePeople? Opportunities and Challenges for Participatory AI. In Equity and Accessin Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO’22). Association for Computing Machinery, New York, NY, USA, Article 6,8 pages. https://doi.org/10.1145/3551624.3555290[11] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. 2021. Mul-timodal datasets: misogyny, pornography, and malignant stereotypes. arXiv(2021). https://arxiv.org/abs/2110.01963[12] Black in AI. 2020. Academic Program. https://blackinai.github.io/#/programs/academic-program[13] Black in AI (n.d.). https://blackinai.github.io[14] Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020.Language (Technology) is Power: A Critical Survey of “Bias” in NLP. InProceedings of the 58th Annual Meeting of the Association for ComputationalLinguistics. Association for Computational Linguistics, Online, 5454–5476.https://doi.org/10.18653/v1/2020.acl-main.485[15] ACM Publications Board. 2019. ACM Publications Policy on Author NameChanges. https://www.acm.org/publications/policies/author-name-changes[16] Melisa Bok. 2022. Comment on issue: Transphobic name and email policy. https://github.com/openreview/openreview/issues/28#issuecomment-1124245541[17] Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, andAdam Tauman Kalai. 2016. Man is to Computer Programmer as Woman isto Homemaker? Debiasing Word Embeddings. Advances in Neural InformationProcessing Systems 29 (2016).[18] Yang Trista Cao and Hal Daumé III. 2020. Toward Gender-Inclusive CoreferenceResolution. In Proceedings of the 58th Annual Meeting of the Association forComputational Linguistics. Association for Computational Linguistics, Online,4568–4595. https://doi.org/10.18653/v1/2020.acl-main.418[19] Logan S Casey, Sari L Reisner, Mary G Findling, Robert J Blendon, John MBenson, Justin M Sayde, and Carolyn Miller. 2019. Discrimination in the UnitedStates: Experiences of lesbian, gay, bisexual, transgender, and queer Americans.Health services research 54 (2019), 1454–1466.[20] EACech and TJWaidzunas. 2021. Systemic inequalities for LGBTQprofessionalsin STEM. Science advances 7, 3 (2021), eabe0933.[21] Erin A. Cech and Michelle Pham. 2017. Queer in STEM Organizations: Work-place Disadvantages for LGBT Employees in STEM Related Federal Agencies.The Social Sciences 6 (2017), 12.[22] Erin A. Cech and Michelle V. Pham. 2017. Queer in STEM Organizations: Work-place Disadvantages for LGBT Employees in STEM Related Federal Agencies.Social Sciences 6, 1 (2017). https://doi.org/10.3390/socsci6010012[23] Pia Ceres. 2022. Kids are back in classrooms and laptops are still spying onthem. Wired (Aug 2022). https://www.wired.com/story/student-monitoring-software-privacy-in-schools/[24] Soon Kyu Choi, Shahrzad Divsalar, Jennifer Flórez-Donado, Krystal Kit-tle, Andy Lin, Ilan H. Meyer, and Prince Torres-Salazar. 2019. STRESS,HEALTH, AND WELL-BEING OF LGBT PEOPLE IN COLOMBIA. https://www.ohchr.org/sites/default/files/Documents/Issues/SexualOrientation/IESOGI/Academics/1912_Colombia_Report_English_FINAL.pdf[25] Camille Cobb, Ted McCarthy, Annuska Perkins, Ankitha Bharadwaj, JaredComis, Brian Do, and Kate Starbird. 2014. Designing for the deluge: under-standing & supporting the distributed, collaborative work of crisis volunteers.In Proceedings of the 17th ACM conference on Computer supported cooperativework & social computing. 888–899.[26] Patricia Hill Collins. 2019. Intersectionality as critical social theory. DukeUniversity Press.[27] Patricia Hill Collins and Sirma Bilge. 2020. Intersectionality. JohnWiley & Sons.[28] Susan E Collins, Seema L Clifasefi, Joey Stanton, Kee JE Straits, Eleanor Gil-Kashiwabara, Patricia Rodriguez Espinosa, Andel V Nicasio, Michele P Andrasik,StarlynMHawes, Kimberly AMiller, et al. 2018. Community-based participatoryresearch (CBPR): Towards equitable involvement of community in psychologyresearch. American Psychologist 73, 7 (2018), 884.[29] Bill Cooke and Uma Kothari. 2001. Participation. Zed Books, London, England.[30] A. Feder Cooper, Ellen Abrams, and NA NA. 2021. Emergent Unfairness inAlgorithmic Fairness-Accuracy Trade-Off Research. In Proceedings of the 2021AAAI/ACM Conference on AI, Ethics, and Society. ACM. https://doi.org/10.1145/3461702.3462519[31] SamCorbett-Davies and Sharad Goel. 2018. Themeasure andmismeasure of fair-ness: A critical review of fair machine learning. arXiv preprint arXiv:1808.00023(2018). https://arxiv.org/abs/1808.00023[32] Sasha Costanza-Chock. 2018. Design justice: Towards an intersectional feministframework for design theory and practice. Proceedings of the Design ResearchSociety (2018).[33] Jakub Dalek, Nica Dumlao, Miles Kenyon, Irene Poetranto, Adam Senft, CarolineWesley, Arturo Filastò, Maria Xynou, and Amie Bishop. 2021. No Access:LGBTIQ Website Censorship in Six Countries. (2021). https://citizenlab.ca/2021/08/no-access-lgbtiq-website-censorship-in-six-countries/[34] Deep Learning Indaba 2017. https://deeplearningindaba.com/2021/[35] Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, JeffPhillips, and Kai-Wei Chang. 2021. Harms of Gender Exclusivity and Chal-lenges in Non-Binary Representation in Language Technologies. In Proceedingsof the 2021 Conference on Empirical Methods in Natural Language Processing.Association for Computational Linguistics, Online and Punta Cana, DominicanRepublic, 1968–1994. https://doi.org/10.18653/v1/2021.emnlp-main.150[36] Michael A DeVito, Ashley Marie Walker, and Jeremy Birnholtz. 2018. ’Too Gayfor Facebook’: Presenting LGBTQ+ Identity Throughout the Personal SocialMedia Ecosystem. Proceedings of the ACM on Human-Computer Interaction 2,CSCW (2018), 1–23.[37] Michael A DeVito, Ashley Marie Walker, Caitlin Lustig, Amy J Ko, Katta Spiel,Alex A Ahmed, Kimberley Allison, Morgan Scheuerman, Briana Dym, Jed RBrubaker, et al. 2020. Queer in HCI: Supporting LGBTQIA+ Researchers andResearch Across Domains. In Extended Abstracts of the 2020 CHI Conference onHuman Factors in Computing Systems. 1–4.[38] Catherine D’ignazio and Lauren F Klein. 2020. Data feminism. MIT press.[39] Diversity in AI (n.d.). http://www.diverseinai.org[40] Jesse Dodge, Maarten Sap, AnaMarasović, William Agnew, Gabriel Ilharco, DirkGroeneveld, Margaret Mitchell, and Matt Gardner. 2021. Documenting LargeWebtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. arXivpreprint arXiv:2104.08758 (Nov. 2021), 1286–1305. https://doi.org/10.18653/v1/2021.emnlp-main.98[41] Jack Drescher. 2015. Out of DSM: Depathologizing homosexuality. Behavioralsciences 5, 4 (2015), 565–575.[42] Ashe Dryden. 2013. CODES OF CONDUCT 101 + FAQ. Link.[43] Ashe Dryden. 2013. Increasing Diversity at Your Conference. Link.[44] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S.Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd Innovationsin Theoretical Computer Science Conference. https://doi.org/10.1145/2090236.2090255[45] Russell Rowe Dynes. 1970. Organized behavior in disaster. Heath LexingtonBooks.[46] Val Elefante. 2021. Lips. Queer in AI Workshop at International Conference onMachine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax[47] ELLIS. 2022. ELLIS PhD Program: Call for applications 2022. https://ellis.eu/news/ellis-phd-program-call-for-applications-2022[48] Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, andSuresh Venkatasubramanian. 2015. Certifying and Removing Disparate Impact.In Proceedings of the 21th ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining (Sydney, NSW, Australia) (KDD ’15). Association forComputing Machinery, New York, NY, USA, 259–268. https://doi.org/10.1145/2783258.2783311[49] Myra Marx Ferree. 2016. The discursive politics of feminist intersectionality.In Framing Intersectionality. Routledge, 55–65.[50] Michelle Fine and María Elena Torre. 2006. Intimate details: Participatory actionresearch in prison. Action Research 4, 3 (2006), 253–269.[51] Aoife Finn, Peter-Lucas Jones, Keoni Mahelona, Suzanne Duncan, and GiannaLeoni. 2022. Developing a Part-Of-Speech tagger for te reo Māori. In Proceedingsof the Fifth Workshop on the Use of Computational Methods in the Study ofEndangered Languages. 93–98.[52] Will Fleisher. 2021. What’s Fair about Individual Fairness? Association forComputing Machinery, New York, NY, USA, 480–490. https://doi.org/10.1145/3461702.3462621[53] Luciano Floridi. 2019. Establishing the rules for building trustworthy AI. NatureMachine Intelligence 1, 6 (2019), 261–262.[54] Allen Institute for Artificial Intelligence. (n.d.). https://allenai.org/[55] Association for Computational Linguistics. (n.d.). https://www.aclweb.org/[56] Office for National Statistics. 2021. National identity, ethnic group, lan-guage and religion question development for Census 2021. https://www.ons.gov.uk/census/censustransformationprogramme/questiondevelopment/nationalidentityethnicgrouplanguageandreligionquestiondevelopmentforcensus2021[57] National Science Foundation. (n.d.). https://www.nsf.gov/[58] Jon Freeman. 2023. Letter to the NSF Director. https://static1.squarespace.com/static/545d3fabe4b0811b5cc48193/t/63c867aefb89f3761070a5a3/1674078140137/Letter+to+NSF+Director+-+LGBTQ%2B+Data_redacted.pdf[59] Jonathan B. Freeman. 2020. Measuring and Resolving LGBTQ Disparities inSTEM. Policy Insights from the Behavioral and Brain Sciences 7 (2020), 141 – 148.[60] Paolo Gaudiano. 2021. Exposure doesn’t pay: Why tech conferences shouldcompensate their speakers. https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/.https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/[61] GDPR Personal Data (n.d.). GDPR Personal Data. https://gdpr-info.eu/issues/personal-data/[62] Timnit Gebru and Emily Denton. 2021. Beyond Fairness. https://neurips.cc/virtual/2021/tutorial/21889Organizers of QueerInAI, et al.[63] Christine Geeng, Mike Harris, Elissa Redmiles, and Franziska Roesner. 2021.Queer Security Advice in the US. (2021).[64] Christine Geeng and Alexis Hiniker. 2021. LGBTQ privacy concerns on socialmedia. arXiv preprint arXiv:2112.00107 (2021).[65] A Gomes, D Antonialli, and T Dias-Oliva. 2019. Drag queens and artificialintelligence. Should computers decide what is toxic on the internet. InternetLab blog (2019). https://internetlab.org.br/en/news/drag-queens-and-artificial-intelligence-should-computers-decide-what-is-toxic-on-the-internet/[66] Mary L Gray and Siddharth Suri. 2019. Ghost work: How to stop Silicon Valleyfrom building a new global underclass. Eamon Dolan Books.[67] LW Green, MA George, et al. 2003. Appendix C: Guidelines for participatoryresearch in health promotion. In Community-based participatory research forhealth, M. Minkler and N. Wallerstein (Eds.). San Francisco, CA, Jossey-Bass.[68] Christina E. Gringeri, Stéphanie Wahab, and Ben Anderson-Nathe. 2010. WhatMakes it Feminist?: Mapping the Landscape of Feminist Social Work Re-search. Affilia 25, 4 (2010), 390–405. https://doi.org/10.1177/0886109910384072arXiv:https://doi.org/10.1177/0886109910384072[69] Carlos Gutierrez. 2018. Data Privacy Is Crucial for the LGBT Community. (2018).https://staysafeonline.org/blog/data-privacy-crucial-lgbt-community/[70] Kevin Guyan. 2022. Fixing the Wrong Problems: Queer Communities and theFalse Promise of Unbiased and Equal Data Systems. European Data ProtectionLaw Review 8, 4 (2022). https://doi.org/10.21552/edpl/2022/4/5[71] Karen Hacker and J. Glover Taylor. 2011. Community-Engaged Research101. https://catalyst.harvard.edu/publications-documents/community-engaged-research-101-2/[72] Alex Hanna, Emily Denton, Andrew Smart, and Jamila Smith-Loud. 2020. To-wards a Critical Race Methodology in Algorithmic Fairness. In Proceedings ofthe 2020 Conference on Fairness, Accountability, and Transparency (Barcelona,Spain) (FAT* ’20). Association for Computing Machinery, New York, NY, USA,501–512. https://doi.org/10.1145/3351095.3372826[73] Gary W Harper, Pedro A Serrano, Douglas Bruce, and Jose A Bauermeister.2016. The internet’s multiple roles in facilitating the sexual orientation identitydevelopment of gay and bisexual male adolescents. American journal of men’shealth 10, 5 (2016), 359–376.[74] Oliver Haug. 2021. TikTokers Are Using Grindr to Out LGBTQ+ Olympians,Potentially Endangering Their Lives. Them (2021). https://www.them.us/story/tiktokers-use-grindr-out-lgbtq-olympians/[75] IEEE. (n.d.). IEEE Author Name Change Policy. https://conferences.ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/ieee-author-name-change-policy/ [Accessed Feb 2023].[76] DisAbility in AI. (n.d.). https://elesa.github.io/ability_in_AI[77] Indigenous in AI (n.d.). https://indigenousinai.org/[78] Abigail Z. Jacobs and Hanna Wallach. 2021. Measurement and Fairness. InProceedings of the 2021 ACM Conference on Fairness, Accountability, and Trans-parency (Virtual Event, Canada) (FAccT ’21). Association for Computing Ma-chinery, New York, NY, USA, 375–385. https://doi.org/10.1145/3442188.3445901[79] Khari Johnson. 2021. Black and Queer AI Groups Say They’ll Spurn GoogleFunding. Wired (2021). https://www.wired.com/story/black-queer-ai-groups-spurn-google-funding/[80] Khari Johnson. 2022. HowWrongful Arrests Based on AI Derailed 3 Men’s Lives.Wired (2022). https://www.wired.com/story/wrongful-arrests-ai-derailed-3-mens-lives/[81] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek,Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A A Kohl, Andrew JBallard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, RishubJain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy,Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer,Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W Senior, KorayKavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021. Highly accurateprotein structure prediction with AlphaFold. Nature 596, 7873 (2021), 583–589.https://doi.org/10.1038/s41586-021-03819-2[82] Pratyusha Kalluri. 2020. Don’t ask if artificial intelligence is good or fair, askhow it shifts power. Nature 583, 169 (2020).[83] Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler,Aaron Tam, Corinne Bintz, Daniella Raz, and PM Krafft. 2020. Toward situatedinterventions for algorithmic equity: lessons from the field. In Proceedings ofthe 2020 conference on fairness, accountability, and transparency. 45–55.[84] Os Keyes. 2018. The misgendering machines: Trans/HCI implications of auto-matic gender recognition. Proceedings of the ACM on human-computer interac-tion 2, CSCW (2018), 1–22. https://doi.org/10.1145/3274357[85] Os Keyes. 2019. Counting the Countless: Why data science is a profound threatfor queer people. Real Life 2 (2019).[86] Os Keyes, Zoë Hitzig, and Mwenza Blell. 2021. Truth from the machine: artificialintelligence and the materialization of identity. Interdisciplinary Science Reviews46 (2021), 158 – 175.[87] Khipu. (n.d.). https://khipu.ai/committee-2023/[88] Youjin Kong. 2022. Are “Intersectionally Fair” AI Algorithms Really Fairto Women of Color? A Philosophical Analysis. In 2022 ACM Conference onFairness, Accountability, and Transparency (Seoul, Republic of Korea) (FAccT’22). Association for Computing Machinery, New York, NY, USA, 485–494.https://doi.org/10.1145/3531146.3533114[89] Andrey Kormilitzin, Nenad Tomasev, Kevin R McKee, and DanW Joyce. 2023. Aparticipatory initiative to include LGBT+ voices in AI for mental health. NatureMedicine (2023), 1–2.[90] Gary A Kreps and Susan Lovegren Bosworth. 1994. Organizing, role enactment,and disaster: A structural theory. University of Delaware Press.[91] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counter-factual Fairness. In Advances in Neural Information Processing Systems, I. Guyon,U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett(Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf[92] Katie Langin. 2023. NSF still won’t track sexual orientation among scientificworkforce, prompting frustration. https://www.science.org/content/article/nsf-still-won-t-track-sexual-orientation-among-scientific-workforce-prompting[93] LatinX in AI (n.d.). https://www.latinxinai.org[94] Neil Lawrence. 2021. Comment on pull request: Fix author name. https://github.com/mlresearch/v119/pull/4#issuecomment-760081621[95] Jason Edward Lewis, Angie Abdilla, Noelani Arista, KaipulaumakaniolonoBaker, Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, MeredithColeman, Ashley Cordes, Joel Davison, et al. 2020. Indigenous protocol andartificial intelligence position paper. (2020).[96] Peizhao Li, Yifei Wang, Han Zhao, Pengyu Hong, and Hongfu Liu. 2021. OnDyadic Fairness: Exploring and Mitigating Bias in Graph Connections. In In-ternational Conference on Learning Representations. https://openreview.net/forum?id=xgGS6PmzNq6[97] Yanan Long. 2021. Automatic Gender Recognition: Perspectives from Phe-nomenological Hermeneutics. Queer in AI Workshop at International Conferenceon Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax[98] Christina Lu, Jackie Kay, and Kevin McKee. 2022. Subverting machines, fluctu-ating identities: Re-learning human categorization. In 2022 ACM Conference onFairness, Accountability, and Transparency. 1005–1015.[99] Sarah Maiter, Laura Simich, Nora Jacobson, and Julie Wise. 2008. Reciprocity:An ethic for community-based participatory action research. Action research 6,3 (2008), 305–325.[100] Miranda Marquit. 2018. Survey: 60% of LGBTQ Student Borrowers RegretTaking Out Student Loans. (2018). https://www.lendingtree.com/student/lgbtq-student-borrowers-regret-loans-survey/[101] Masakhane (n.d.). https://www.masakhane.io[102] Lyndsey McMillon-Brown. 2021. Implementing diversity, equity and inclusionefforts at conferences. Nature Energy 6, 11 (2021), 1000–1002.[103] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and AramGalstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACMComput. Surv. 54, 6, Article 115 (jul 2021), 35 pages. https://doi.org/10.1145/3457607[104] Doug Meyer. 2015. Violence against queer people: Race, class, gender, and thepersistence of anti-LGBT discrimination. Rutgers University Press.[105] Muslims in ML. (n.d.). http://www.musiml.org/[106] Name Change Policy Working Group (n.d.). Name Change Policy WorkingGroup. https://ncpwg.org/[107] NeurIPS. (n.d.). NeurIPS Proceedings: Name Change Policy. https://papers.nips.cc/, “Name Change Policy” link in footer [Accessed Feb 2023].[108] Inc Nike. (n.d.). https://sportai.splashthat.com/[109] North Africans in ML. (n.d.). https://sites.google.com/view/northafricansinml[110] North American Chapter of the Association for Computational Linguistics.(n.d.). https://naacl.org[111] Molly Olmstead. 2021. A Prominent Priest Was Outed for Using Grindr. ExpertsSay It’s a Warning Sign. Slate (2021). https://slate.com/technology/2021/07/catholic-priest-grindr-data-privacy.html[112] Conference on Empirical Methods in Natural Language Processing. (n.d.). https://emnlp.org/[113] International Conference on Machine Learning. (n.d.). https://icml.cc/[114] Conference on Neural Information Processing Systems. (n.d.). https://neurips.cc/[115] ORCID (n.d.). Open Researcher and Contributor ID (ORCID). https://orcid.org/[116] Amandalynne Paullada, Inioluwa Deborah Raji, Emily M. Bender, Emily Denton,and Alex Hanna. 2021. Data and its (dis)contents: A survey of dataset devel-opment and use in machine learning research. Patterns 2, 11 (2021), 100336.https://doi.org/10.1016/j.patter.2021.100336[117] Matt Payton. 2021. Egyptian police ’are using Grindr to find and arrest LGBTpeople’. The Independent (2021). https://www.independent.co.uk/news/world/africa/egyptian-police-grindr-dating-app-arrest-lgbt-gay-antigay-lesbian-homophobia-a7211881.htmlQueer In AI: A Case Study in Community-Led Participatory AI[118] Billy Perrigo. 2023. OpenAI Used Kenyan Workers on Less Than $2 Per Hourto Make ChatGPT Less Toxic. Time (2023). https://time.com/6247678/openai-chatgpt-kenya-workers/[119] Anthony T Pinter, Morgan Klaus Scheuerman, and Jed R Brubaker. 2021. Enter-ing Doors, Evading Traps: Benefits and Risks of Visibility During TransgenderComingOuts. Proceedings of the ACM onHuman-Computer Interaction 4, CSCW3(2021), 1–27.[120] Anastasia Powell, Adrian J Scott, and Nicola Henry. 2020. Digital harassmentand abuse: Experiences of sexuality and gender minority adults. Europeanjournal of criminology 17, 2 (2020), 199–223.[121] ACL Pubcheck. (n.d.). https://github.com/acl-org/aclpubcheck [Accessed Feb2023].[122] Queer in AI at NeurIPS 2021. http://queerinai.org/neurips-2021[123] Queer in AI Organizers. 2019. Code of Conduct. https://sites.google.com/view/queer-in-ai/code-of-conduct.[124] Queer in AI YouTube Channel (n.d.). Queer in AI YouTube Channel. https://www.youtube.com/channel/UCXyVUke1cCnYNBwLsxCxQxg/videos[125] Organizers of QueerInAI, A Pranav, MaryLena Bleile, Arjun Subramonian, LucaSoldaini, Danica J. Sutherland, Sabine Weber, and Pan Xu. 2021. How to MakeVirtual Conferences Queer-Friendly: A Guide. In Proceedings of the 2021 Work-shop on Widening NLP. Conference on Empirical Methods in Natural LanguageProcessing, Punta Cana, Dominican Republic. queerinai.org/diversity-guide[126] Organizers of QueerInAI, Ashwin S, William Agnew, Hetvi Jethwani, and ArjunSubramonian. 2021. Rebuilding Trust: Queer in AI Approach to ArtificialIntelligence Risk Management. queerinai.org/risk-management[127] Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, PiotrMirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, SamMadge, et al. 2021. Skilful precipitation nowcasting using deep generativemodels of radar. Nature 597, 7878 (2021), 672–677.[128] Joanna Redden, Jessica Brand, and Vanesa Terzieva. 2020. Data Harm Record(Updated). (2020). https://datajusticelab.org/data-harm-record/[129] Eva Reid. 2021. How To Make Conference Speaker Fees More Inclusive AndEquitable. hhttps://technical.ly/2021/07/22/conferences-pay-speakers//. https://technical.ly/2021/07/22/conferences-pay-speakers/[130] Christina R. Richey, Katharine M N Lee, Erica M. Rodgers, and Kathryn B. H.Clancy. 2019. Gender and sexual minorities in astronomy and planetary sci-ence face increased risks of harassment and assault. Bulletin of the AmericanAstronomical Society 51 (2019), 0206.[131] Nancy Russell, Susan Igras, Nalin Johri, Henrietta Kuoh, Melinda Pavin, andJane Wickstrom. 2008. ACQUIRE Project Working Paper. https://pdf.usaid.gov/pdf_docs/Pnadm497.pdf[132] Morgan Klaus Scheuerman, Aaron Jiang, Katta Spiel, and Jed R. Brubaker.2021. Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with(Non-)Binary People. In Proceedings of the 2021 CHI Conference on HumanFactors in Computing Systems (Yokohama, Japan) (CHI ’21). Association forComputing Machinery, New York, NY, USA, Article 400, 18 pages. https://doi.org/10.1145/3411764.3445742[133] Morgan Klaus Scheuerman, Madeleine Pape, and Alex Hanna. 2021. Auto-essentialization: Gender in automated facial analysis as extended colonialproject. Big Data & Society 8, 2 (2021), 20539517211053712.[134] Morgan Klaus Scheuerman, Jacob M Paul, and Jed R Brubaker. 2019. Howcomputers see gender: An evaluation of gender classification in commercialfacial analysis services. Proceedings of the ACM on Human-Computer Interaction3, CSCW (2019), 1–33.[135] Natalie Schluter. 2018. The glass ceiling in NLP. In Proceedings of the 2018Conference on Empirical Methods in Natural Language Processing. 2793–2798.[136] Sarah Schulman. 2021. Let the Record Show: A Political History of ACT UP NewYork, 1987-1993. Farrar, Straus and Giroux.[137] Louise Seamster and Raphaël Charron-Chénier. 2017. Predatory Inclu-sion and Education Debt: Rethinking the Racial Wealth Gap. SocialCurrents 4, 3 (2017), 199–207. https://doi.org/10.1177/2329496516686620arXiv:https://doi.org/10.1177/2329496516686620[138] Semantic Scholar (n.d.). Semantic Scholar. https://semanticscholar.org/[139] Tom Simonite. 2021. AI and the List of Dirty, Naughty, Obscene, and OtherwiseBad Words. Wired (2021). https://www.wired.com/story/ai-list-dirty-naughty-obscene-bad-words/[140] Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022. Par-ticipation Is Not a Design Fix for Machine Learning. In Equity and Access inAlgorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO ’22).Association for Computing Machinery, New York, NY, USA, Article 1, 6 pages.https://doi.org/10.1145/3551624.3555285[141] Shakira Smith, Oliver L Haimson, Claire Fitzsimmons, and Nikki EcharteBrown. 2021. Censorship of Marginalized Communities on Instagram. Salty(2021). https://saltyworld.net/exclusive-report-censorship-of-marginalized-communities-on-instagram-2021-pdf-download/[142] Dean Spade. 2020. Mutual aid: Building solidarity during this crisis (and the next).Verso Books.[143] Robyn Speer. 2021. Google Scholar deadnames trans authors and ob-structs their name change. Link. https://docs.google.com/document/d/1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE[144] Robyn Speer. 2021. Google Scholar has failed us. (2021). https://scholar.hasfailed.us/[145] Kate Starbird and Leysia Palen. 2011. \"Voluntweeters\" self-organizing by digitalvolunteers in times of crisis. In Proceedings of the SIGCHI conference on humanfactors in computing systems. 1071–1080.[146] Luke Stark and Jevan Hutson. 2021. Physiognomic Artificial Intelligence. Avail-able at SSRN 3927300 32, 4 (2021), 922.[147] Arjun Subramonian. 2022. On Dyadic Fairness: Exploring and Mitigating Biasin Graph Connections. In ICLR Blog Track. https://iclr-blog-track.github.io/2022/03/25/dyadic-fairness/ https://iclr-blog-track.github.io/2022/03/25/dyadic-fairness/.[148] Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, IsadoraCruxen, Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, and CatherineD’Ignazio. 2022. Towards Intersectional Feminist and Participatory ML: ACase Study in Supporting Feminicide Counterdata Collection. In 2022 ACMConference on Fairness, Accountability, and Transparency (Seoul, Republic ofKorea) (FAccT ’22). Association for Computing Machinery, New York, NY, USA,667–678. https://doi.org/10.1145/3531146.3533132[149] Danica J. Sutherland. 2022. Name Change Policies: A Brief (Personal) Tour.Queer in AI workshop, NeurIPS 2022; https://djsutherland.ml/slides/qai-name-change.[150] Latanya Sweeney. 2000. Simple Demographics Often Identify People Uniquely.(2000). http://dataprivacylab.org/projects/identifiability/[151] Rajesh Tandon. 1988. Social transformation and participatory research. Con-vergence 21, 2 (1988), 5.[152] Theresa Jean Tanenbaum, Irving Rettig, H Michael Schwartz, BM Watson,Teddy G Goetz, Katta Spiel, and Mike Hill. 2021. A vision for a more trans-inclusive publishingworld: guest article. Committee on Publication Ethics. https://publicationethics.org/news/vision-more-trans-inclusive-publishing-world.[153] NAACL DEI Team. (n.d.). NAACL Citation Name Change Procedure. https://2021.naacl.org/blog/name-change-procedure/ [Accessed Feb 2023].[154] Jens T. Theilen, Andreas Baur, Felix Bieker, Regina Ammicht Quinn, MaritHansen, and Gloria González Fuster. 2021. Feminist data protection: an in-troduction. Internet Policy Review (2021). https://policyreview.info/articles/analysis/feminist-data-protection-introduction[155] Nenad Tomasev, Kevin R McKee, Jackie Kay, and Shakir Mohamed. 2021. Fair-ness for Unobserved Characteristics: Insights from Technological Impactson Queer Communities. arXiv preprint arXiv:2102.04257 (2021). https://doi.org/10.1145/3461702.3462540[156] Toronto Public Library 2022. https://www.crowdcast.io/e/tpl_aiequityinclusion[157] Paige Yes Treebridge. 2021. Crowdsourcing a Corpus of Dogwhistle Transphobia.Queer in AI Workshop at International Conference on Machine Learning 2021(2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax[158] Fangjing Tu. 2022. What can we learn from longitudinal studieson the impacts of college internships? https://ccwt.wisc.edu/wp-content/uploads/2022/04/Final_CCWT_report_LR-What-can-we-learn-from-longitudinal-studies-on-the-impacts-of-college-internships.pdf[159] Ayesha IT Tulloch. 2020. Improving sex and gender identity equity and inclusionat conservation and ecology conferences. Nature Ecology & Evolution 4, 10(2020), 1311–1320.[160] Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, EdgardoFerran, George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer,et al. 2019. Applications of machine learning in drug discovery and development.Nature Reviews Drug discovery 18, 6 (2019), 463–477.[161] The Asexual Visibility and Education Network. (n.d.). http://www.asexuality.org/[162] Lindsay Weinberg. 2022. Rethinking Fairness: An Interdisciplinary Survey ofCritiques of Hegemonic ML Fairness Approaches. Journal of Artificial Intelli-gence Research 74 (2022), 75–109.[163] Widening NLP (n.d.). http://www.winlp.org[164] Bianca DM Wilson, Soon Kyu Choi, Gary W Harper, Marguerita Lightfoot,Stephen Russell, and Ilan H Meyer. 2020. Homelessness among LGBT adults inthe US. https://williamsinstitute.law.ucla.edu/publications/lgbt-homelessness-us/[165] Women in Machine Learning. 2021. Code of Conduct. https://wimlworkshop.org/conduct/.[166] Women in Machine Learning (n.d.). https://wimlworkshop.org[167] Aman Yadav, Christopher D Seals, Cristina M Soto Sullivan, Michael Lachney,Quintana Clark, Kathy GDixon, andMark JT Smith. 2020. The forgotten scholar:underrepresented minority postdoc experiences in STEM fields. EducationalStudies 56, 2 (2020), 160–185.Organizers of QueerInAI, et al.A THE LIMITS OF COMPUTATIONALMETHODS TO ACHIEVE FAIRNESSComputational approaches to fair machine learning ensure that modelssatisfy certain mathematical formulations of fairness or don’t capture socialbiases. For example, a fair model may treat similar individuals similarly(individual fairness), predict similar outcomes across sensitive attributes(group fairness), or learn representations that are high-quality for all indi-viduals and don’t encode stereotypes related to sensitive attributes [31, 52].Different operationalizations of fairness in machine learning encode differ-ent theoretical understandings of fairness, and many operationalizations,due to their quantitative nature and focus on parity, don’t capture notionsof fairness based in, for example, representational justice [78]. Many re-searchers consider vectors of unfairness in machine learning models toinclude tainted examples (e.g., historical data that capture stereotypes anddiscrimination), limited features (e.g., unobserved features for marginalizedcommunities), and sample size disparities (e.g., significantly fewer datafor minoritized groups) [8]. However, researchers often neglect how thesevectors result from interlocking power relations and the social inequalitythat these relations produce [88].Current paradigms for ensuring fairness in machine learning largely relyon historical data and observed attributes [8]. Causality is emerging as alens through which fairness can be observed under intervention [8, 91], butit too assumes that sensitive attributes and identities are known, whichis often not the case due to privacy laws and the dangers involved in dis-closing certain sensitive attributes (e.g., disability, queerness, etc.) [61, 154];measurable, which is almost never true (e.g., gender) [35]; discrete, whichreinforces hegemonic, colonial categorizations (e.g., race and ethnicity op-tions on the US/UK census, the gender binary, etc.) [56, 72]; and static,which is problematic given that one’s identity can change over time (e.g.,genderfluidity) [35]. These assumptions especially pose problems in the con-text of queerness since sexuality and gender identity are often “unobservedcharacteristics, which are frequently missing, unknown, or fundamentallyunmeasurable” [155]. Furthermore, observational fairness neglects thatsome communities face complex, intersecting vectors of marginality thatpreclude their presence in the very data observed for fairness.Another pitfall of fair machine learning is the tendency to mitigate biasesin models posthoc; any model that is created without queer people in mindand is band-aided after the fact to protect them from harmwill still inevitablyharm them. Additionally, to improve model fairness for queer communities,current paradigms of fairness dictate to collect more data on them, whichexposes queer people to predatory inclusion, serious privacy risks, and evenviolence [30, 62, 64, 126, 137]. Data are often not collected consensually[116]. Furthermore, given the dire underrepresentation of queer people indatasets to begin with, without caution, even simple demographics canuniquely identify queer persons [150]. This could be disastrous for queerpeople living under violent, oppressive institutions.Not all fair machine learning models distribute justice to queer commu-nities. For instance, applications of fair link prediction in social networksto deliver content or connection recommendations that are independent ofusers’ identities could be problematic [96, 147]. Many LGBTQIA+ peoplecreate and rely on the sanctity of safe spaces online [73]. Thus, recommend-ing them users or news sources that are hostile (e.g., promote homophobic,racist, or sexist content) can result in severe psychological harm and a vio-lation of privacy. Furthermore, many queer individuals feel isolated in reallife and actually yearn to find other users online who share their identity,to which fair link prediction is antithetical [161]. Moreover, fairness doesnot benefit a model that is inherently flawed. Researchers have attemptedto build neural networks to infer sexuality from images of people, however,sexuality is fundamentally not detectable by a human or machine learningmodel [4]. As such, no amount of fairness can compensate for the reality thatthe premise of the model is based in physiognomy [146] and assumes thebiological essentialism of sexuality and expression. Furthermore, a sexualitydetection system, regardless of how effective, may be easily weaponized byoppressive institutions against queer and cishet people alike, with severerepresentational and allocational harms, from violation of privacy to death.Fairness cannot help such a system intended to police queer bodies.Finally, time after time, institutions that claim to act without discrimi-nating on the basis of protected class can produce disparate impact [48].Similarly, machine learning models that purportedly make decisions inde-pendently of sensitive attributes automate systemic oppression. A modelthat assists and benefits queer people will take into account queer identitiesand actively strive to improve societal equity.B QUEER IN AI SURVEYSThis section overviews the creation of and methodologies Queer in AIemploys in administering its demographic survey. Following this, surveyresults for Queer in AI’s organizers and community are presented.B.1 Queer-Inclusive Data ScienceData science and analytics have historically been weaponized againstmarginalized communities, including queer people, by justifying policiesthat permit or amplify inequality and discrimination [128]. Data collectionoften also poses serious privacy and security risks to queer communities[69, 128]. Queer in AI attempts to, in part, reclaim data science as a tool forjustice. Queer in AI administers an organizer survey (§B.5) to understandorganizers’ identities, their motivations for and obstacles to volunteering,and other issues that they face, as well as a related community survey(§B.6).B.2 Curation RationaleThe responses to Queer in AI’s organizer survey7 are used to better under-stand organizers’ identities, their motivations for and obstacles to volun-teering, and other issues that they face. The community survey8 is usedto identify issues within queer communities, shape the future programs ofQueer in AI, and inform its operation. In particular, Queer in AI uses thecommunity survey for:• understanding issues and status of queer communities,• understanding queer intersectionality• collecting info on trans-inclusive publications,• collecting info on queer inclusivity in academia and conferences,• shaping Queer in AI mentoring programs,• getting feedback on Queer in AI socials and initiatives.B.3 Data Collection PolicyThe organizer survey is only sent out to Queer in AI organizers via Slack.The community survey is sent out to Queer in AI members via Slack, all at-tendees of Queer in AI socials and workshops, and is placed on top of Queerin AI’s website. Respondents can be anonymous while entering the surveyresponses. All questions in both surveys are optional; in demographic ques-tions like gender and sexual orientation, respondents can choose multipleresponses; and many questions allow free-text responses. Only a handful ofQueer in AI organizers have access to these responses. Folks can contactQueer in AI to delete the information if they want. LGBTQ Crisis Hotlinesare linked in the survey considering the nature of the questions.B.4 Survey Curators’ DemographicsThe surveys were designed in collaboration with gender theory scholarsand transgender, gender-diverse and BIPOC members of Queer in AI. All ofthe curators have informal training in queer studies through activism and7https://forms.gle/oSHTtpkdzUvpNhQL68https://docs.google.com/forms/d/e/1FAIpQLSes-lzwkKHruQrAmH3Tnz1tJsTUl-YP51V8wDtHbfb8Z9FoNg/viewformQueer In AI: A Case Study in Community-Led Participatory AIadvocacy in Queer in AI and affiliated groups. The curation team consisted of8 members. They ranged in age from 21-35 years, with gender including men(2), women (2), non-binary folks (2), agender individual (1) and genderfluid(1). 5 of them are transgender. 5 of them are BIPOC. Region-wise, 1 is fromEast Asia, 1 is from Europe, 1 is from South Africa, 1 is from South Americaand 4 are from North America.B.5 Queer in AI OrganizersDecentralized, participatory organizations are in large part defined by thepeople who volunteer to run events and initiatives. To empower and repre-sent the queer community, in all its diversity (not just across gender andsexual and romantic orientations, but also disability, ethnicity, place of ori-gin, economic background, and many more) it is vital to recruit, train, andretain a diverse set of volunteers. This section discusses the demographicsof Queer in AI’s volunteers and Queer in AI’s experiences in recruiting andtraining their volunteers.Figures A3a, A3b, A9, A10, and Table A1 present demographics of Queerin AI’s organizers based on a recent survey. To protect anonymity, categorieswith less than or equal to three responses are marked by *. Most organizersidentify as gay, bisexual, and/or queer, and as men and/or non-binary; les-bians and women remain underrepresented. Almost all volunteers wantedto help the community, but 75% also wanted community, highlighting theimportance of socialization and fun in organizing (Figure A15). By far thebiggest challenge Queer in AI’s volunteers faced (Figure A16) was not hav-ing enough time (70%). While most volunteers have received recognitionof their work from friends, colleagues, or other volunteers, only 25% hadreceived recognition from their bosses or advisors, and none had receivedawards or other such recognition (Figure A18). The time pressures and lackof outside recognition reflects a lack of institutional support for Queer inAI: its volunteers want to contribute more, but their jobs and careers willnot support or value them doing so. Even so, volunteering with Queer inAI has helped many of its organizers professionally, with most reportinggetting the experience to organize socials, workshops or conferences, andmany reporting finding research opportunities or help applying for jobsor school through Queer in AI, both valuable connections especially giventhat a majority of its organizers are students or early-career. 85% of Queerin AI’s organizers report that volunteering has allowed them to help thecommunities they care about and 75% report being a part of a communitythat has brought them joy, showing that Queer in AI is successfully provid-ing volunteers with the things they joined for by providing a space to buildsolidarity, understanding and learning from each others experience/issues(Figure A17).Undergraduate student ≤3Graduate student 15Junior academic 6Senior academic 8Junior industry ≤3Senior industry 6Other ≤3Table A1: Queer in AI organizers’ career stagesHowever, Queer in AI’s organizers lack diversity along several importantaxes, including place of origin, ethnicity, gender identity (including transidentities), caste, neurodivergence and disability. Recent programming atworkshops has featured a variety of talks and panels centering trans, non-binary, and queer BIPOC issues, including discussions of how Queer in AIcan do better. Efforts are also continuing to help encourage communitymembers to raise any concerns about inclusivity, including feedback on thecommunity survey discussed next and through other channels.B.6 Queer in AI CommunityThis section presents five years of demographics for the Queer in AI com-munity. To protect the anonymity of survey participants, exact numbersare reported only for categories with more than three responses (categorieswith ≤ 3 are marked by *). Overall, the community has grown significantlysince 2018, with the number of survey respondents growing by almostfive-fold.Demographics. In terms of sexual orientation, most of Queer in AI mem-bers identify as gay, bisexual, or queer, with the latter category increasingsignificantly in recent years; lesbians remain underrepresented in the Queerin AI community (Figure A2). While 2021 saw a significant increase innon-binary members, men and women remain the most common genderidentities in the community (Figure A1). Since 2020, Queer in AI has also sur-veyed its members about their ethnicity (Figure A4c); community membersoverwhelmingly self-describe as white, followed by South Asian, Latinx,and East Asian. About 22% of survey respondents identify as transgender,10% as disabled, and 30% as neurodivergent.Safety. Despite recent worldwide progress in queer rights, Queer in AImembers still face significant discrimination (Table A2). 67% of membersreported to have faced at least one safety incident in 2021, the most commonbeing target of jokes and innuendos (47.9%), being deliberately ignored orexcluded (43.6%), or being singled out as resident authority (42.1%). Memberswho live in countries where queer people are persecuted have a similardistribution of incidents, but at amuch higher rate. BIPOCmembers reportedhigher rates of incidents, with 38% mentioning facing microaggressions.Mental Health. An overwhelming majority of survey respondents re-ported mental health hardships (Table A3). Many reported that mentalhealth issues have impaired their ability to conduct research (79.9%), espe-cially neurodivergent members (91.9%); About a third reported that theyhave harmed themselves or considered suicide. Results in Table A4 showthat Queer in AI members struggle the most with their mental health as astudent (43.2%); over a third has reported struggles in the last year, perhapsrelated to the continued impact of the COVID-19 pandemic.Obstacles. Members of the Queer in AI community also struggle with alack of community they can rely on (77.4%). Undergraduate students areespecially affected, with 91.6% reporting a lack of a support group theycould rely on. On a 1–5 scale, members reported a lack of representation ofnon-cisgender (1.7 / 5, Table A7), and BIPOC folks (2 / 5) in their immediatework environment (Table A9). Cisgender survey respondents remain largelyunaware of specific issues affecting non-cisgender scholars (Table A6), suchas lack of name changes policies for many academic journals. Finally, slightlymore Queer in AI members recently reported having come completely out:47% in 2021, up over 41.8% in 2020 (Table A5).B.7 Queer in AI GeographyThis section reports the country of origin and residence for Queer in AIorganizers, members, and graduate school scholarship recipients in Fig-ures A9–A10, Figures A11–A12, and Figures A13–A14 respectively.B.8 Reporting Survey Results: EthnicityAggregating human data is complicated, and transparency in the process ofaggregation is critical. We detail the choices that went into the aggregationof ethnicity responses. A group of organizers decided on a set of categories—“Mixed ethnicity,” “Black/African/African-American,” “Jewish,” “SoutheastAsian,” “West Asian,” “East Asian,” “South Asian,” “Latinx,” “Caucasian,”“Middle Eastern,” “Hispanic,” and “Unaggregated”—after a pass of the rawdata and getting feedback from multiple Queer in AI organizers and otheraffinity groups. The “Unaggregated” category was introduced to includeOrganizers of QueerInAI, et al.ManWomanQuestioningGenderfluidGenderqueerAgenderNon-binaryGendernon-conformingThird-genderPangenderBi-genderTwo-spiritedUnaggregated050100Numberofrespondents2018201920202021–2022FigureA1:Gender statistics of theQueer inAI communitymembers. Datawas collected via the demographic surveys (§B.6).Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories. “Unaggregated”refers to responses that could not be adequately described with any subset of other categories; however, responses in this groupmay overlap with the remaining categories. For categories with ≤ 3 responses (marked by *), exact numbers are omitted toprotect anonymity.GayStraightBisexualLesbianQueerAsexualPansexualDemisexualQuestioningUnaggregated020406080100Numberofrespondents2018201920202021–2022Figure A2: Sexual orientation statistics of the Queer in AI community members. Data was collected via the demographicsurveys (§B.6). Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiplecategories. “Unaggregated” refers to responses that could not be adequately described with any subset of other categories;however, responses in this group may overlap with the remaining categories. For categories with ≤ 3 responses (marked by *),exact numbers are omitted to protect anonymity.responses that the organizers felt were not adequately described by theother existing categories (e.g. responses like ‘Person of color’).Aggregation for responses that belonged to two or more categories in-volved a few heuristics. Firstly, anythingwith thewords ‘mixed’ or ‘half’ wasassigned to the “Mixed ethnicity” category. Moreover, references to multiplecategories were aggregated into each of the mentioned ones. For example,‘half white and half Indian’9 would be assigned to “Mixed,” “Caucasian,”and “South Asian.” For responses of the form ‘{Ethnic identity}–American’,the organizers chose to consider only the mentioned ethnic identity, inalignment with the discussion among Queer in AI members. Given the9Example responses in this section are not taken from the raw data and provided forillustration only.complexity of the process, Queer in AI organizers continually evaluatedbest practices for including mixed and migrant ethnic identities in futuresurveys.Although there is an overlap between the categories “West Asian” and“Middle Eastern,” organizers chose to retain both categories because “MiddleEastern” includes parts of Asia, Africa, and Europe. While the organizersrecognize that “Middle Eastern” is a Eurocentric term, they chose to retainthat as a category for this paper because several responses use that term.The organizers hope to improve this terminology in the future iterationsafter consulting the communities in question.Lastly, a lot of responses self-described themselves as “Asian.”For each such response, the organizers looked at the correspondingresponse to country of origin, and used that to aggregate it withinQueer In AI: A Case Study in Community-Led Participatory AI“East/Southeast/West/Central/South Asian.” Responses that did not clarifythe country of origin were included within the “Unaggregated” category.Organizers of QueerInAI, et al.GayStraightBisexualLesbianQueerAsexualPansexualQuestioning01020Numberofrespondents(a) Sexual orientation of Queer in AI organizers.ManWomanQuestioningGenderfluidGenderqueerAgenderNon-binaryGendernon-conformingThird-genderPangenderBi-genderUnaggregated01020Numberofrespondents(b) Gender of Queer in AI organizers.Figure A3: Sexual orientation (a) and gender (b) statistics of the Queer in AI organizers (2021–2022). Write-in responses wereaggregated by a team of Queer in AI organizers, with some falling into multiple categories. “Unaggregated” refers to responsesthat could not be adequately described with any subset of other categories; however, responses in this group may overlap withthe remaining categories. For categories with ≤ 3 responses (marked by *), exact numbers are omitted to protect anonymity.OverallOnly non-CisRespondentsOnly BIPOCRespondentsRespondents who do notlive in queer-safe countriesI feared for my physical safety 23.6% 20.9% 26.5% 37.3%I felt I was deliberately ignored or excluded 43.6% 38.4% 49.0% 56.9%I felt intimidated/bullied 31.4% 27.9% 32.7% 43.1%I observed others staring at me 39.3% 31.4% 46.9% 39.2%I received a low performance evaluation 5.0% 4.7% 6.1% 7.8%I received unsolicited physical contact 22.9% 24.4% 20.4% 27.5%I was in a hostile work environment 20.0% 16.3% 20.4% 29.4%I was pursued, followed or stalked 10.7% 11.6% 12.2% 17.6%I was singled out as the \"resident authority\"due to my identity42.1% 38.4% 32.7% 51.0%I was the target of derogatory comments(written or in person)40.7% 39.5% 36.7% 49.0%I was the target of innuendos and/or jokes 47.9% 48.8% 49.0% 68.6%I was the target of vandalism or graffiti 3.6% 5.8% 4.1% 3.9%Table A2: Share of safety incidents reported by Queer in AI members in 2021.OverallOnly non-CisRespondentsOnly BIPOCRespondentsNeurodivergentRespondentsConferences exacerbate my mentalhealth problems29.5% 28.2% 16.1% 29.0%I’ve had mental health crises at conferences 16.8% 16.5% 21.0% 19.4%I’ve harmed myself 30.2% 25.9% 25.8% 41.9%I’ve seriously considered orattempted suicide38.3% 30.6% 38.7% 56.5%My ability to conduct research or participatein classes has been impaired by mentalhealth issues79.9% 81.2% 58.1% 91.9%Table A3: Self-reported mental health of Queer in AI members in 2021.Queer In AI: A Case Study in Community-Led Participatory AIMixedethnicityBlack/African/African-AmericanSouthAsianEast AsianSoutheast AsianLatinxJewishMiddle EasternCaucasian01020Numberofrespondents(a) Queer in AI Organizers (2021–2022): Self-Reported Ethnicity.MixedethnicityBlack/African/African-AmericanSouthAsianEast AsianSoutheast AsianLatinxJewishMiddle EasternCaucasian01020Numberofrespondents(b) Queer in AI Scholarship Recipients: Self-Reported Ethnicity.CaucasianSouthAsianEast AsianBlack/African/African-AmericanLatinxMixedethnicityJewishMiddle EasternSoutheast AsianWest AsianCentral AsianHispanicUnaggregated050100150Numberofrespondents(c) Queer in AI Community (2021–2022): Self-Reported Ethnicity.Figure A4: Self-reported ethnicities of Queer in AI’s organizers (a), scholarship recipients (b), and community members (c)respectively. Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories.“Unaggregated” refers to responses that could not be adequately described with any subset of other categories; however,responses in this group may overlap with the remaining categories. For categories with ≤ 3 responses (marked by *), exactnumbers are omitted to protect anonymity.When did you feel your mental health was at the lowest point?When I was a student 43.2%Within the last year 33.7%When I was questioning my sexual orientation / gender 31.1%When I was struggling with my career 27.4%Before and during coming out stages 26.8%When I was in the country wherequeer folks are generally not accepted15.3%Table A4: Moments when Queer in AI members have struggled the most with mental health.Organizers of QueerInAI, et al.YesQuestioning No050100150200Numberofrespondents 2018201920202021–2022(a) Queer in AI Community: Are youTrans?YesQuestioning NoOther02040Numberofrespondents(b) Queer in AI Organizers: Are youTrans?YesQuestioning No02040Numberofrespondents(c) Queer in AI Scholarship Recip-ients: Are you Trans?Figure A5: Queer in AI’s statistics for transgender community members (a), organizers (b), and scholarship recipients (c)respectively. Write-in responses were aggregated by a team of Queer in AI organizers. For categories with ≤ 3 responses (markedby *), exact numbers are omitted to protect anonymity.Yes No0100200Numberofrespondents(a) Queer in AI Community (2021–2022): Are you Intersex?Yes No02040Numberofrespondents(b) Queer in AI Organizers: Areyou Intersex?Yes No02040Numberofrespondents(c) Queer in AI Scholarship Recip-ients: Are you Intersex?Figure A6: Queer in AI’s statistics for intersex communitymembers (a), organizers (b), and scholarship recipients (c) respectively.For categories with ≤ 3 responses (marked by *), exact numbers are omitted to protect anonymity.Yes NoUnsure/Other020406080100Numberofrespondents(a) Queer in AI Community (2021–2022): Are you Neurodivergent or Dis-abled?Yes No051015Numberofrespondents(b) Queer in AI Organizers:Are you Neurodivergent orDisabled?Yes NoUnsure/Other051015Numberofrespondents(c) Queer in AI Scholarship Recipi-ents: Are you Neurodivergent or Dis-abled?Figure A7: Queer in AI’s statistics for neurodivergent and/or disabled community members (a), organizers (b), and scholarshiprecipients (c) respectively. Write-in responses were aggregated by a team of Queer in AI organizers.Queer In AI: A Case Study in Community-Led Participatory AIUndergraduatestudentGraduatestudentJunioracademicSenioracademicJuniorindustrySeniorindustryUnaggregated050100Numberofrespondents2018201920202021–2022Figure A8: Career stage statistics of the Queer in AI community members. Data was collected via the demographic surveys (§B.6).Write-in responses were aggregated by a team of Queer in AI organizers. “Unaggregated” refers to responses that could not beadequately described with any subset of other categories; however, responses in this group may overlap with the remainingcategories. For categories with ≤ 3 responses (marked by *), exact numbers are omitted to protect anonymity.Note: the 2020 survey did not differentiate between the graduate and undergraduate student respondents; here we report thecombined total of these two groups under “Graduate student”.Countries Queer in AI Organizers From Originally0.00, 0.000.00, 3.003.00, 3.573.57, 5.005.00, 6.006.00, 7.00Figure A9: Queer in AI Organizers Country of Origin.Countries Queer in AI Organizers Live in 0.00,  0.00 0.00,  3.00 3.00,  3.86 3.86,  6.00 6.00, 16.0016.00, 17.00Figure A10: Countries Queer in AI Organizers Live in.Organizers of QueerInAI, et al.Countries Queer in AI Community From Originally 2018 0.00,  0.00 0.00,  3.00 3.00,  3.29 3.29,  4.29 4.29,  6.00 6.00, 11.0011.00, 12.00Countries Queer in AI Community From Originally in 2020 0.00,  0.00 0.00,  3.00 3.00,  4.14 4.14,  5.86 5.86,  9.14 9.14, 16.0016.00, 43.0043.00, 44.00Countries Queer in AI Community From Originally in 2021 0.00,  0.00 0.00,  3.00 3.00,  4.57 4.57,  8.86 8.86, 10.7110.71, 21.0021.00, 73.0073.00, 74.00Figure A11: Country Queer in AI Community From, 2018, 2020, 2021.Have you disclosed your gender and/orsexual orientation to your peers? 2020 Survey 2021 SurveyCompletely out 41.8% 47.7%Out except for certain people/not publicly 22.4% 19.7%Out to friends/family 6.1% 3.8%Out to certain friends/family 27.6% 26.5%Not out to anyone 2.0% 2.3%Table A5: Status of disclosure of gender and/or sexual orientation among Queer in AI survey respondents in 2020 and 2021.Queer In AI: A Case Study in Community-Led Participatory AICountries Queer in AI Community Lives in 2018 0.00,  0.00 0.00,  3.00 3.00,  4.57 4.57,  8.00 8.00, 23.0023.00, 24.00Countries Queer in AI Community Lives in 2020 0.00,  0.00 0.00,  3.00 3.00,  4.71 4.71,  8.14 8.14,  9.86 9.86, 15.0015.00, 58.0058.00, 59.00Countries Queer in AI Community Lives in 2021  0.00,   0.00  0.00,   3.00  3.00,   3.71  3.71,   9.14  9.14,  10.43 10.43,  12.43 12.43,  14.00 14.00, 109.00109.00, 110.00Figure A12: Country Queer in AI Community Lives in, 2018, 2020, 2021.On a scale of 1 to 5......how well represented are non-cis folks in your immediate work/research group? 1.54...how well represented are non-cis folks in Queer spaces you are part of (this includes Queer in AI)? 3.12...how often have you witnessed transphobia / microaggressions against non-cis folks? 2.90...how often have you called out transphobia / microaggressions against non-cis folks? 2.90...how much effort have you put in to make your group more inclusive of non-cis folks? 3.10...how aware are you about the name change policies in academic publications? 2.67...how aware are you about issues regarding mitigating deadnaming in citations? 2.51Table A6: Average responses to survey questions from cisgender respondents about their familiarity with non-cisgender issues.Organizers of QueerInAI, et al.Countries Queer in AI Scholar Recipients From Originally0.00, 0.000.00, 3.003.00, 3.573.57, 5.005.00, 6.006.00, 7.00Figure A13: Scholarship Recipients Country of Origin.Countries Queer in AI Scholar Recipients Live in 0.00,  0.00 0.00,  3.00 3.00,  3.29 3.29,  4.00 4.00, 10.0010.00, 11.00Figure A14: Country Scholarship Recipients Live in.On a scale of 1 to 5......how well represented are non-cis folks in your immediate work/research group? 1.98...how well represented are non-cis folks in Queer spaces you are part of (this includes Queer in AI)? 3.42...how often have you faced transphobia / microaggressions from cis folks? 3.01...how often have you faced transphobia / microaggressions from queer cis folks? 2.25Table A7: Average responses to survey questions from non-cisgender respondents about their experience with representationand transphobia.On a scale of 1 to 5......how well represented are queer BIPOC folks in your immediate work/research group? 1.76...how well represented are queer BIPOC folks in Queer spaces you are part of (this includes Queer in AI)? 2.80...how often have you witnessed racism / microaggressions against queer BIPOC folks? 2.53...how often have you called out racism / microaggressions against queer BIPOC folks? 2.41...how much effort have you put in to make your group more inclusive of queer BIPOC folks? 2.91Table A8: Average responses to survey questions from white respondents about their familiarity with BIPOC issues.Queer In AI: A Case Study in Community-Led Participatory AIOn a scale of 1 to 5......how well represented are queer BIPOC folks in your immediate work/research group? 1.76...how well represented are queer BIPOC folks in Queer spaces you are part of (this includes Queer in AI)? 2.80...how often have you witnessed racism / microaggressions against queer BIPOC folks? 2.53...how often have you called out racism / microaggressions against queer BIPOC folks? 2.41...how much effort have you put in to make your group more inclusive of queer BIPOC folks? 2.91Table A9: Average responses to survey questions from BIPOC respondents about their experience with representation andracism.Wanted to helpQueerAIcommunityWanted moreinterac-tion/socializationwithQueerAIcommunityWanted to improveD&I at conference(s)Wanted to getbetteratorganizingskills Other02040NumberofrespondentsFigure A15: Motivations that Queer in AI organizers had for volunteering.NotenoughtimeMentalwellbeingstrug-glesrelatedtomyidentityMentalwellbeingstrugglesrelatedtoothersourcesToolsandtechnologyinusearen’tagoodfitfortasksPeopleandorganiza-tionsnotvaluingmyworkwithQueerinAIPushback,opposition,orlackofsupportfrompeopleout-sideofQueerinAIcommunityWorkingagainstoppressionandmarginalizationremindsmeoforexposesmetoitNotfeelingconnectedtoQueerinAIcommunityUnclearorganization/leadershipHavenotreceivedneededtoolsortrainingtosup-portmyvolunteeringAccesstoneededtechnology/internetNotenoughhelpfromothervolunteersOther02040NumberofrespondentsFigure A16: Challenges that Queer in AI organizers faced when volunteering.Organizers of QueerInAI, et al.I’vegainedorimprovedmyorganizingskillsI’mmoreconfidentinmyorganizingskillsI’vereceivedvaluablementor-shipornetworkingopportunitiesI’velearnedaboutnewideasandresearchdirectionsI’velearnedaboutre-sources/opportunitiesthathavehelpedmyfriends,family,orcommunityI’vebeenpartofacommu-nitythathasbroughtmejoyI’vegrowninmyunderstand-ingandconceptionofmyselfI’vehelpedcommunitiesandpeopleIcareaboutI’veadvancedmyca-reer,research,orstudiesI’vereceivedfinancialcom-pensationorscholarships02040NumberofrespondentsFigure A17: Benefits that Queer in AI organizers received from volunteering.Receivedrecognitionfromfriends or colleaguesReceivedrecognitionfromQueerinAIvolunteersReceivedrecogni-tion on socialmediaReceivedinvitationstotalksorpanelsReceivedrecognitionfrommyadvisor,boss,orsupervisorReceivedrecognitionfromorga-nizationoutsideofQueerinAI02040NumberofrespondentsFigure A18: Recognition received by Queer in AI organizers.Queer In AI: A Case Study in Community-Led Participatory AIB.9 FinancesTable A10 provides revenue sources for Queer in AI since its founding in2018. Table A11 provides expenses of Queer in AI since 2018.C POLICY, ADVOCACY, AND IMPACTQueer in AI translates findings from its programs and the policies that it de-velops into real-world advocacy and systemic change for queer researchersand communities. Queer in AI, grounded in survey results and the inclusiveconference guide, has helped conferences such as ICML [113], NeurIPS[114], NAACL [110], EMNLP [112], and more extensively revise their reg-istration forms and diversity surveys to be more queer-inclusive; helpedshape author guidelines about publication accessibility, quality, and inclu-sivity; worked actively with conference infrastructure and logistics teamsto protect the privacy of queer speakers and participants; helped instituteeffective name-change processes at NAACL and EMNLP; and has workedwith the Association for Computational Linguistics [55] to implement aname change process, proactive measures to prevent the deadnaming oftrans authors, and protocols to handle authors’ requests to keep their videosprivate. These processes have at times been arduous, encountering resis-tance due to bureaucratic inertia and lack of concern, sometimes requiringsubstantial organizer effort and even threats of pulling Queer in AI eventsto effect.Queer in AI also educates companies, universities, and the general publicon queer inclusivity and the important, diverse topics discussed at Queer inAI workshops and socials. Queer in AI has helped shape Semantic Scholar’sfeature to allow authors to indicate their pronouns on their profile, sharedways to improve queer inclusivity at venues including the Allen Insti-tute for Artificial Intelligence, Nike, and the Toronto Public Library, andtrained professors and teaching assistants at the University of California,Los Angeles on respecting and including queer students in their classrooms[54, 108, 138, 156]. Resources built by Queer in AI related to the conferenceguide are also being adopted as exemplars by others, e.g., at student ACMchapters. Queer in AI also accessibly communicate the main points of itstalks and panels through Twitter threads and maintains a public YouTubechannel with talk and panel recordings [124].Queer in AI has also leveraged its findings and experience to push insti-tutions for change. They wrote to the National Science Foundation (NSF),criticizing the institution for failing to include LGBTQIA+ people in theirdiversity mission, study the discrimination and underrepresentation ofLGBTQIA+ people, and even simply include questions on sexual orienta-tion and gender identity in their STEM census surveys, despite Queer inAI’s demographic survey results showing that queer scientists don’t feelcomfortable or welcome at conferences or work environments and faceharassment and discrimination [57]. Queer in AI offered its expertise, drawnfrom the inclusive conference guide and years of experience running demo-graphic surveys, to the NSF to implement questions on sexual orientationand gender identity while protecting the privacy of LGBTQIA+ data.Organizers of QueerInAI, et al.2018 IncomeGoogle Twitter Prowler.io DeepMind NVIDIA$7,500 $2,500 $2,500 $2,500 $2,5002019 Income2018 carryover Google DeepMind Microsoft Prowler.io Apple$2,421.00 $20,000 $20,000 $20,000 $7,500 $15,0002020 Income2019 carryover Google DeepMind Microsoft Apple NVIDIA Prowler.io oSTEM$56,884.52 $20,000 $20,000 $20,000 $20,000 $20,000 $7,500 $10,0002021 Income2020 carryover Donations DeepMind Microsoft Apple oSTEM NVIDIA Capital One Intel Rasa Technologies$130,852.30 $33,287.79 $20,000 $20,000 $20,000 $20,000 $15,000 $7,500 $7,500 $7,5002022 Income2021 carryover Donations Grants DeepMind Microsoft Apple oSTEM D.E. Shaw Research Netflix$174,020.78 $13,710.78 $5,000 $20,000 $20,000 $20,000 $10,000 $15,000 $3,000Table A10: Queer in AI revenue, in USD.Expense 2018 2019 2020 2021 2022Physical Venue Costs $12,251.26 $22,018.02 $2,389.05 – $8,198.34Travel Scholarships and Registration $750.00 $2,053.20 – $200.00 $6,941.43Promotional Goods or Items $2,065.00 $3,965.26 $426.48 – $55.43Honoraria for Speakers and Panelists – – $8,500.00 $20,000.00 $14,500.00Emergency Aid Program – – $10,000.00 $10,000.00 $5,000.00Consulting – – – $2,813.44 –Virtual Infrastructure $12.00 $12.00 $90.00 $2,478.00 –Grad App Program – – $17,969.50 $71,880.23 $40,435.42Other – – $1,000.00 – –Contractors – – $1,000.00 – $33,220.00Total $15,079.26 $28,036.48 $33,532.22 $107,371.67 $100,657.69Table A11: Queer in AI expenses, in USD.",
    "id": 573308845,
    "identifiers": {
        "doi": null,
        "oai": "oai:eprints.ucl.ac.uk.OAI2:10173681"
    },
    "title": "Queer In AI: A Case Study in Community-Led Participatory AI",
    "language": {
        "code": "en",
        "name": "English"
    },
    "publishedDate": "2023-06-01T01:00:00+01:00",
    "publisher": "'Association for Computing Machinery (ACM)'",
    "references": [],
    "sourceFulltextUrls": [
        "https://discovery.ucl.ac.uk/10173681/1/2303.16972v3.pdf"
    ],
    "updatedDate": "",
    "yearPublished": "2023",
    "links": [
        {
            "type": "download",
            "url": "https://core.ac.uk/download/573308845.pdf"
        },
        {
            "type": "reader",
            "url": "https://core.ac.uk/reader/573308845"
        },
        {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/573308845/medium"
        },
        {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/573308845/large"
        },
        {
            "type": "display",
            "url": "https://core.ac.uk/outputs/573308845"
        }
    ],
    "abstract": "Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer people. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, decentralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community’s programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization’s impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI’s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods",
    "tags": [
        "Proceedings paper"
    ],
    "fulltextStatus": "enabled",
    "subjects": [
        "Proceedings paper"
    ],
    "oai": "oai:eprints.ucl.ac.uk.OAI2:10173681",
    "deleted": "ALLOWED",
    "disabled": false,
    "journals": null,
    "repositories": {
        "id": "118",
        "openDoarId": 0,
        "name": "UCL Discovery",
        "urlHomepage": null,
        "uriJournals": null,
        "physicalName": "noname",
        "roarId": 0,
        "baseId": 0,
        "pdfStatus": null,
        "nrUpdates": 0,
        "lastUpdateTime": null
    },
    "repositoryDocument": {
        "id": 573308845,
        "depositedDate": null,
        "publishedDate": "2023-06-01T01:00:00+01:00",
        "updatedDate": "2024-02-19T10:35:08+00:00",
        "acceptedDate": null,
        "createdDate": "2023-07-24T10:07:09+01:00"
    },
    "urls": [
        "https://discovery.ucl.ac.uk/id/eprint/10173681/1/2303.16972v3.pdf",
        "https://discovery.ucl.ac.uk/id/eprint/10173681/"
    ],
    "lastUpdate": "2024-02-19T10:35:08+00:00",
    "setSpecs": []
}