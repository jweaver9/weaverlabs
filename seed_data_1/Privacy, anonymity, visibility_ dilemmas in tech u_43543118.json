{
    "acceptedDate": "",
    "authors": [
        {
            "name": "Ganesh, Maya Indira"
        },
        {
            "name": "Deutch, Jeff"
        },
        {
            "name": "Schulte, Jennifer"
        }
    ],
    "contributors": [],
    "createdDate": "2016-08-09T11:27:56+01:00",
    "dataProvider": {
        "id": 603,
        "name": "IDS OpenDocs",
        "url": "https://api.core.ac.uk/v3/data-providers/603",
        "logo": "https://api.core.ac.uk/data-providers/603/logo"
    },
    "depositedDate": "",
    "documentType": "research",
    "doi": "",
    "downloadUrl": "https://core.ac.uk/download/pdf/43543118.pdf",
    "fullText": "RESEARCH REPORT\n JULY 2016\nMaya Indira Ganesh, Jeff Deutch and Jennifer Schulte \nPrivacy, anonymity, visibility: \n dilemmas in tech use by \n marginalised communities\n240\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\n1 Making All Voices Count is a citizen engagement and accountable governance programme. It aims to harness the transformative \npotential of unusual partnerships and innovative applications of communication technologies to contribute to fundamental change \nin the relationship citizens have with the state. It focuses the majority of its work in six priority countries – Ghana, Indonesia, \nKenya, the Philippines, South Africa and Tanzania. See page 40 for more information.\nAuthors\nMaya Indira Ganesh has worked with the Tactical Technology Collective since 2010 and is the Director \nof Applied Research. She has a background in feminist activism, research and writing, and in media and \ntechnology studies. She is a doctoral candidate at Leuphana University, Lüneburg, Germany.\nJennifer Schulte is a Human Rights Researcher and Sociologist with over a decade of experience \nworking with human rights, aid and development organisations. She has led and advised on research \nand programme evaluations in 51 countries, and has facilitated training on responsible data, digital and \nholistic security, ethics and technology, gender-based violence prevention and response, and refugee child \nprotection. Contact her via jenniferschulte.org, or at @schultjen on Twitter.\nJeff Deutch is a Researcher at the Tactical Technology Collective and a Fellow at the Centre for Internet \nand Human Rights, Frankfurt (Oder), Germany. His research interests include the politics of data, online \nand offline privacy, and digital security as they pertain to marginalisation and social exclusion. \nCredits\nEditors: Karen Brock (k.brock@greenink.co.uk) and Tim Woods (t.woods@greenink.co.uk), Green Ink \nDesigner: Lance Bellers, lancebellers@btinternet.com\nAcknowledgements\nThis work was supported by a grant from Making All Voices Count. It was conducted in 2014–15, and \nthis report was prepared in February 2016, following external and internal reviews. We would like to \nacknowledge the participation of respondents in Nairobi, Cape Town and Johannesburg. We would \nlike to thank Tanya Notley, Noortje Marres and Olumide Abimbola for their advice and support; Becky \nFaith and Nick Benequista for their reviews; and Koketso Moeti, Melissa Wainana, the Gay and Lesbian \nCoalition of Kenya, SERI South Africa, Sasha Kinney, Nick Hargreaves, Kate Tissington, Shireen Mukadam \nand Rumbidzai Dube for local research support and assistance. Questions about this project should be \ndirected to Maya Ganesh: maya@tacticaltech.org \nReference and copyright\nIDS requests due acknowledgement and quotes from this publication to be referenced as: Ganesh, M.I.; \nDeutch, J. and Schulte, J. (2016) Privacy, anonymity, visibility: dilemmas in tech use by marginalised \ncommunities, Brighton: IDS\n© The Institute of Development Studies 2016\nThis work is distributed under the terms of the Creative Commons Attribution 4.0 \nInternational licence, which permits unrestricted use, distribution and reproduction in any \nmedium, provided the original authors and source are credited. http://creativecommons.org/licenses/\nby/4.0/legalcode\nFR\nON\nT \nCO\nVE\nR \nIM\nAG\nE:\n R\nES\nID\nEN\nTS\n O\nF \nTH\nEM\nBE\nLI\nH\nLE\n IN\nFO\nRM\nAL\n S\nET\nTL\nEM\nEN\nT,\n S\nO\nU\nTH\n A\nFR\nIC\nA,\n P\nRO\nTE\nST\n A\nG\nAI\nN\nST\n IN\nAD\nEQ\nU\nAT\nE \nSE\nRV\nIC\nES\n IN\n 2\n01\n1\n/P\nH\nIL\nLI\nP \nDE\n W\nET\n340\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nContents\nExecutive summary 4\n1. Introduction 5\n2. The research: questions, context and design 6\nPutting the questions in context 6\nThe flip side of technology in activism: the risk of exposure 7\nUnpacking visibility, anonymity, exposure and transparency 8\nVisibility: ‘being counted’ versus exposure 9\nResearch design, methods and approaches 10\nResearch design: Kenya 11\nResearch design: South Africa 12\n‘Do no harm’ approaches to ethics and security in research 13\nTaking research back to the community 14\n3. Research results: Kenya 15\nBeing LGBTQ in Nairobi: the contours of marginalisation 15\nSocial media practices and perceptions 16\nUsing T4T&A tools to report violence 17\nUtunzi 18\n‘Speak out’ 20\n4. Research results: South Africa 22\nThe landscape of activism 22\nThe housing list: applying T4T&A in movements and communities 23\nTechnology practices among marginalised activists in Johannesburg 25\nRisks of and barriers to using T4T&A tools 26\nA lack of trust 27\n5. Reflections and learnings 29\nCustomise control over visibility: understand user practices 29\nAddress differences across movements and communities of practice 31\nPut human rights first 33\nReferences 35\n440\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nExecutive summary\nHow do marginalised communities \nuse technology for transparency \nand accountability?\nThis paper synthesises reflections and learnings from two studies, in Kenya and \nSouth Africa, about how marginalised communities – lesbian, gay, bisexual, trans  \nand queer (LGBTQ) people in Nairobi, Kenya, and economically marginalised \nhousing and urban development rights activists in Johannesburg, South Africa – \nuse technologies commonly applied in transparency and accountability work, and \nthe limits of their use of these technologies. \nTechnology for transparency and accountability (T4T&A) initiatives intend to make \nthe public functioning of government visible, and states accountable to citizens \nfor their actions. This research assumes that privacy and anonymity are important \ntactics for activists using technology, especially in transparency and accountability \nwork that challenges institutions and authorities. However, privacy is practically \nimpossible to maintain on popular, commonly available, proprietary platforms, \nmany of which are deployed in T4T&A activities. Does this limit activists’ work \nwith technology and if so, how? What are the other risks and barriers marginalised \npeople face in their use of technology? \nQuestions based on these concerns were clarified through formative interviews \nwith 26 people, and fieldwork interviews with 37 people. The most significant \nreflections from both case studies are that: \n• marginalised users have different needs for privacy and security online, and \nT4T&A activities need to integrate these concerns \n• collaborations across and within technology and activist movements and \ncommunities must recognise their different histories of engagement with \npolitics, technology and the state\n• without the full enjoyment of human rights, marginalised people’s participation \nin T4T&A activities is bound to be limited.\n540\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\n1 Digital technology applications are increasingly popular tools employed in work around civic engagement, democratic \nparticipation and transparency and accountability in governance and public services. This is visible in open data and open \nknowledge movements, social media and map-based applications, and the combination of other open data, data journalism and \nvisualisation for government transparency and public accountability.\n2  Maya Ganesh and Jeff Deutch worked on the Kenya research. Jennifer Schulte planned and conducted the fieldwork in South \nAfrica, based on background work by Maya Ganesh who, with Jeff Deutch, also analysed the South African results and wrote the \nreport findings. \nIntroduction\nThe Tactical Technology Collective (Tactical Tech) \ncarried out two case studies that investigated \nhow marginalised communities of activists in \nKenya and South Africa use digital technology, \nand the limitations, risks and barriers they face \nin doing so. These studies were inspired by \nMcGee and Carlitz’s questions about why the \nmarginalised in a society do not use technology \nfor transparency and accountability (T4T&A) \napplications1 – even if they have access to digital \ndevices (McGee and Carlitz 2013). This report \nsynthesises findings from the two studies, and \nframes them as reflections and learnings to inform \nfuture T4T&A activities.\nThe two case studies are based on semi-\nstructured fieldwork interviews with 37 \nrespondents in two communities – lesbian, \ngay, bisexual, trans and queer (LGBTQ) \npeople in Nairobi, Kenya, and economically \nmarginalised housing and urban development \nrights activists in Johannesburg, South Africa2 \n– conducted over a six-month period. These \ntwo communities are marginalised by race, \nclass, socio-economic status, gender and sexual \nidentity – characteristics that overlap and \nintersect. The identification of fieldwork interview \nrespondents, and the process and content of the \nfieldwork interviews, were shaped by 26 formative \ninterviews with key informants in the two \ncommunities, carried out over the seven months \npreceding the fieldwork. \nThe two case studies were initially focused on \nexploring the tension between anonymity and \nvisibility for marginal populations online. They \ninterrogated the anecdotal finding that increased \nonline visibility for the issues faced by marginalised \ncommunities has the side effect of making \nindividuals visible too – often to their detriment, \nbecause they are working in hostile local political \ncontexts. The findings show that such individuals \nhave a legitimate need for anonymity and privacy, \nbecause technology platforms do create negative \nexposure, but that threats tend to be local, lateral and \npersonal, originating within families, communities \nand movements. This research confirms the nature \nand dynamics of this tension, and looks at the way \nthat it affects use of digital technologies.\nThe case studies refer to two very different \ncommunities in specific political, social, economic \nand historical contexts; thus they are not directly \ncomparable, nor is that the intention of this report. \nRather, it attempts to reframe what marginalised \ncommunities’ access to and use of digital technologies \nimplies for T4T&A activities. It discusses the design \nand results of the research, before presenting a \nseries of reflections to make sense of the findings \nin light of T4T&A activities. It also draws on \nconversations and inputs from members of both \ncommunities in Nairobi and Johannesburg who \nparticipated in outreach events in October 2015, \nwhere the study results were fed back for comment \nand discussion.\n640\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\n2. The research: questions, \ncontext and design\nThe two studies this report is based on started \nwith the observation that there is a tension \nbetween anonymity and visibility in the use of \ndigital technologies: that while digital technologies \n– primarily social media and mobile phones – can \nhelp amplify and create visibility for marginalised \nactivists’ issues, at the same time they make the \nactivists themselves visible in ways that they often \nfind they are unable to control. This inability to \ncontrol their own visibility as activists presents \nrisks to their work, particularly if their work \ndeals with sensitive issues that directly challenge \ninstitutional power or corruption. The potential \nfor different kinds of negative exposure were \ninvestigated in the context of technology use in \nactivists’ work, and across the range of different \nrisks and barriers they face. What did negative \nexposure mean for LGBTQ people in Nairobi, and \nlow-income, black and mixed-race people working \non housing and urban development rights in \nJohannesburg?\nThe tension between anonymity and visibility \nis positioned within two broad frames of \ndiscussing T4T&A: the ‘open’ movement and \nT4T&A initiatives, which promote visibility and \npublicity for public information, public servants \nand processes; and the ‘data rights’ discourse, \nwhich is about anonymity and individual rights to \nprivacy and freedom from surveillance. How are \nthe two reconciled when the technologies that \nencourage openness and visibility – mobile phone-\nbased applications, crowdmaps and freedom of \ninformation requests – also invite violations of \nprivacy, and enable surveillance by their very \narchitecture and technical specifications? Is there \na middle ground between visibility and anonymity, \nand if so, how is it managed?\nDeveloping an argument based on this tension led \nus to frame it within the notion of risk to the work \nof marginalised people who are using technologies \nfor transparency and accountability, as well as \nin their personal lives. In doing so, the research \nquestion expanded to look at how technology fits \ninto the wider context of activists’ lives and into \nthe political context of their activism, and what \nimplications this has for activists’ engagement \nwith T4T&A activities. Thus, this research has \nbeen developed in response to the question: how \ndo digital technologies fit within the wider context \nof the lives of marginalised activists, and within \nthe political context of rights in Kenya and South \nAfrica, and what implications does this have for \ntheir engagement with T4T&A activities?\nTo answer this question, the study addressed the \nfollowing sub-questions:\n• How and for what purposes are marginalised \nactivists using technology – personally, and in \ntheir activism?\n• How does this use vary according to socio-\ndemographic differences within marginalised \ncommunities?\n• What are the risks and barriers marginalised \nactivists face in using digital technologies in \ntheir transparency and accountability work?\nThe following section provides context to these \nquestions by describing the risks faced by activists \nin their use of technology. This is followed by a \ndiscussion of the different ways in which visibility, \ninvisibility and anonymity can be unpacked in the \ncontext of transparency and accountability, and \nmarginalised communities.\nPutting the questions in \ncontext\nThis section provides a background to Tactical \nTech’s work and how our engagement with activism \ninforms our approach to these questions. We \nwere curious about the limits of online activism \nenabled by digital technologies: how can citizens \nand governments engage in meaningful dialogue \nthrough technology when governments are actively \npersecuting or marginalising citizens through \nviolence and criminalisation? What happens when \nthese citizens are marginal in society and have few \nsocial safety nets and little social capital to protect \nthemselves? How does their marginalisation play \nout in their use of digital technologies, and what \n740\nThe research: questions, context and designSection 2\n3 “Mr Kaye observes that encryption and anonymity, separately or together, assist in shielding opinions from outside scrutiny \n(particularly important in hostile environments), empower individuals to circumvent censorship and other unlawful barriers to \nthe free flow of information, and shield journalists, researchers, lawyers and civil society from unlawful surveillance and \nharassment. In this regard, encryption and anonymity provide individuals and groups with a zone of privacy online to hold \nopinions and exercise freedom of expression without arbitrary and unlawful interference or attacks” (Privacy International 2015).\nare the risks and limits to their use of technology? \nHow can the promise of ‘visibility’ be unpacked to \nshed light on what it could mean for historically \ninvisible communities?\nThe flip side of technology in \nactivism: the risk of exposure\nTactical Tech has been ‘bookmarking’ cases of \nhow the Web 2.0 Internet is implicated in negative \noutcomes for activists and human rights defenders. \nActivists who are articulate and effective online can \nface a range of threats and harms from authorities, \ninstitutions and people they know who are \nthreatened by their actions. Sometimes, activists, \njournalists and those working to expose corruption, \ninjustice and violence in and by public institutions \nneed to work anonymously to protect sources, \nwhistle-blowers and themselves. This tends to \naffect people who are already marginalised in their \nsocieties most seriously. For example, the Kvinna \ntill Kvinna Foundation’s work with women human \nrights defenders in precarious situations around \nthe world documents the impact on them of online \nharassment and offline harms mediated through \ntechnology (Kvinna till Kvinna Foundation 2014).\nThe struggle to control digital traces was an issue \nfor activists in the Hong Kong protests of late 2014. \nFor those protestors who had been underground \nfor many years prior to the street protests, it \nwas important to remain undetected; however, it \nwas also an opportunity for these movements to \nbecome more active above ground. This tension \nwas heightened by the promotion of a mobile \nphone application for activists to report on events \non the ground, which was discovered to introduce \nmalware into a user’s phone. Although a technology \nfor transparency group, Code for Hong Kong, was \nnamed as having developed the application, they \nwere not in fact responsible. Activists were therefore \nbeing spied on to track and record their movements \nand information (Boehler and Sam 2014).\nJailed Egyptian activist Alaa Abd El-Fattah was \nawarded the Sakharov Prize for Freedom of \nThought in 2014, but it was later rescinded when \nhis tweets from two years prior were discovered, \npurportedly calling for ‘death to Jews’. It turned \nout that a selection of tweets about Zionist settlers   \ntaking over Palestinian lands and the Israeli army’s \nattacks on Gaza had been taken out of context and \nmisinterpreted (Muftah 2014).\nIn the USA, the Los Angeles Times published the \nnames of individuals who donated to support or \noppose Proposition 8, an initiative in California \nto constitutionally define marriage as a union \nbetween a man and a woman (Minkhoff et al. \n2014). By doing so, it exposed the people who \ncared enough to put money into supporting or \nopposing marriage equality, revealing their private \naffiliations before Proposition 8 went to the vote. \nOne notable example of someone who got caught \nin the transparency net was Brendan Eich, the \nChief Execuitve Officer of Mozilla, the company that \nmakes the Firefox browser. His donation in support \nof Proposition 8 – against marriage equality (Ball \n2014) – jarred with Firefox’s public image as an \nemployer that supports LGBTQ equality in the \nworkplace, as well as aligning itself with a pro-\nprivacy position.\nMarginalised groups who become visible and \nidentifiable may face a higher risk of offline \nviolence or discrimination. For example, the \nEgyptian police uses Grindr, the dating application \npopular with gay men worldwide, to triangulate, \nidentify and arrest LGBTQ users (Sheils 2014); \nsimilarly, in Lebanon, police are using WhatsApp to \ntarget and entrap gay men (Mamba 2014). Grindr \nrecently removed its ‘show your distance’ option \nin response to privacy advocates raising concerns \nabout the feature (Aravosis 2014), although it was \nlater reintroduced.  \nIn some countries, states are direct instigators \nof surveillance and the monitoring of activists \nand journalists. This raises the issue of the right \nto privacy and the importance of privacy in the \nwork of activism, points recently made by Privacy \nInternational in their discussion of a report by \nthe UN Special Rapporteur on Privacy, David \nKaye.3 Serious forms of harassment, and the \nintimidation of activists and journalists by state \nand non-state actors is occurring around the \nworld, in environments where activists, civil society \norganisations and non-governmental organisations \n(NGOs) are increasingly being criminalised (Ronan \n2014); revelations by whistle-blower Edward \n840\nThe research: questions, context and designSection 2\nSnowden showed the world the scale of collusion \nbetween technology companies and intelligence \nagencies, and the use of surveillance on citizens \nglobally. \nAcross Africa, for example, there are significant \nlevels of surveillance and monitoring of activists. \nThe South African Right to Know network has a \nproject and a recently published report on the \nmonitoring and harassment of activists – some \nof whom were involved in the present study – by \nSouth African government intelligence (R2K 2015). \nThe report indicates that there is an ongoing \npractice of creating informants within activist \ncommunities to get information.\nCitizenlab, a security research centre at the \nUniversity of Toronto, Canada, found that \nsurveillance malware developed by the Italian \ncompany Hacking Team was found in Ethiopia, \nMorocco, Nigeria, Somalia and Sudan (Marczak \net al. 2014). In 2013, Angolan journalist and \nactivist Rafael Marques was found to have been the \ntarget of surveillance by his government (Gunter \n2014). Governments of some African countries are \nalready censoring and monitoring citizen projects \nonline, in addition to limiting freedom of the press \nand the protection of journalists (Sasaki and Rising \nVoices 2010).\nThus activists engaged in progressive social \nchange and justice work face risks associated with \ndigital technology, from top-down surveillance to \nexposure through social media. This context served \nas a starting point and background for investigating \nthe kinds of risks and barriers marginalised \ncommunities face in their use of technology in \nactivism in Kenya and South Africa.\nUnpacking visibility, anonymity, \nexposure and transparency\nThe two case studies are based on the argument \nthat being unable to manage anonymity and \nvisibility online is to risk exposure in the course \nof transparency and accountability work. Web 2.0 \ntechnologies, such as mobile applications, social \nmedia and maps – tools popularly used in T4T&A \nactivities – do not guarantee privacy for the user, \nand therefore states or corporations that are \nthreatened by use of these tools for transparency \nhave the technical wherewithal to identify the \ncitizens using them. This may pose more risks and \nliabilities for those who are already marginalised \nin their societies than it does for those who are \nmore secure in their social status and social \nidentity, limiting the use of applications for T4T&A \nactivities. In order to develop some background \nto this, Tactical Tech wanted to unpack the idea \nof visibility through technology, alongside the \nmovement for transparency through technology. \nIn doing so, we found that the technical states of \n‘visible’ or ‘anonymous’ can be considered along a \ncontinuum of visibility that has different symbolic \nand literal meanings for marginalised people, who \nseek to control and negotiate these states both \nonline and offline. \nAt first glance, visibility and transparency appear \nto be connected concepts. Transparency is to see \nthrough something that is otherwise opaque. The \nidea of ‘openness’ has also become associated \nwith technology for transparency. Open data \nand knowledge are new technical tools that are \nbelieved to enable transparency. For example, a \ngovernment department can be transparent when \nits functioning and practices are open to scrutiny; \nthis may involve everyday, operational aspects \nsuch as the citizen oversight of government \nbudgets, expense sheets and minutes of \nmeetings. Dieter Zinnbauer (2012) questions this \nperspective when he suggests that technologies \nof transparency and openness allow governments \nto make claims that they are revealing their \nfunctioning, but may not actually be doing so. \nHe uses the metaphor provided by parliament \nbuildings, police booths or financial institutions \nin glass-fronted buildings. By opening up one \npart or aspect of government functioning, such \nas how international aid money is spent, others \nmay become (or remain) conveniently obscured, \nsuch as the government’s purchase of malicious \nsurveillance software to spy on citizen activists.\nVisibility, invisibility, transparency, openness and \nexposure are perhaps different philosophical and \ntechnical aspects of the demand for accountability \nfrom public institutions. They bear discussion \nbecause transparency is not an open-and-shut \ncase. For example, it can have one positive \nor expected outcome in terms of government \ntransparency, but mean something else for \nwhistle-blowers who are at risk because they can \nbe exposed by leaking information. We continue \nby describing some of these different aspects in \nthe context of human rights defenders, activists \nand communities working on transparency and \naccountability issues.\n940\nThe research: questions, context and designSection 2\n4 In addition to not counting smaller ethnic groups, the final figures for the 2009 Kenyan census were never released. \n(BBC News 2009).\n5 Personal communication, Baerbel Heide Uhl, Berlin, Germany, March 2014.\nVisibility: ‘being counted’ versus \nexposure\nVisibility is about ‘being seen’ in the sense of being \nrecognised or acknowledged, and hence ‘counted’. \n‘Being visible’ is considered important because it \nallows the realities of injustice or violence against \na particular marginal group or identity to be \nrecognised and acknowledged. ‘Witnessing’ and \ndocumentation have therefore been two of the \nmost popular and powerful ways in which digital \ntechnologies have enabled marginalised groups to \nmake claims for rights and about rights violations. \nThis is the intention of projects such as Harassmap, \nwhich provide evidence of public sexual harassment \nin Egypt, a topic that women do not readily discuss.\nZanele Muholi’s years-long photographic \ndocumentation of queer black women in South \nAfrican townships follows in this tradition of visibility \nas witnessing. Through intimate photographs, \nassembled into books and exhibitions called Faces \nand Phases, and more recently in 2015, Isibonelo: \nEvidence, Muholi’s work challenges the invisibility \nof this community, and raises awareness of the \npersistence of violence against queer black women \nin a country where homosexuality is legal.\nAnother example of visibility as recognition \nor acknowledgement comes from Kenya. In \n2007–08, post-election violence in Kenya was \ndrawn along ethnic lines. While collecting ethnic \ndata may pose the risk of exposing people from \nmarginalised ethnicities by making them known, \nit also enables marginalised groups like smaller \nethnic communities, which may not have been \ncounted before, to be recognised.4 This means \nthey can demand resource allocation and political \nrepresentation (Nyambura-Mwaura 2009). Without \nsuch empirical evidence, these groups argue, it \nbecomes almost impossible to document and \nmonitor patterns of violence against them.\nVisibility can also imply exposure in a negative \nsense, of being exposed through mechanisms of \nsurveillance that are embedded in institutional \ninfrastructures. For example, in Europe, the migrant \nrights and sex-worker rights network KoK finds \nthat continental databases like Euro-Sur are used \nto track and monitor movements of migrants into \nand through Europe.5 In Jordan, Syrian refugees \nare given cash handouts by the United Nations High \nCommission for Refugees only when they have had \ntheir irises scanned using a technology, Iris Guard, \npurchased by by the Cairo Amman Bank which \nadministers the handouts (Vrankulj 2014). What \nhappens to the refugees’ iris data is not known at \nthis point. But Tactical Tech has found that British \nand US intelligence personnel are on the advisory \nboard of Iris Guard.\nMarginalised communities have not only been the \ntargets of surveillance, but also the community on \nwhom social surveillance technologies are usually \ntested (Eubanks 2014). Virginia Eubanks’ work \nin the USA shows that concerns around visibility \nand surveillance are familiar to people who are \nsocially marginal. Mothers on welfare, for example, \nget subsidies – but their spending is monitored by \nsocial service authorities who assume they will be \nwasteful, fraudulent or unreliable. \nPeople of colour invite surveillance through the Stop \nand Frisk programmes in New York City: “An analysis \nby the NYCLU [New York Civil Liberties Union] \nrevealed that innocent New Yorkers have been \nsubjected to police stops and street interrogations \nmore than 4 million times since 2002, and that \nblack and Latino communities continue to be the \noverwhelming target of these tactics. Nearly nine \nout of ten stopped-and-frisked New Yorkers have \nbeen completely innocent, according to the NYPD’s \n[New York Police Department] own reports” (NYCLU \nno date). At the same time, cameras worn by the \npolice to monitor their interactions with people \nof colour have recently come to attention during \nconsiderations of the extent of police violence \nagainst this community (Stanley 2015).\nWorldwide, queer people as a marginalised group \nhave historically been the subjects of surveillance \nas a way of identifying, naming, tracking and \nultimately controlling them (Monahan 2009; Weeks \n2000). At the same time, invisibility is part of the \nexperience of being queer and amounts to not \nbeing acknowledged within society. In societies \nwhere being LGBTQ is criminalised, or where there \nis pervasive homophobia or transphobia, LGBTQ \npeople have a need to remain undetected in the \nmainstream, but at the same time to remain visible \nto those that they would consider part of their own \ncommunity. Tactics for passing as straight may \ninclude dressing and presenting oneself in a certain \nway, or having an opposite-sex partner to conceal \none’s same-sex orientation. While passing for \n10\n40\nThe research: questions, context and designSection 2\nstraight, a LGBTQ person may still use and respond \nto the speech and body language unique to their \ncommunity. LGBTQ subcultures and communities \naround the world are also distinguished by unique \nterms, speech patterns and personal presentation \nstyles (Tewksbury 1996). \nIn the context of apartheid South Africa, visibility \nand invisibility were enabled by the application \nof bureaucracy as a technology of control and \nmanagement. Here, an elaborate system of racial \ncategorisation, fingerprinting, zoning, biometric \nidentifiers of race, identity passbooks and over \n160 laws were created to limit black and mixed-\nrace people’s freedoms of assembly, movement, \nexpression and association, and to deprive them of \nother human rights. These systems were fed and \nfired by a constant assertion of race; thus, anyone \nwho was not white was made highly visible through \nthese technologies, but at the same time made \ninvisible in mainstream society because they were \nphysically and symbolically excluded. Paul Edwards \nand Gabrielle Hecht present a rounded and complete \npicture of the ways in which narratives of technology \nand the development of national and social identity \nin apartheid and post-apartheid South Africa have \nhad practical, material and symbolic outcomes:\n“The apartheid state aimed to manage its race-\nbased identity registration – the hated passbooks \nand their related fingerprint databases – with \ncomputer technology, thereby muting the \nsystem’s oppressive character beneath a quest \nfor bureaucratic efficiency through automation. \nActivists reacted by making the underlying \ntechnology itself an issue, connecting computers \nto military systems and political persecution by \nthe police” (Edwards and Hecht 2010: 620). \nSouth Africa’s colonial and apartheid regimes \nwere not the only ones to use technologies \nof bureaucratic management in this way. \nMichel Foucault coined the term ‘biopower’ to \ndescribe how modern nation states use various \ntechnologies, such as taxonomies and classificatory \nsystems, to organise, manage and literally control \nlarge populations (Foucault 1976). Sharply honed \nas a tool of control in colonial contexts, European \nstates used these tools at home to classify citizens, \nto identify those who were fit to drive modern \nindustries and those who were unfit – the disabled, \nmentally ill, unwed mothers and other ‘social \ndeviants’. Thus entire communities were created, by \nbeing made visible in this manner (Robertson and \nTravaglia 2015). \nThe different ways in which visibility, invisibility, \nexposure and transparency intersect, sketched \nout in this section, raise two points for this \nresearch. First, the ‘tension between visibility and \nanonymity’ – implied by applications of privacy-\nenhancing technologies, or the risk of exposure \nthrough technology – is in fact only one aspect \nof this contradiction. For marginal and invisible \ncommunities, visibility is an important aspect of \nclaims to rights and advocacy, and technology is a \nway of achieving this. But top-down bureaucracies \nthat function to organise and manage society \ntend to make marginal communities visible and \nvulnerable. These perspectives form a backdrop \nagainst which to investigate the practices of \nmarginal communities in using technologies, and \nhow concerns about exposure, visibility, invisibility \nand anonymity play out in their own particular \ncontexts.\nResearch design, methods and \napproaches\nThe research used a qualitative methodology based \non semi-structured interviews with a total of 37 \nLGBTQ activists in Nairobi, and housing and urban \ndevelopment rights in Johannesburg. Following \nformative, exploratory interviews in both cities prior \nto fieldwork, Tactical Tech developed an interview \nguide and sample determination exercises to \nensure a robust sampling range. \nTactical Tech does not work directly in either Kenya \nor South Africa, but has a history of partnerships, \ncollaborations and networks with activists in both \ncountries. While access to target populations \nwas limited, these networks made it possible to \nsample potential respondents purposively through \n‘snowball sampling’ – asking people we knew \nthrough pre-existing networks to refer us to others \nin their own networks. Respondents were therefore \nall associated with local, regional, national or \ninternational movements and networks. Moreover, \ngiven the sensitive nature of respondents’ work, \nwhich is sometimes confrontational to the state, \nwe wanted to maintain a low profile and access our \nsample through known networks. \nThere was a particular emphasis on ensuring \nthat study respondents were not active users \nof T4T&A applications, in order to identify why \nthis was so. However, what qualifies as a T4T&A \napplication is up for question: is it custom-made, or \nbased on mobile phone reporting, social media or \n11\n40\nThe research: questions, context and designSection 2\ncrowdsourcing technologies? In the Kenyan context, \nit was harder to come across respondents who did \nnot have access to any of these communication \nplatforms: they were all familiar and in current \nuse, with the exception of crowdmaps. In South \nAfrica, there were more respondents from socio-\neconomically weaker sections of society with less \naccess to digital technologies, but every one of \nthem was familiar with mobile phones and mobile \napplications.\nResearch design: Kenya\nDesk research\nAn initial review of background information \non T4T&A included a review of the literature \non information communication technology for \ndevelopment (ICT4D), as well as of the emerging \nT4T&A field. Literature concerning recent socio-\npolitical events in Kenya, and the status of LGBTQ \nrights, was closely followed during the research \nperiod. The close monitoring of popular discourses \nof transparency and accountability, technology, and \nLGBTQ rights issues was helpful in reflecting on and \ninterpreting the analysis of research results.\nFormative interviews\nIn October 2014, an exploratory visit to Nairobi \nwas conducted with two objectives. The first was \nto carry out interviews with local respondents to \nclarify the research questions and methodology, \nto understand the context and ensure that the \nquestion was relevant, and incorporate feedback \ninto project methodology and interview schedules. \nSixteen interviews were conducted at this time \nwith individuals from a range of organisations \nand backgrounds. More than half were associated \nwith civic technology and T4T&A projects; the \nrest were a combination of activists from women’s \nrights networks, child rights networks, health and \ndevelopment NGOs, and LGBTQ networks.\nThe visit revealed distinct class divisions within \nthe NGO, civic technology and LGBTQ activist \ncommunities in Nairobi: it would be very easy to \nover-represent middle-to-upper class, educated \ngay men (and some lesbian women) from the \ncity. During the exploratory visit, Tactical Tech \nwas able to identify individuals and networks that \ncould introduce them to working-class, female or \ntrans respondents who would be less comfortable \ncommunicating in English. Interviews indicated the \nimportance of taking an intersectional approach \nto marginalisation (Winker and Degele 2011); \nwithin this already marginalised community, the \nvoices and experiences of working-class people, \nwomen and trans people tend to be hidden. As \nsuch, particular efforts were made to include these \nconsiderations in developing a sample that included \nas many different points of view as possible.\nThe second objective of the visit was to identify \nnetworks of local respondents, potential partners \nand peers who could provide access to LGBTQ \ncommunity networks beyond Tactical Tech’s \nexisting networks, including points of access to \nreach the more marginalised. Gaining access to \nmarginalised groups and building trust is often \ndifficult, particularly for outside researchers and \norganisations. In some cases, funded NGOs and \nformalised activist groups are proxies for the wider \ncommunity, and were a point of entry to locate \nmarginalised populations. During the pilot visit, \nresearchers were able to talk to local respondents \nabout the best way of accessing a range of \nrespondents; connections made at this time \nallowed us to develop enough trust to access these, \nmaking for a diverse sample. \nFor this study, Tactical Tech partnered with a \nNairobi-based umbrella organisation of smaller \norganisations throughout the country made up of, \nand / or representing the needs of, LGBTQ people in \nKenya. The network provided logistical support in \ndetermining appropriate interview locations, and its \nreputation within the LGBTQ community was helpful \nin identifying potential respondents. However, the \nnetwork was also seen by some as exclusionary \nand not representative of some sections of the \ncommunity. To address this, researchers also met \nrespondents through the networks of individuals \noutside the organisation. In this way, they worked \nto ensure adequate representation of all sexual \norientation, gender identity and class groups.\nSampling and sample\nThe Kenya case study is based on responses \nfrom 20 individuals living in Nairobi, Kenya. The \nresearch did not explicitly ascertain their exact \nidentities along the spectrum of LGBTQ, only that \nthey closely associated with this broad and diverse \ncommunity, either as individuals in a social network \nor as activists in paid and volunteer capacities. \nRespondents spanned a range of gender identities \nfrom male to female, were all aged between 18 \nand 40, and represented different socio-economic \nclasses. The majority worked in voluntary or \npaid capacities in NGOs and LGBTQ coalitions, \n12\n40\nThe research: questions, context and designSection 2\nin addition to part-time work in other jobs; three \nwomen were college students, but there were also \nlawyers, film-makers, journalists, artists and self-\nemployed people in the sample.\nAnalysis is based on data from 20 fieldwork \ninterviews. Sixteen formative interviews were also \nconducted, prior to fieldwork, both face-to-face \nin Nairobi and via Internet calls. This research \nwas carried out between October 2014 (formative \ninterviews) and March 2015 (fieldwork inverviews), \nwith analysis and writing conducted between June \nand October 2015.\nLimitations of the study\nLimited resources prevented primary research \nbeing conducted outside Nairobi. Although some \nrespondents originate from outside Nairobi, and \nall efforts were made to interview a diverse sample \nwith varied perceptions, there may be a bias in \ncontent analysis, with the experience of Nairobi \nresidents over-represented. This, combined with \na small sample size, implies that findings cannot \nbe extrapolated for marginalised people outside \nthe capital. Despite these limitations, the study \nmethodology yielded important empirical insights, \nand the findings can be adopted to inform T4T&A \ninterventions.\nResearch design: South Africa\nDesk research\nThe research team conducted a review of the \ngovernment transparency and accountability, \nT4T&A and ICT4D literatures. They also reviewed \nT4T&A projects in South Africa, and as part of \nthe desk research, carried out three telephone / \nInternet call interviews with experts working on \nthese issues in South Africa.\nFormative interviews\nThe lead researcher travelled to South Africa \nin January 2015 to interview local experts, to \nshape the research questions and orientate the \nteam in the current socio-political context. We \nlistened to a range of opinions and experiences \nabout technology applications for activism. \nSeven formative interviews were conducted \nduring this trip, with an additional three via \ntelephone / Internet calls. Respondents worked \nin parliamentary monitoring, citizen media and \njournalism, youth and education issues, housing \nand urban development rights, and freedom of \naccess to information projects.\nOwing to scheduling issues, most of the formative \ninterviews conducted at this stage were with \npeople in positions of authority who were relatively \nprivileged in terms of class and race. They did \nnot reflect the intended sample, and therefore a \nspecific effort was made to undertake a sampling \nexercise that would help identify a more diverse \nsample for the study. Nonetheless, some of the \nformative interviews resulted in insights borne \nof rich experiences of working with marginalised \ncommunities through applications of technology. \nThe formative interviews also provided an \nopportunity to meet with a local research assistant \nand identify logistical, operational and security \nconsiderations for the upcoming research process.\nSampling and sample\nIn addition to the ten formative interviews \ndescribed above, three more interviews were \nconducted with key female informants as part \nof a sample determination exercise; one of the \nrespondents had already been interviewed. \nThese three sample-focused formative interviews \nwere with:\n• a Johannesburg-based white policy activist and \nresearcher at a housing and lands rights policy \norganisation\n• a Johannesburg-based black T4T&A activist \nliving and working in low-income communities\n• a Cape Town-based Indian-origin freelance \nsecurity studies researcher and writer associated \nwith the Right to Know movement.\nThese sample-focused formative interviews were to \ndetermine the range of profiles of activists working \nin housing rights and urban development-related \nsocial movements. The results helped us identify \nsocio-economically and politically marginalised \norganisations and groups, whose protests and \ndissent the government has tried to suppress. \nWeighing responses from our key informants, \nwe developed a qualitative sampling strategy \nand purposively selected a range of profiles of \nJohannesburg activists, seeking maximum variation \nin perceptions and lived experiences. To that end, \nmixed purposive sampling approaches were used, \nincluding:\n• extreme-case sampling (identifying the extremes \nor poles of some characteristic and then \nselecting cases representing these extremes for \nexamination)\n13\n40\nThe research: questions, context and designSection 2\n• typical-case sampling (selecting what are \nbelieved to be average cases)\n• critical-case sampling (selecting what are \nbelieved to be particularly important cases)\n• negative-case sampling (selecting cases that \ndisconfirm the researcher’s expectations and \ngeneralisations)\n• opportunistic sampling (selecting cases when \nthe opportunity arises).\nThe different kinds of activist communities \nidentified through the sampling exercise allowed \nus to ensure that we were indeed reaching out to \nthe marginalised, whose voices are rarely heard in \nmainstream media, public debates or government \npolicy discourses. We focused mainly on the \nfollowing types of key respondents from working-\nclass, mass-based movements living in informal \nsettlements often far from the city centre, and from \nformal NGOs or academia in Johannesburg’s main \nbusiness district and city centre:\n• staff of NGOs and community-based \norganisations (CBOs) working on socio-\neconomic rights and legal aid\n• CBO members\n• activists in the housing and socio-economic \nrights movements.\nWe reached out to several people in each category \nto schedule fieldwork interviews, and received \nnine negative responses, for a range of reasons. \nFor the final fieldwork sample, we interviewed 17 \nrespondents from across all three categories.\nSampling and data collection were strengthened \nby a local research assistant who is well trusted in \nboth informal settlement communities and urban \ndevelopment NGOs, and who facilitated access to \nmarginalised activists for fieldwork interviews in \nsecure locations.\nLimitations of the study\nAt the start of each formative and fieldwork \ninterview, the researcher followed an informed \nconsent process to ensure that respondents \nmade a conscious decision on whether or not the \ntranscript of their interview would be recorded. \nEight respondents, concerned about potential \ninadvertent privacy and confidentiality risks, did \nnot consent to recording, and these fieldwork \ninterviews were documented through note-taking; \nnine consented to their fieldwork interview being \nrecorded. Some explained that surreptitious \nrecordings of activists speaking in group meetings \nhave been later edited out of context, and \npublished without consent in the press, attributing \nto them inaccurate and discrediting statements. \nAmong the eight who did not consent to digital \nrecording for transcription purposes, five were \nmarginalised black women activists who have faced \nharassment and threats in the past for speaking out \nagainst rights violations and oppression.\nFor the unrecorded fieldwork interviews, detailed \nnotes captured key concepts and voluminous \ndirect quotes. Still, the results of the content \nanalysis and code frequencies could be marginally \nskewed as a result of a dataset that combines \ninterview notes with full transcripts. It is unlikely, \nthough, that the extent of skewing is substantively \nsignificant, as the results otherwise are reliable \nand valid given the sampling approach, variation \nin respondent perceptions, and triangulation \nof descriptions relevant to key elements of the \nresearch questions.\n‘Do no harm’ approaches to ethics \nand security in research\nOne of the key aspects shaping the development \nof this research was the location and identity of \nthe implementing organisation. As an organisation \nthat has worked with activist communities for \nmore than a decade, Tactical Tech is known \nfor providing capacity building and training \nworkshops around digital campaigning, privacy \nand security. This work has made the organisation \nsensitive to the implications of engaging and \nintervening in a community; therefore, the need \nto maintain relationships over time, in order to \nbuild and sustain networks, has become a part \nof its core values and practices. As a direct result \nof this, Tactical Tech had pre-existing networks \nof collaboration and trust in Kenya and South \nAfrica. It has also been involved in supporting \nthe practices of communities of activists around \nthe world, in some cases dealing with sensitive \nexperiences of safety, security and well-being.\nSuch an organisation faces ethical considerations \nin the course of research. For example, if \nrespondents are discussing risks and threats as an \nactive, ongoing situation in an interview, how can \nthe researcher use this knowledge without placing \nthe respondent at risk? If a respondent mentions \nthat she is struggling to manage her social media \nprofile and is worried about social censure and \n14\n40\nThe research: questions, context and designSection 2\n6 The complete research reports of each case study spell out the specific logistical steps undertaken as part of the ethical practice \nof doing research in these contexts.\nvisibility because of social media, how should the \nresearcher respond during the interview without \ndiluting purpose or introducing bias?\nIn this research, Tactical Tech also had to consider \nwhat publishing the findings might mean for (state \nand non-state) adversaries of LGBTQ people. Would \npublication inadvertently expose something about \nLGBTQ digital practices? As a consequence of \ninternal and external discussions on these issues, \nthis report does not include details that may risk \nexposing local respondents, their organisations and \nnetworks.\nNotley et al. (2015) find that developing an ethical \nframework and principles within which to evaluate \nNGO practices is complex, given the kind of work \nthat NGOs do in close collaboration with groups \nover lengthy periods of time. Their action research \nevaluated the impact of video advocacy projects \nwithin a global network, Video for Change. They \nfound that most measures of outreach tend to \ndetermine impact, whereas the processes and \npractices of video advocacy, participation and \nengagement with communities – and accountability \nto those communities – form a matrix of ethical \nissues in such work. They say:\n“This focus on defining the kind of participation \nthat matters across the full video-making cycle \ncritically differentiates Video for Change from \nmore traditional forms of documentary practice, \nwhich often keep communities and social \nmovements at arm’s length, either because \nthey do not know how to engage people using \nparticipatory methods, or they do not value \nparticipation, or because they feel they want \nto fall in line with more traditional journalistic \nethics in order to make claims about objectivity” \n(Notley et al. 2015: 10).\nFor networks like Video for Change and Tactical \nTech, relationships with communities are not kept \nat an objective distance; the strength of our work \ncomes from participation, sharing and engagement. \nTactical Tech has been funded to provide groups \nlike those interviewed in this study with training \nand capacity-building support, and it is part of our \norganisational mandate to provide these services to \ncommunities around the world. Thus, accountability \nto these organisations and communities constitutes \npart of our ethical practice in this work.\nOne of the principles which has been used in this \nstudy and other interventions at Tactical Tech is \n‘do no harm’, a principle that emerged from conflict \nand post-conflict transformation work and is \nrelevant to many community-based interventions \nand research. Do no harm involves working \nthrough the risks and opportunities presented by \nan intervention and prioritising the well-being and \nsecurity of participants. The do no harm principle \nsuggests that any intervention becomes part of \nthe context it wants to change, and inadvertently \nproduces negative impacts alongside the positive \nones (Anderson 1999). The desire to minimise any \npotential source of harm and to maximise positive \nimpacts was a guiding influence that shaped this \nstudy. In a practitioner setting, this approach – \nperhaps as one of many – serves as an ethical \nguideline in the absence of external ethical review \nboards or committees.\nThe desire to minimise any potential source of harm \nand to maximise positive impacts was a guiding \ninfluence that shaped this study. Do no harm \nprinciples were applied in both research contexts \nin terms of physical and logistical considerations, \nand practices of data collection, management and \nanalysis.6\nTaking research back to the \ncommunity\nOnce all the interviews were finished and draft \nversions of the two reports completed, in October \n2015, Tactical Tech organised two day-long \nworkshops Nairobi and Johannesburg with the \ncommunities and partners originally involved in \nthe research. The events were organised in order \nto generate interest in the research, and to have \nthe communities discuss and review the findings, \nhelping to clarify content and verify the analysis. \nThey were also an opportunity to bring together \nT4T&A actors in both cities with the members of \nthe communities directly involved in the research, \nalthough many members of the T4T&A community \nwere absent, despite invitations. \n15\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nBeing LGBTQ in Nairobi: the \ncontours of marginalisation\nHomosexuality is still very much a taboo subject \nin Kenya. Surveys conducted by the Pew Research \nCenter (2013) indicate that 88% of Kenyans \nview homosexuality as unacceptable, 3% find it \nacceptable, and the remaining 9% do not view \nit as a moral issue. This places Kenya among \nthe ten countries in the world least accepting \nof homosexuality. LGBTQ people in Nairobi face \nphysical violence, ostracism, homophobia, social \nexclusion, and structural and interpersonal \ndiscrimination. As part of this, the fear of blackmail, \nextortion and entrapment is justifiably high. The \nmajority of respondents in this research hide at least \nsome aspects of their lives, and the threat of being \nexposed is real and potentially deeply damaging.\nLGBTQ people in Nairobi face risks and barriers \nonline connected to the barriers and risks they \nexperience offline. While all LGBTQ people face \nmarginalisation and discrimination in Kenya by \nvirtue of the criminalisation of homosexuality, there \nare different levels of marginalisation within the \ncommunity, stratified by ethnicity, class and gender. \nIt is perhaps most relevant for those who are \nworking class and do not enjoy the safety provided \nby social status and wealth; poverty is the factor \nthat connects those respondents who feel most \nmarginalised.\nHowever, marginalisation is also particularly relevant \nfor lesbian, bisexual and queer (LBQ) women. When \ninterviewed, many LBQ women spoke of the Kenyan \nLGBTQ space being dominated by gay men, and \nthe relative invisibility they experience, both within \nthe movement and in the few safe, public spaces \nthat exist. Similarly, a growing trans movement \nhas put the issue of trans invisibility and violence \nhigh on the agenda for the LGBTQ movement. One \nrespondent said “everyone wants to see a Kenyan \nlesbian”, implying that both in the mainstream \nmedia and in activist circles, there exists a high \ndegree of exclusion of LBQ women, and a sense that \nKenyan lesbians might not even exist.\nWomen respondents perceived LGBTQ issues in \nKenya as often being framed in terms of the risk \nof HIV (human immunodeficiency virus) infection. \nAs a result, men who have sex with men (MSM) \nand gay men are highly visible through a number \nof funded collectives, NGOs, CBOs and events. One \nLBQ respondent who spoke about this asked: “Is \nthere one problem that all lesbians face?”, meaning \nthat one easily identifiable problem – like the threat \nof infection by HIV – is perhaps what LBQ women \nin Kenya need in order to be visible. The problem \nRO\nBI\nN\n H\nAM\nM\nO\nN\nD/\nPA\nN\nO\nS \nPI\nCT\nU\nRE\nS\n‘B’, a 32 year old gay man from Kenya, who fled to South \nAfrica in fear of his life.\nThe problem of invisibility itself is not visible: it lacks a \nparticular hook or focus for funding or other supportive efforts.\n3. Research results: Kenya\n16\n40\nResearch results: KenyaSection 3\n7 However, one respondent flagged that there are still people, particularly in the slums, who remain outside of the social media \nbubble. While efforts are made on the part of activists and NGOs to reach them, the fact that they are not online can mean that \nthey are not even aware that there are communities of people out there who are like them.\nof invisibility itself, she said, is not visible: it lacks \na particular hook or focus for funding or other \nsupportive efforts. This invisibility is compounded \nby the fact that, as other LBQ respondents pointed \nout, the fear of violence or negative consequences \nfor being visible prevents them from being publicly \nknown as LBQ. Recent documentation from Kenya \n(CAL and GALCK Kenya 2016), published after the \nfieldwork for this study was completed, describes \nthe extent of violence faced by LBQ women, \ndocumenting the damaging effects of pervasive, \nstructural and social homophobia and sexism. \nThough many LBQ women have been invited to \nspeak in mainstream media forums, not one woman \nhas chosen to respond, leaving the voice of middle-\nclass Kenyan gay men to speak for all Kenyan \nqueers. LBQ respondents in this sample made it a \npoint to mention that for upper-class or wealthier \nLBQ women in Nairobi, who do not have to use \npublic transport and can live in fairly homogenous \nand secure environments, the problem of invisibility \nwas not the same.\nSocial media practices and \nperceptions\nWhile a vast majority of people in Kenya have \nmobile phones, the question of access to digital \ntechnology and social media presents itself in \nmultiple and layered ways. Airtime is relatively \ncheap, but phones themselves may not be, and \nlaptops and tablets remain out of reach for many \npeople. Digital literacy is also an issue; the question \nis not just about having a phone or smartphone, \nbut also how a person uses it, what they know \nabout how it functions, whether they have the \nknowledge to make informed decisions about \nhow to use it effectively and to feel sure of what is \nsafe and what is not. Despite low digital literacy, \nrespondents have evolved specific responses to \nmanaging and mitigating the threats they face.\nGiven the criminalisation and high level of \nmarginalisation that the LGBTQ community faces in \nKenya, both from the state and from society, there \nis a tension between the necessity of maintaining \nindividual anonymity in activism, and developing a \nvisible community in resistance to the invisibility of \nLGBTQ people in Kenyan society.\nFieldwork interviews showed that social media, \nprimarily Facebook, was the most used and \naccessible online space for the LGBTQ community, \nwhere “everyone is connected – low income or high \nincome”.7 Social media serves not just to connect \npeople, but also to provide space for knowledge \nsharing and support. One respondent reported that \n“every day we pose a question [online] – whether \nit’s on substance abuse, violence, trauma from \nassault or whatever queer women in general are \ngoing through. We have created visibility that way.”\nHowever, while the use of social media is \nwidespread, nearly all respondents maintain two \naccounts on Facebook because of high levels of \nlateral surveillance: a ‘straight’ account using their \nreal name, where they connect with their family, \nstraight friends and church community; and a \nqueer account under an adopted name where they \nconnect with others in the LGBTQ community. The \nuse of an adopted queer name is widespread and \nmay be used in offline contexts too – particularly \nwhile establishing trust in new relationships. \nNevertheless, the two accounts can result in \ndangerous situations; respondents described being \naccidentally outed to their families after being \ntagged under their real name in a photo attending \na LGBTQ gathering. Cases of surveillance also \ninclude family members actively seeking out queer \naccounts to expose users.\nHaving two accounts requires a considerable \ndegree of management and negotiation. LGBTQ \nKenyans often use their adopted Facebook names \n“Every day we pose a question [online] – whether it’s \non substance abuse, violence, trauma from assault – \nwhatever queer women … are going through. We have \ncreated visibility that way.”\n17\n40\nSection 3 Research results: Kenya\nboth in the online and offline contexts within \nthe LGBTQ community; someone who meets a \nFacebook friend offline will only refer to them by \ntheir adopted name, not actually knowing the \nperson’s real name. But LGBTQ individuals who \ncome across the ‘straight’ account of an LGBTQ \nfriend often will not add them as a connection. \nHarry explained: “I’ve seen my queer friends have \ntwo accounts, and I’ve gotten to see their straight \naccount. I usually don’t add their straight account \nbecause they haven’t added me on it.” \nWhile the online world offers freedom as well as \nrisks, respondents in the sample indicate that \nthey create their own risk mitigation measures. \nThese included particular methods for managing \nvisual images online, captioning and tagging of \nvisuals, admitting people into social media groups, \nand verifications of identity for admittance to \nparties. Some respondents indicated a careful \nuse of privacy mechanisms. For example, Thomas \nsaid that LGBTQ people will not put photos of \nthemselves as their profile pictures, that queer \naccounts more often have “pictures of random \npeople, like Rihanna or whoever. You don’t use your \nface on that account.”\nThe use of multiple social media accounts to \nescape exposure finds a parallel in Pakistan. Emrys \nSchoemaker finds a practice of multiple social \nmedia accounts among lower-middle income men \nand women in smaller towns in Pakistan where a \npractice of ‘digital purdah’ is used by men with \ntwo Facebook accounts to ‘protect their culture’; \ntwo accounts allow them to have one for male \nfriends outside the family, and another account for \nfamily members (Schoemaker 2015). The rationale \nfor these two accounts is that they do not want \npictures of their female family members accessible \nto men outside the family. Women who are already \nsegregated and in purdah actually remain there \nin the online world. So having two accounts, in \nboth the Kenyan and Pakistani contexts, concerns \npeople selectively hiding and revealing themselves \nbecause of social norms and values. However, this \nrevealing and hiding only serves to maintain the \nstatus quo: both the Pakistani women who have \nbeen veiled, and the Kenyan LGBTQ people who \nhave been closeted, remain hidden.\nThe tension between anonymity and visibility \nis not just about being seen or not being seen. \nVisibility and anonymity take on different meanings \ndepending on the context in which the digital is \nbeing used. LGBTQ people experience the digital \nboth as personal individuals and as engaged, \npolitical actors and activists. There is a desire for \npersonal anonymity to the hostile outside world, \nand visibility in participating in the local LGBTQ \ncommunity; at the same time, there is a desire \nfor visibility as a community and for LGBTQ rights \nthrough the medium of the digital, at the same \ntime as a need for privacy as a community when it \ncomes to offline events and activities.\nHowever, the study shows that anonymity is difficult \nto maintain. It demands attention and a constant \nawareness of the leakage of digital traces – through \nchanges in the settings of social media platforms, \nand through the actions or inactions of others – \nand how these may put a user at risk of exposure. \nThe social media platforms where these different \nstates play out are unable to contain the shifting \npositions and needs of individuals to use and \nmanage the technology they have access to.\nDiscussion of social media platforms was \ndominated by Facebook. Twitter, for instance, is \nnot as popular as platforms which connect only \nfriends and known groups; it is perceived as being \na tool to connect with communities that are global, \nand thus less interesting to the LGBTQ community \nhere. Active Twitter use was mentioned by only \none respondent, an activist working for a NGO and \nengaged in national, regional and international \ndiscussions on gender and sexuality rights. For \nothers working in NGOs, Twitter was occasionally \nused to publish organisational updates.\nUsing T4T&A tools to report \nviolence\nLGBTQ people interviewed in this study listed \nexperiences of facing interpersonal violence, which \nthey attribute to being socially ostracised and \nmarginalised: ostracism or estrangement from family, \nstreet harassment for appearing different, bullying, \nassault, eviction from housing, public humiliation \nand shaming, corrective blackmail, extortion, \nsexual harassment at the workplace, and coercive \nsex. The threat of physical violence and attacks on \nLGBTQ NGO offices have led respondents to employ \nstrategies to secure their physical spaces through the \nuse of closed-circuit television at office entrances, \nphysical security, sign-in / sign-out books, and so on.\nThe scale and extent of this violence in a climate \nwhere there is no recognition of LGBTQ people’s \n18\n40\nSection 3 Research results: Kenya\nrights makes reporting it extremely difficult. Study \nrespondents said that there is no point in talking \nabout these incidents or attempting to address \nthem, because they do not trust any institution \nor individual to actually respond positively. Could \nanything come of reporting violence? The rest of \nthis section describes the origins and reception of \nUtunzi and Speak Out, two T4T&A applications to \nreport on violence faced by LGBTQ people.\nUtunzi\nTwo Nairobi-based developers wanted to do \nsomething to support the LGBTQ community \nbecause of its relative invisibility in Kenyan society, \nand the fact that violence and discrimination \nagainst LGBTQ people often goes unseen or \nunnoticed because of a lack of empirical evidence. \nSo they developed Utunzi, a crowdmap to report \nviolence. Several hundred individuals submitted \nreports to the platform during Utunzi’s initial \nlaunch, but after this early interest the number of \nreports dwindled significantly. When investigating \nwhy individuals are not likely to use such a \nplatform, several key issues emerged.\nNo connection with the community\nLGBTQ people sampled for this study – that is, \npotential users of Utunzi – were not even aware \nthat it existed. There was limited sensitisation or \ncapacity building within the LGBTQ community on \nhow the platform works, or about why reporting \nviolations against LGBTQ people is necessary. \nSo, even if the tool was known, there were \nno mechanisms through which to engage the \ncommunity and popularise the tool. Jeremy says:\n“In an ideal world, it’s best that it has \norganisations’ complete buy-in. Like right now \nI have a case, which I should have reported to \nUtunzi, but I didn’t report it … because I don’t \neven know if it exists anymore. So we need \nto have a space where people can know that \nimmediately [when] you post something in this \nspace, a solution comes on board. Even if it’s \nsomeone who is coming up with a tool, engage \nthe organisations in developing it. And let them \nunderstand this is a space, then they will take \nup the responsibility to take it to the community \nmembers and tell them.”\nHowever, the developers and people associated \nwith the project insist that there was discussion \nwith the LGBTQ community. It is possible that the \nsample of respondents interviewed here were not \nconnected to the developers or involved in their \ndiscussions with the LGBTQ community about the \ndevelopment of Utunzi. \nLGBTQ respondents in this case study were asked \nabout their awareness of Nairobi’s thriving non-\nprofit and social justice technology community; \nit was found that there was almost uniformly no \nawareness of this work or community. Through \nthe research, and in the workshop held to share \nfindings, it emerged that there was little or no \nconnection between LGBTQ communities and the \nT4T&A communities. There is, generally, limited \nsupport for NGOs and activists in their use of \ntechnology.\nAlso, LGBTQ respondents do not feel they have \naccess to skilled and sensitive people that they \ncan turn to for inexpensive solutions and support \nto meet their tech needs. For example, a member \nof a LBQ women’s art collective in Nairobi said \nthat simple tech support to build a website that \nwould not be trolled or defaced in any way was \nnot available; they could pay for a commercial \nweb developer if they had the money, but were \nuncomfortable sharing sensitive information such \nas administrative access to their infrastructure to \nsomeone who could be homophobic.\nAn easier interface and accessibility\nAs a web-based platform, Utunzi required \nindividuals to use a computer, introducing an \nentry-level barrier. While many individuals in \nKenya have a phone with a data plan, computer \nownership rates remain low. Several respondents \nsuggested that an app-based tool would be more \neffective and have higher uptake than a web-\nIndividuals did not necessarily trust that the data \nthey were submitting in a report would be used for \nthe purposes stated on the website.\n19\n40\nSection 3 Research results: Kenya\n8 A popular mobile money transfer service in Kenya.\nbased platform. Respondents also found the \ntool complicated, and said they need something \neasier. “For us it’s too complex. It needs to be \nsimplified. As simple as possible. Not all of us \nare technologically ‘chop-chop’. It’s simplifying it. \nWhatsApp is very simple. You type something and \nit’s done.” Activists in this sample recommended \na mobile app or an app-based hotline where users \nwere not required to access a website, and could \nget an immediate response to an immediate crisis.\nLow trust\nRespondents in this sample said that there was a \nsignificant issue of trust associated with this, and \nsimilar platforms. The issue of trust plays out in the \nfollowing ways.\nIndividuals did not necessarily trust that the \ndata they were submitting in a report would be \nused for the purposes stated on the website. \nDespite security measures put in place by \nplatform developers, respondents felt that they \ndid not know that data would be communicated \nsecurely. There was little indication of a known \nor trustworthy organisation behind the platform \nand, due to a culture of social stigmatisation, \nblackmail and extortion of the LGBTQ community, \nmany people do not feel secure in sharing \npersonal details. Alfie stated: “People are also very \nreluctant to post. This is because of the fear of \nbacklash. If I post there and my friend who’s not \ngay sees, what will happen? He or she might start \nrejecting me. People are afraid the information \nmight get out.”\nSimilarly, another respondent, Grace, stated:\n“I know somebody who went through some sort \nof ... bad stuff happened to her and I tried to \nconvince her to report it both using a tool and \nalso to police but she was not willing to do it. I \nhonestly don’t know why. Maybe they’re afraid \nthat information will get somewhere out ... It’s \nvirtual ... by the time you get there it’s already \ndone. Nothing happens after that information is \ncollected. It’s put in a basket. People feel like, \nwhat’s the point of doing it?”\nRespondents indicated a general sense of distrust \nwith any kind of app or platform, with the exception \nof M-Pesa,8 and an overwhelming sense of \nscepticism for platforms addressing socio-political \nissues in Kenya. This finds resonance in a recent \nGlobal Consumer Trust Report, which found that \nin Kenya and other parts of Africa, user trust has \ndeclined in downloading and using apps because of \nthe lack of protection for personal information and \nthe threat of malware (MEF 2014).\nAlthough it was actually independently developed \nby two local technologists, only receiving support \nfrom an international organisation during its \nsecond phase of redevelopment, Utunzi was \nassumed by respondents to be funded by an \ninternational NGO. Many said that they were \nsuspicious of the motivations and actions of \ninternational NGOs that engaged a community in a \nnew project without anything positive accruing for \nindividuals or the community. During the research \nwe heard respondents asking what the benefits of \nparticipating in a research project would be for them \nor their community, on more than one occasion.\nRespondents said that those people who did submit \nreports to Utunzi – who overcame the obstacles of \naccess, trust and awareness – did not receive any \nresponse from NGOs or platform administrators. \nWhen people did hear back, it was often many \ndays later, long after the emergency had been \naddressed elsewhere. It is not surprising that \nresponses were delayed; Utunzi was not structured \nas an emergency-response platform, even though \nusers thought it was. So, there was a fundamental \nmisconception about the purpose of this crowdmap. \nThe lack of response from NGOs and organisations \nmaintaining Utunzi further damaged trust in this \nplatform. One respondent likened the platform to \ndesks at police stations for reporting gender-based \nviolence: a good idea in theory but not in practice. \nWhile present at all police stations, ‘gender desks’ \nare seldom used due to victims feeling that police \ndo not take reports seriously or do not adequately \nfollow incidents up after they have been reported.\nUtunzi repurposed\nThe Utunzi example indicates that if the violence \nfaced by LGBTQ people were to be addressed \nthrough a crowdmap, it would require far more \nengagement with the community and its networks; \ninterfaces need to be easy to navigate and there \nneeds to be an assurance of impact and beneficial \noutcomes for individuals. These learnings were \nshared with a funding organisation that implements \nprojects for and with LGBTQ networks in Kenya. \nAt the time of conducting fieldwork in Nairobi, a \nfieldwork interview was conducted with the project \n20\n40\nSection 3 Research results: Kenya\n9 ‘Speak out’ is not the real name of the platform. Information requests about the service can be directed to Maya Ganesh at \nTactical Tech.\nmanager, George, who works at an international \ndonor agency that is managing the redevelopment of \nUtunzi, and has a history of working in LGBTQ NGOs. \nThe donor organisation George works for has \nbeen supporting an emergency response project \nfor coalitions serving LGBTQ communities on the \nborder with Uganda. Following the criminalisation \nand active persecution of LGBTQ people there, \nthere has been increased vigilance and anxiety on \nthe part of Kenyan LGBTQ groups. This work, and \nreports from LGBTQ people in Nairobi, indicated \na need for a coordinated emergency response to \naddress the violence the community was facing and \nreporting. Emergency requirements in these cases \ninclude medical services, legal aid and psycho-social \nsupport and counselling. \nWhen it became clear that Utunzi was not working \nas a crowdmap for individuals to report violence, \nGeorge and his colleagues took a decision to make \nit a specialised site for sending reports of violence \nto a network of vetted first responders. According \nto George, these revisions in Utunzi were intended \nto create an efficient response, not necessarily \na direct response. Although the phone number \ncalled from or the Internet protocol (IP) address \nfrom which an online report is sent are logged, the \nfull report of the case is not stored on the site’s \nservers. Information about a case will be carefully \ndocumented. The case will be verified by whoever \nwithin the network of first responders receives the \ncall, to make sure it is legitimate. There is a roster \nof first responders, so if one cannot respond for \nsome reason, there are others who can take on the \ncase. Other changes to Utunzi include:\n• a focus on a specific region, with attention \ndirected to supporting responders there\n• cases are documented more thoroughly, and \ndata are analysed every month.\nThe story of Utunzi offers some valuable lessons, \nthe simplest and most critical of these being that \ntechnology applications for a community need \nto be developed in consultation with them and in \nresponse to their needs.\nSpeak out\nOne of the other T4T&A projects that emerged from \nthe Nairobi case study was ‘Speak Out’,9 a platform \ncomprising a Facebook page and a Twitter feed. \nIt was started by an individual whose identity is \nknown to the LGBTQ community in Nairobi, but who \nwas not interviewed for the research. Thus, this \nresearch reflects on Speak Out through interviews \nwith its users and supporters. Speak Out was \ndeveloped through technical support and strategic \ndevelopment with an international NGO and \ntherefore is not as entirely ‘homegrown’ as some \nrespondents described it. \nCloseted MSM (men who have sex with men) and \ngay men are particularly vulnerable to blackmail \nand extortion. The internet – social media, dating \nsites and mobile dating apps like Grindr – is a \npopular way for MSM and gay men to meet each \nother away from the gaze of mainstream society. \nBlackmailers and extortionists also spend time \non these sites posing as potential dates, sexual \npartners or lovers. It is common practice to talk \nfor a while online, sharing seemingly benign yet \nsensitive personal information such as occupation, \naddress, personal details before meeting in \nperson. Meeting in person is considered to be more \nrevealing; graduated anonymity is considered to \nbe a protective mechanism that closeted gay men \n/ MSM have employed for their own security.\nHowever, this is an instance of a security tactic that \ncan backfire: blackmailers use this extended period \nof online communication to extract information \nabout a gay man / MSM. When blackmailers (often \npart of an organised gang) believe they have \nenough information, they reveal their real intention: \nextortion. They threaten to out the individual to his \nfamily or employer unless they pay. Respondents \ndescribed their friends (never themselves) as \nsometimes being caught in the act as blackmailers \nburst into the room, or out of the closet, taking \nphotos on a phone. These photos and the online \nexchanges are used as leverage for blackmail.\nOne human rights lawyer interviewed here who \nrepresents LGBTQ people said that the most \ncommon cases they get are of blackmail, and that \nbeing underground and closeted is extremely \ndangerous for gay men / MSM. Those gay men \n/ MSM who are open about their sexuality are \nless likely to be blackmailed, although it is not \nuncommon to face other forms of discrimination \nand /or violence.\nThus the approach of Speak Out is simple: given \nthe scale of blackmail and extortion suffered, \n21\n40\nResearch results: KenyaSection 3\nparticularly within the closeted gay community, \nSpeak Out serves to expose the extortionists. \nDescribed as an online platform to monitor human \nrights abuses against sexual and gender minorities, \nSpeak Out invites people to submit the names \nand addresses, handles and online aliases of \nblackmailers and extortionists which, after careful \nverification, are then published on Speak Out’s \npages as a warning system for other closeted gay \nmen. Speak Out also verifies and documents cases \nof violence against the LGBTQ community. It is \nwell respected within that community and by the \nrespondents. It serves as a symbol of resistance \nthat is based on familiar, known platforms and \nprovides an active service to the community, \nallowing them to secure their own online and \noffline spaces.\nConclusions\nBoth Utunzi and Speak Out offer valuable insights \ninto how the development and uptake of T4T&A \nprojects have occurred in this community. Both \nwere imagined as a response to the struggle to \nmanage visibility and anonymity. In the case of \nUtunzi, a crowdmap was used to make violence \nvisible, and this visibility was assumed to be key \nin claim for rights and acceptance in Kenyan \nsociety; however, the development of the project \nneeded more investment in user research and \nthe context of uptake by the LGBTQ community. \nSpeak Out works in the opposite way, to \nexpose the perpetrators of violence through \nthe productive use of the online exchanges and \nmaterials that are used to extort and harass a \nvulnerable community.\nSpeak out serves as a symbol of resistance that is based \non familiar, known platforms and provides an active \nservice to the community, allowing them to secure their \nown online and offline spaces.\n22\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\n4. Research results: South Africa\nThis section presents results from the case \nstudy of how marginalised communities in \nSouth Africa engage with technology, and \nwhat inhibits them from using T4T&A tools. \nThe findings are from fieldwork interviews with \nactivists working on housing, land and urban \ndevelopment rights in Johannesburg, South \nAfrica. This work is described here alongside a \nset of formative interviews in Cape Town, held \nfive months prior to the fieldwork, with activists, \nlawyers and academics working on similar issues. \nBoth the formative interviews and the fieldwork \ninterviews presented diverse and rich insights into \ntechnology usage and applications across a broad \ncontinuum of actors; it is for this reason that they \nare presented here together, and both inform the \nanalysis of the findings from South Africa. \nThe results describe the particular instance of \nhow communities of activists use Freedom of \nInformation Act requests to obtain ‘the housing \nlist’, and what this means for a broader view of \nT4T&A activities. They also describe how low-\nincome communities use technologies in mobilising \nand organising, and the issues of trust, violence \nand marginalisation that emerge from this.\nThe landscape of activism\nIn the landscape of South African activism and \nengagement with housing and urban development \nissues, a rich tapestry of this country’s history \nof struggle emerges. One of the findings from \nthe formative interviews is that within the social \nmovement for housing and urban development \nrights, activists can be clustered according to their \nsocio-economic status, age and location, reflecting \ndiffering histories of privilege and oppression. This \ngrouping helps contextualise diverse activists’ \nperceptions of the uses and practices of technology \nin their daily lives and activism. Both the formative \nand fieldwork interviews served to define the \ndifferent kinds of actors in this space, which include: \n‘NGO activists’, ‘legal NGOs’, ‘urban development \nNGOs’, ‘housing researchers’, ‘old-school land \nrights and housing activists’ (as opposed to \nA drone-mapping image of Kya Sands informal settlement (right) and Bloubosrand suburb, Gauteng, illustrating the spatial \ndynamics of housing inequality in Johannesburg, South Africa.\nJO\nH\nN\nN\nY \nM\nIL\nLE\nR \n/ \nM\nIL\nLE\nFO\nTO\n, W\nW\nW\n.U\nN\nEQ\nU\nA\nLS\nC\nEN\nES\n.C\nO\nM\n23\n40\nResearch results: South AfricaSection 4\n‘younger activists’), ‘mass-base NGOs’, ‘community \ndevelopment forums’ and ‘building committees’.\nWhat this diversity of actors implies is that \nthe practices, uses, risks and barriers of using \ntechnology are specific to each group, serving \ndifferent functions in each case. The class, racial, \nethnic and gender backgrounds of individual \nactivists determine what their engagement with \ntechnology and activism is, and what sorts of \napproaches they will adopt. Those who work in \nformal NGOs engaged in ‘development’ in the \nurban setting position themselves and function \nquite differently from those in working-class \nmovements based in informal settlements. The \nsample also includes older and younger activists, \nand the most distinctive aspect of this age divide \nis that the older activists all have a history of \nbeing involved in anti-apartheid struggles, which \nshapes their perceptions and practices concerning \ntechnology use. \nRespondents noted distinctions between their two \ncities, saying very pointedly technology projects \nand data-based advocacy manifest differently \nin Cape Town and Johannesburg. Johannesburg \nrespondents perceived NGO activists in Cape \nTown, many of whom are white, to be more data \nsavvy and technologically advanced, and to be \nusing open data. \nTwo linked interactions during the formative \ninterview stage of the research revealed some of \nthese differences in geography, race and class. \nIn Cape Town, a Right to Know advocate said in a \nformative interview that “secrecy has destroyed \nSouth Africa ... We need to end secrecy and \neveryone and everything should be transparent … \nNo one should be invisible … Privacy should only \nbe for journalists and their sources who need to \nbe protected.” When pushed to clarify, he said that \nhe believed that privacy was not essential to other \nactivists.\nThis quote, with the identity of the source \nwithheld, was presented to a different respondent \nin a formative interview. The respondent in \nthis interview was a black woman activist \nin Johannesburg, a passionate champion of \napplications of technology for social justice. She \ntold her story of coming from an impoverished \nprovince and working to expose corruption and \ninjustice. Her house was burnt down for blogging \nabout campaigns against corporations; she has \nbeen threatened for writing about whistle-blowers. \nShe was scathing about the idea of complete \ntransparency. “Complete transparency is a nice \nidea for white men in the suburbs ... Whiteness \nprotects people in South Africa and it is a white \nlens through which this idea of transparency is \nseen. It is also a gendered lens … I need to speak \nanonymously sometimes.”\nThese divisions were not necessarily discussed \nin a negative sense; rather, respondents used \nthem as a way of pointing out that it is important \nnot to view either activists or movements as \nmonolithic, and that T4T&A activities must be \nsure to engage with the right kind of actors. \nIf they do not, there is the risk of launching \nactivities in communities that are not well \nresourced, and do not have either the capacity \nor the support to engage in activities.\nThe housing list: applying T4T&A in \nmovements and communities\nSouth Africa has a progressive constitution that \nguarantees housing to its citizens, along with the \nright to services, to not be evicted, and to be free \nof arbitrary searches that were common during \napartheid. However, while the state is responsible \nfor providing housing for its citizens, it falls short of \nmeeting this responsibility. According to academic \nMarie Huchzermeyer (2013), the 2013 UN Habitat \nreport ranks Johannesburg as the world’s most \nunequal city, and the number of shacks and \ninformal settlements is only continuing to grow. \nDuring apartheid, communities were forcibly \nremoved from their places of residence and had to \nlive with others of the same race. While the post-\napartheid era has brought de jure equality to South \nAfricans, the state’s neoliberal policies continue to \nsustain economic inequalities, particularly across \nracial lines. In South Africa, the state has failed \nto provide housing or do away with corruption, \nand there is a lack of transparency in housing \nallocation, spatial inequality, an absence of pro-\npoor planning and insecurity of tenure.\nThree of the formative interviews discussed ‘the \nhousing list’, which describes the schedule and \norder of housing allocations, and is considered \nto be a kind of holy grail for housing-rights \nactivists because it can be used to monitor the \nstate practice in allocating housing to citizens. \nThese interviews highlighted the structural and \nphilosophical issues about applying technological \ntools to support housing claims. \n24\n40\nResearch results: South AfricaSection 4\nThe housing list is particularly relevant and \nimportant for households and whole communities \nthat have been evicted (‘temporarily relocated’) \nand must wait for permanent housing to be allotted \nto them. Lawyers working with such communities in \nCape Town use paper-based freedom of information \nrequests, known as PAIAs (Promotion of Access to \nInformation Act), both to identify when they can \nexpect to be relocated and as a pressure tactic on \nthe state that keeps them in temporary housing, \nsometimes for as long as ten years. The Right to \nKnow movement is an active partner in this. \nOne of the three respondents, a lawyer, said: “The \nunderstanding around housing delivery is that \nthere is a ‘waiting list system’ which constitutes \na housing queue, and that people must wait \npatiently until their name comes up in terms of \na rational process of ‘first come, first served’ … \nThis is why the list is important.” Once the list is \nfinally made available, however, people find their \nnames and details of new housing on it, but they \nalso find that the actual process of allocation does \nnot proceed rationally or logically. The respondent \ncontinues: “People have been on waiting lists, \nbut their homes never materialise, or people who \ncame after them [on the list] get houses first. \nSo the focus tends to be on the immediate need \n(rightfully so), but at the expense of sustainably \nor meaningfully addressing the problem of \nhousing ... The list isn’t everything.” Research \nfrom the Socio-Economic Research Institute of \nSouth Africa (Tissington et al. 2013) finds that \nthe housing list and its promises of ordered and \nequitable allocation are a myth because of the \narray of opaque policies and bureaucratic details \nsurrounding the list itself, which impede housing \nallocation, and government corruption.\nRespondents shared the learning that mechanisms \nto access information are just one, early stage in \nthe process of housing allocation, but that they \nneed to be integrated into campaigning, or used \nas a piece of a broader advocacy strategy. “Access \nis one thing, but then what?” asked another \nrespondent, also a lawyer, before going on to point \nout that the step after access is legibility. This \nrefers to the ability to make information part of \na campaign, to use it strategically as leverage in \nengaging with a bureaucracy, and to understand \nhow it works and where it comes from. There are \npeople who know how to do this, and those who \ndo not: the respondent described the difference \nbetween them as a “data divide”. \nFormative interviews underlined the importance \nof distinguishing between “intermediaries” who \nare considered to be more adept in the use of \ntechnologies, and “communities” who are seen as \nbeing on the “receiving end” of T4T&A applications \nand activities.\nWhen communities do have access to information \nwith which to hold the government to account, the \nrespondents discussed how it is difficult for them to \nengage with or negotiate with government actors: \n“Even if people do get access to technology and \nthe information they need, they don’t really know \nhow to engage with power.” To illustrate her point, \nthis respondent took out her notepad and drew \ntwo circles on the opposite ends of the page. She \nlabelled one ‘state’ and the other ‘community’. \nWithin the circle representing the community, \nshe drew some smaller circles. “Communities \nhave gatekeepers, power centres,” she said, of \nthese smaller circles. “How they make sense of \ninformation and technology is crucial.” She then \ndrew even smaller circles, between state and \ncommunity but closer to community, and labelled \nthem ‘intermediaries’. “There is the mistaken \nassumption,” she said, “that putting some wires \nbetween states and communities will have them \ntalking to each other.” She went on to note that for \na community engaging with the state through its \nbureaucrats and functionaries, there is a learning \ncurve to “talking with and through” data and \ntechnology. \nThese two respondents also stated that there are \nassumptions underlying how a community will \nuse the information and technology it has access \nto. If there is a data exchange with the state – \nperhaps taking the form of spreadsheets, maps, \nshort message service texts (SMSs), statements or \nvisuals – data is assumed to be something rational, \nthat will be understood in a rational manner. But, \nsaid one respondent, “data only reveals patterns, \nand there is no piece of data that a community \ncan actually use. It has to be made sense of by \nsomeone for them … Who is this someone?”\nThis particular interaction must be read as a \ndistillation of reflections from an intermediary \nsupport organisation working with low-income \nand marginalised communities, over a number \nof years, based on the use of different tools and \ninformation to hold local government to account. \nThe interaction articulates the need for a theory \nof change to accompany the application of T4T&A \n25\n40\n10 In a workshop in Johannesburg in October 2015 where research results were shared, Wits University professor Indra de \nLanerolle discussed the project and details such as the use of Unstructured Supplementary Service Data (USSD) codes to report \ninformation, which enabled users of legacy and ‘dumb’ phones to participate at no extra cost.\nResearch results: South AfricaSection 4\ntools in community work, as well as highlighting \nthe importance of recognising the dynamics of \ndifferent communities and movements.\nThere are examples of successful collaborations \nacross different communities to learn from. For \nexample, formative interview respondents referenced \na strong example of collaboration, the Our Toilets \nAre Dirty mobile phone-based social audit of toilets \nin Khayelitsha township in Cape Town (Ukwazi \n2014). This was significant because people \nassociated with the audit felt that the collaboration \nwas positive and beneficial, and there was an \napplication of technology that was inclusive.10\nTechnology practices among \nmarginalised activists in Johannesburg\nThe fieldwork interviews in Johannesburg – with \n17 activists who are from, or working with, low-\nincome housing rights and urban development \norganisations – resulted in information about their \ntechnology use and practices, and the limitations \nand barriers they face in using technology. \nMobile phones were reported to be the most \nwidely used device for activism and community \ndevelopment work. However, airtime tariffs are \nparticularly high in South Africa and only 62% of \nSouth Africans use a mobile every day; far fewer, \njust 22%, report using the Internet on a daily basis \n(de Lanerolle 2012). This is compounded by the \nfact that to get a mobile, it is necessary to have a \nregistered address and identification, which poses \na large barrier to undocumented migrants from \nneighbouring countries. Some respondents from \nNGOs viewed mobile phone use as “ubiquitous”, \nbut responses from local community activists \nsuggested otherwise.\nThe same factors which place mobiles out of reach \nfor some community members, place computers \nand tablets even further out of reach, particularly \non an individual level. Instead, computers are \nassociated with offices and tend to be used more \nin the context of NGOs than community activism. \nComputers may be accessed for specific purposes, \nsuch as research or emailing, but this is likely \nto require a trip into the city centre to an NGO \noffice or Internet cafe. And access, even in this \nlimited sense, is shaped along lines of gender and \nage. Email has very low levels of uptake in the \nactivist community and is used more for official \ncommunication than for informal communications \nwithin a social group.\nWhile mobile use might be prevalent among \nactivists themselves, members of low-income \ncommunities, especially women, have very limited \naccess to mobiles; in some cases, women must ask \ncommunity leaders – mostly men – to make calls for \nthem, even in emergencies. Furthermore, unreliable \nelectricity supply can mean that people are unable \nto charge their phones. Nevertheless, poorer, black \nactivists often use phones to allow them to conduct \nmeetings from afar, to avoid having to travel into \nthe city centre, saving time and money. Voice calls, \nSMS and WhatsApp are the most used features for \nactivism and organising, as well as to listen to and \nparticipate in local radio shows.\nWhatsApp is favoured by activists as it uses \nminimal data, and group chat features make it \nappealing for social organising and mobilising. It \nis also ‘reshaped’ for uses it was never created for, \nsuch as recording the minutes of group meetings \nand creating virtual newsrooms.\nPolice that monitor these activist communities are \naware that WhatsApp is popular and central to \nactivists’ organising. Some respondents report that \npolice claim to have intercepted activists’ WhatsApp \nmessages and have told them so, resulting in a fear \nof surveillance. However, local experts claim that \nthe police do not have the technical capacity for \nWhatsApp interception, and are only saying so to \nintimidate activists and obscure the fact that they rely \non informants, which is not unusual in South Africa. \nA theme that emerged in discussions of the use \nof WhatsApp is that it is a space where movement \ndynamics and hierarchies are reinforced. Women \nactivists talked about how community WhatsApp \ngroups are used to make sexist or harassing \ncomments. Community group leaders also use \nWhatsApp to play power games with senior leaders, \npublicly shaming them. This makes it difficult \nfor other activists to engage, because they are \nreluctant to voice their opinions in group chats due \nto the fear of public shaming.\nNeither Facebook or Twitter were popular with this \nactivist community. The cost of data is an issue and \nneither of these platforms were thought to be essential.\n26\n40\nResearch results: South AfricaSection 4\nRisks of and barriers to using T4T&A \ntools\nCost is one of the primary issues inhibiting our \nrespondents’ use of technology. When asking about \nT4T&A applications, one respondent said “people \nwould rather have airtime to contact you in an \nemergency than use it to report corruption”. \nLanguage is another issue. Respondents from \nlow-income communities said that social media \nand T4T&A platforms tend to be predominantly \nin English, as well as perhaps Afrikaans and Zulu, \nbut in a nation with 11 national languages, and \nwhere socio-economic divisions have implications \nfor education and literacy, this can exclude large \ncommunities. \nThird, and linked to educational disparities and age, \nis the issue of digital literacy. Low digital literacy \nacts both in barring people from using tools as \neffectively as possible, and in preventing them from \nbeing able to assess the risks and possibilities of a \nparticular tool.\nRespondents reported that violence occurs as a \nresult of activists’ work being politically challenging \nand sensitive, and includes verbal and sexual \nharassment, physical attack, sexual assault, theft \nand destruction of data and devices, blackmail, \nand surveillance. According to the findings of this \nstudy, all forms of violence, including psychological, \nphysical, sexual, economic and state-perpetrated, \ncontinue to affect black South Africans \ndisproportionately.\nPolice monitoring, crowd control and the excessive \nuse of force against black working-class residents \nof Johannesburg’s informal settlements, continue \nto reduce activists’ capacities to participate \nsecurely in protest actions. A black male activist \nexplained that police or informants may monitor \nactivist events and “take steps to prevent the \nmarch, or sabotage the march, or try to prevent the \nmarch by harassing organisers, arresting them on \nspurious grounds, taking them out, or whatever”. \nBlack activists in the informal settlements also \nexpressed feeling mostly powerless to protect \nthemselves in protests due to gaping power \ndisparities between themselves and the police, \nnoting repeatedly that they only have stones to try \nto protect themselves when a protest turns violent, \nwhile the police have guns and other firearms, and \nuse them against protesters.\nSouth African activists’ concerns about ‘lateral \nsurveillance’ (Andrejevic 2005) have to do with \nthe fear of intimate partners, family, friends, \ncomrades and informants infiltrating activist \ngroups. One black South African male activist \nspoke about how some activists use intentional \nmisinformation in WhatsApp groups to prevent \npolice infiltrators or criminals from joining their \ndemonstrations. While no respondent offered \nexamples of actual instances that infiltration \nhad occurred, many voiced fears that it could \nhappen. One black male activist respondent gave \nthe hypothetical situation of “venting my anger \nthrough WhatsApp or Facebook, then someone \nelse with his / her own intention, having access \nto this [finger snap], can expose me that I’m in a \nvery unstable marriage, and stuff like that”. Lateral \nsurveillance of his personal communications \ncould be used by infiltrators to discredit him as a \nmovement leader. \nFears of surveillance tend to be stronger among \nthe older generation, particularly those in black \nand mixed race and poorer communities who \nexperienced high levels of surveillance first-hand \nduring the anti-apartheid resistance. Younger \nrespondents and those working in NGOs tended \nto view digital risks more in terms of privacy \nthan security. Fears of online surveillance push \nsome younger activists to re-adopt ‘old-school’ \ntechniques, including having sensitive meetings \nand conversations in offline spaces.\nBlack women activists raised issues of sexual \npredation and harassment, not only by police and \nstate authorities, but also in the CSOs where they \nwork. A black woman activist who is well connected \nThe cost of airtime inhibits the use of T4T&A tools: \n“People would rather have airtime to contact you in an \nemergency than use it to report corruption.”\n27\n40\nResearch results: South AfricaSection 4\n11 Respondents were referring specifically to a project by Code for South Africa and Ndifuna Ukwazi to use mobile phones to \nreport broken toilets in the Cape Town township of Khayelitsha. The toilets were paid for by the government and were \nsupposed to be maintained through local government support. The project encouraged citizens to report on broken toilets so \nthat the information could be taken back to the government.\nto different communities in Johannesburg – from \ncity-based development NGOs to slum-based \npopular movements – said that women working \nin CBOs, movement groups, networks and NGOs \nface daily risks of gender-based violence. Black \nand low-income women are more at risk, with \nfewer resources to respond to and recover from \nincidences of violence.\nIn more conservative rural areas, women activists \nreported facing retaliation and social ostracism \nwhen reporting corruption, particularly whistle-\nblowing about land and housing allocation fraud. \nOne black woman activist explained that “as a \nwoman, to be outspoken can be so complicated. \nAnd also to implicate a man in corruption, you \nwould be shunned.” She explained that traditional \ncommunity leaders are sometimes in collusion with \ngovernment officials or private sector companies \nin giving away land and selling houses meant \nfor internally displaced people. For a woman to \nspeak out against a man, and particularly one \nquite senior and respected within the community, \nwas fraught with risk of serious repercussions. \nWomen activists on community-based and activist \nWhatsApp groups tend to move from one-on-\none chats to group chats due to receiving sexist \ncomments from male activists in a one-on-one \nforum. Thus, there tends to be a perception \nthat while WhatsApp is a useful organising and \nmobilising tool, it does not foster debate or \ndiscussion within a community.\nA lack of trust\nTrust, or the lack thereof, emerged as a theme that \nappears that impede the work of communities and \nmovements. This is multifaceted. One aspect of this \nrelates to the fact that people do not necessarily \ntrust that the information they submit to a platform \n– such as, for example, a a platform for reporting \nbroken toilets – will be handled in a way that is \nsecure, transparent and free from corruption – or \nthat it will actually have any visible impact.11\nRespondents also articulated the absence of \ntrust in the government to respond to them, or \nthat they will ever receive the basic services they \ndeserve; they even described a lack of trust in \ntheir own movements and fellow activists. For \nexample, their concerns include local government \nward councillors’ duties and abuses managing \nadministrative lists of government-provided \nhousing applications: respondents felt there is \ncorruption and opacity in the allocation of housing. \nAdditionally, low-income respondents said that \nthey do not trust that city and state authorities will \nrespond in a timely manner, report corruption, or \ncall for emergency help. Black activists interviewed \nhere and living in informal settlements estimated \nthat an ambulance might come only three or four \ntimes out of ten. They explained that they think \nemergency services workers are afraid to enter the \nsettlements due to stereotyped media coverage \nof residents as troublemakers and criminals using \ngratuitous violence.\nTrust issues emerged in a different form for low-\nincome respondents who had experienced the \nviolent legacies of apartheid, and who continue to \nparticipate in the complex, ongoing, nationwide \nstruggle to fashion a post-apartheid South Africa. \nFor older members of this sample, this history puts \nthem in a low-trust and oppositional relationship to \nthe state, and they do not feel things have changed \nsince 1994. It is not much different for younger \nmembers, who do not have the same historical \nexperience yet feel they have not received their \ndues either in terms of resources, opportunities or \nPeople do not necessarily trust that the information they \nsubmit to a digital platform will be handled in a way that \nis secure, transparent and free from corruption – or that it \nwill actually have any visible impact.\n28\n40\n12 This is an ongoing movement of students and academics that began as protests against the increasing costs of university \neducation for black and historically marginalised communities in South Africa. The University of the Witwatersrand in \nJohannesburg is a centre of coordinated activities (www.feesmustfall.joburg) as well as University of KwaZulu Natal, Durban \nUniversity of Technology, Tshwane University of Technology and movements such as Rhodes Must Fall at the University of \nCape Town.\n13 Rhodes Must Fall is a movement that started on the University of Cape Town campus with a demand to remove the statue of \nCecil Rhodes; this was, however, part of a larger demand (which was eventually met) to dismantle the institutionalised racism \nin higher education in South Africa (http://rhodesmustfall.co.za/).\n14 Personal communication with Koketso Moeti (January 2016) and Achal Prabhala (January 2016). \nResearch results: South AfricaSection 4\nrights as equal South African citizens. The strong \nground-up student movement, Fees Must Fall,12 \nand the success of Rhodes Must Fall13 in 2015, are \nclear examples of their unhappiness at how, 20 \nyears after the de jure end of apartheid, historically \nmarginal communities continue to live in poverty \nand face discrimination. \nMedia reports indicate that there have been violent \nclashes between students of the Fees Must Fall \ncampaigns and police (Al Jazeera America 2015), \nand universities have brought in private security \nand threatened academic staff who are supporting \nstudent activism.14 The state’s use of violence \nto challenge the right of its citizens to protest, \nand the maintenance of secrecy and surveillance, \nindicates a mistrust of activism. This serves to \nshrink the space for activism and dissent generally, \nand this study documented this in the context of \nlow-income and marginal communities around \nJohannesburg. An example is Thembelihle, a \nresidential neighbourhood where citizens protesting \nlack of services have faced violence, and people’s \nprotests have been actively repressed by authorities \n(Clark 2014). The attacks on and surveillance \nof protesting citizens of Thembelihle, and the \nactivists of shack dwellers’ movements, point to the \ncriminalisation of activists and movements.\nThe incidents and experiences reported by \nrespondents, and the current climate of activism \nin South Africa, point to deeply fractured \ncommunication between the state and citizens, \nwhich will have to be addressed, and rid of violence, \nbefore it improves.\n29\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\n5. Reflections and learnings\nThis section presents reflections and analysis \nbased on the case studies to inform the strategies \nand approaches of communities engaged in \nT4T&A activities. The two case studies describe \nvery different contexts. Bringing them together \nin this report does not imply similarities between \nthem; rather, the intention here is to distil lessons \nfrom both and present them together, and to find \npoints of similarity that reinforce learnings about \napplications of technology.\nThe two case studies began as a question about \nhow and if the inability to guarantee privacy and \nanonymity online introduced risks in marginalised \nactivists’ use of technology tools in their \nadvocacy and activism. As Seda Guerses notes, \nanonymity is an end rather than a means, which \nenables – among other things – participation, \na collective voice and a distributed message \n(Guerses 2012). Tactical Tech’s work has shown \nthat the use of mobile phones and social media \nhas put activists, and marginalised communities, \nat risk. Yet limiting the risks of using technology \nis also complex and challenging, and requires \nparticular skills and training. In framing a \nquestion around these concerns, this study \nbegan with activists’ technology use and the risks \nand barriers they faced, so as to contextualise \nit within their actual practices and realities of \nwork on transparency and accountability in their \nsocieties.\nThe two cases show that there is a legitimate need \nfor anonymity and privacy, because technology \nplatforms do create negative exposure; but that \nthreats tend to be local and ‘lateral’ – that is, from \nwithin families, communities and movements. This \nresearch confirms the nature and dynamics of this \ntension for these communities and how it affects \ntheir use of digital technologies, and presents the \nfollowing additional issues:\n• Low levels of trust between communities of \nactivists and institutional authorities affect the \nkinds of dialogue intended to be inspired by \nT4T&A.\n• Marginalisation is reinforced and replicated \nwithin already-marginalised communities, \nperpetuating inequality and invisibility, and \ncreating new centres of power.\n• Violence at interpersonal, community and \nsocial levels is a common feature of the lives \nof marginalised people; institutionalised and \npervasive homophobia, sexism and racism also \nserve as barriers and limitations.\n• Social movements use technologies in organising \nand mobilising, and these can be a powerful \nway to motivate and reach out to marginal \ncommunities; movements are, however, shaped \nby their histories, and are complex, dynamic \nsystems in flux. Thus, the introduction of \ntechnology is never straightforward, predictable \nor easy.\n• A significant gap exists between T4T&A \ncommunities and marginalised activist \ncommunities, and must be bridged if T4T&A \napplications are to be successfully integrated \ninto social justice work.\nCustomise control over \nvisibility: understand user \npractices\nThe documentation of marginalised people’s \ninability to control negative exposure online \nsuggests that the language of openness, \ntransparency and visibility needs to be rephrased \nwith, and for, marginalised communities that may \nbe facing a range of threats from being online. \nSomething that is ‘open’ may on occasion need to \nbe closed, and visibility may need to be restricted \nfor those who are perceived to be threatening, or \nmerely outsiders. The extent of the homophobia \nfaced by LGBTQ Kenyans implies the need for \nsecurity and privacy, yet there is also an equally \nstrong need to connect with others in their \ncommunity, to have a sense of community, a social, \nemotional and sexual life, and to be visible as \nactivists who are engaged in political work around \nhuman rights. None of this is any different from \nwhat other activists do elsewhere in the world.\nReviewing the tactics and approaches taken by \nLGBTQ Kenyans who are online, it can be said that \nanonymity and visibility are negotiated positions, \nconstantly shifting in response to threats. \nAnonymity is intentional and purposeful in hiding \nto evade exposure, a tactic that is familiar to this \ncommunity and continues offline and online. It is \n30\n40\n15 The work of the Women’s Rights Program of the Association for Progressive Communications since 2009 (http://erotics.apc.\norg/) and recent research from Women, Action and Media about harassment on Twitter (Matias et al. 2015); (http://\nwomenactionmedia.org/cms/assets/uploads/2015/05/wam-twitter-abuse-report.pdf) are significant in this regard.\n16 Tactical Tech’s Security in a Box has custom ‘community guides’ available: https://securityinabox.org/en/lgbti-mena and \nhttps://securityinabox.org/en/lgbti-africa and https://securityinabox.org/en/women-hrdshope\n17 For example: www.defendingwomen-defendingrights.org/wp-content/uploads/2015/12/WHRD-IC-Gendering-\nDocumentation-Manual-1.pdf and https://tech.safehubcollective.org/cybersecurity/ https://gendersec.tacticaltech.org/wiki/\nindex.php/Main_Page\n18 There is recent work by Women, Action and Media, the Association for Progressive Communications and NGOs to directly lobby \nsocial media corporations to take a more active role in addressing online harassment and the restrictions on freedom of speech \nand expression online. Sustained advocacy against Facebook’s real name policy, and its questionable content-moderation \npractices, are already well documented and have been undertaken by various Internet governance and policy organisations.\nReflections and learningsSection 5\nalso a tactic to foster a sense of community. Those \nwho work on direct support to LGBTQ people facing \nhomophobic violence, and MSM or gay men who \nare closeted are more likely to face direct threats, \nviolence or surveillance. \nFor South African activists, the tension between \nvisibility and anonymity has to be managed in the \ncontext of offline surveillance, primarily through the \nuse of informants who report on fellow activists’ \nplans to the police. Protestors and the right to \nprotest and dissent is particularly under attack in \nSouth Africa, notably in response to student-led \nmovements. There is also a history of surveillance \nof activists that persists from the apartheid era \nand affects those who are especially vocal on \nstate secrecy, housing issues, land redistribution \nand human rights (R2K 2015). Results show that \ncommunities appropriate and reshape technology \nto suit their own ends, such as the two-account \ntactic employed by LGBTQ Kenyans, or the use of \nWhatsApp to record meeting notes and mobilise by \nSouth African housing activists.\nSome technology skills development organisations \nand networks, of which Tactical Tech is one, support \nactivists in learning about how to be secure and \nprivate in online communications. This can be \ninvaluable for individuals or organisations facing \nsurveillance and monitoring by governments or \ncorporate actors. Particular tactics and digital skills \nmay be required by women activists, journalists and \nadvocates who face harassment and harm online; \nthe harassment they face is explicitly gendered \nand sexualised.15 Tactical Tech’s work has also \ndocumented the need for particular tactics online \nand offline by marginalised communities, such \nas LGBTQ people in the Middle East, North Africa \nand Sub-Saharan Africa, and women human rights \ndefenders and activists online.16 There has also been \na mushrooming of similar projects and resources to \nmitigate the online harassment of women activists \nand journalists.17\nThese resources and projects attempt to support \nmarginalised groups online to be skilled in the \ncontrol of their visibility and anonymity in their use \nof social media as a response to negative exposure: \nouting, harassment, revenge porn, threats and \nso on. Control and responsibility are both placed \non the individual, a theme that privacy scholars \nmay say is unfair at best and untenable at worst \n(Kazansky 2015). NGOs and policy advocacy \ngroups are also working on influencing technology \nplatforms to improve their functionalities to support \nfreedom of speech and expression online.18 \nUser research and use-experience design are \nimportant fields that recognise both the need \nfor customisation of technology platforms and \ninterfaces based on users’ particular contexts, as \nwell as the ways in which users reshape technology \nplatforms. Designer Caroline Sinders (2015), for \nexample, is attempting to resist online harassment \nand violence through redesigning platforms.\nThe redesign of entire platforms is not something \nthat T4T&A advocates and technologists need \nto do. However, the development of technology \napplications does need to recognise user contexts, \nand users’ own productive reshaping of technology \nto meet their needs. T4T&A applications could \nalso adopt user-experience research approaches \nand practices to understand individual community \npractices associated with technology use. The \ncase of the crowdmap, Utunzi, underscores the \nMarginalised and activist communities appropriate \nand reshape technology to suit their own ends\n31\n40\nReflections and learningsSection 5\nvalue of user research and understanding what \nkind of visibility a community needs and wants. \nCommunity participation in the technology \ndevelopment process is an obvious solution, but \nmore valuable perhaps is a deeper appreciation of \ndifference and diverse actors within a community, \nand their roles.\nAs the South African case indicates, women are in \ngreater need of controlling their visibility, and in \nsome cases feel secure in speaking out under the \ncover of anonymity; it is very different for a white, \nmale Right to Know activist to demand complete \ntransparency than it is for a black, female, \ncommunity-based housing activist. How can \ntechnology applications respond to the contextual \ndifferences between different groups of users, or \nwithin a group of users?\nIt is also important for technologists to understand \nwhat is not working. Why did people start and \nthen abandon a platform or tool? How can \ntheir patterns of use inform the development \nof future applications? Innovations to address \ninfrastructural limitations associated with \ntechnology use and applications in resource-poor \nsettings are now common; the two case studies \nindicate that personal, community and socio-\ntechnical contexts limit the use of technology \n– particularly social media – and this needs to be \nacknowledged and addressed as well.\nAddress difference across \nmovements and communities \nof practice\nThere are limited connections between the \ndifferent communities that work on T4T&A and \nthe marginalised groups that participated in the \ntwo country case studies. Different approaches \nto change and rights evolve against varying \nhistorical contexts of discrimination / privilege, \nmarginalisation / inclusion, and activism.\nAn instance where the outcome of different \ncommunities working together was not positive \n– but was eventually turned around – was that \nof Utunzi. In parallel, there is the social media \nfeed, Speak Out, that is for and about the LGBTQ \ncommunity’s own needs for transparency and \ncollective security. There is a note of pride in \npeople’s voices, and a sense of community \nownership, when they talk about it. It is an obvious \nstatement that people from outside a community, \nwho see a problem and create a solution for it \nwithout the engagement of that community, will \noften find that they solved the wrong problem.\nIn the South Africa case study, the sampling \ndetermination exercise revealed the challenge in \nidentifying a robust sample that was representative \nof the different communities working on housing \nand urban development rights. The list of actors \nin this space included policy researchers and \nacademics to shack-dwelling activists. While this \nwas a valuable input to the sampling process, it \nwas also an important finding. Although there \nwere exceptions, there was some segregation \nby race, class and city of different actors who \nmight ostensibly be considered part of the same \nmovement. Formative interviews from South Africa \nalso strongly highlighted the role of intermediaries, \noften with reference to T4T&A actors who are \ninvolved in promoting civic technology applications \nfor communities to engage with the state.\nMovements can offer a dynamic arena within \nwhich to engage with communities, but they also \ncome with their particularities which must be \nfactored in before engaging in T4T&A activities. \nBrendan Halloran and Walter Flores, writing for \nthe Transparency and Accountability Initiative, \nintroduce a series on movements and their role in \naccountability practices and activities (Halloran \nand Flores 2015), which suggests a ‘movements \napproach’ to transparency and accountability \nactions. Our research seems to support that, \nbut with a careful consideration of the nature of \nThe social media feed, Speak Out, is for and about the LGBTQ \ncommunity’s own needs for transparency and collective \nsecurity. There is a note of pride in people’s voices, and a sense \nof community ownership, when they talk about it.\n32\n40\n19 Tactical Tech offered some reflections and lessons based on a two-year project with sex-worker communities in India and \nCambodia that had to negotiate some of these issues (Slater et al. 2015) \nSection 5 Reflections and learnings\nmovements and to integrate with them sensitively \ngiven the many differences that exist within them.\nMovements are not monolithic and carry diverse \nhistories, politics and communities within them. \nThey also have their own power dynamics and \ncreate their own centres of power and margins, \ncreating new contours of marginalisation. Both case \nstudies show evidence of this, and of the particular \nmarginalisation of women. Women and people \nidentifying as women could be encouraged and \nsupported to take on more leadership roles within \nmovements as key actors in T4T&A activities, and \nwith the recognition that this would be the first time \nfor many of these individuals and groups to have \nthis sort of agency.\nFostering spaces for technologists and community-\nbased advocates to work together and learn \nabout each other could result in technical people \nlearning more about the needs of communities for \nwhom T4T&A applications are built, and for the \ndevelopment of custom solutions and community \nownership on T4T&A projects. Technologists need \nto work in partnership with activist communities \nand movements in developing T4T&A tools that \nreflect the needs and experiences of proposed \nend-users. This could, in theory, increase the trust \namong potential end-users, and have a positive \nknock-on effect on the adoption and diffusion of \nT4T&A projects.\nThis may, however, require the assimilation \nof very different approaches to technology, \ndevelopment, human rights, and transparency \nand accountability. How different communities \ncome together and collaborate, despite the vast \ndifferences between them, is not an issue easily \naddressed in this discussion; however some \nconnections are offered here.19 \nAndrew Schrock (2016) traces a history of ‘civic \nhacking’ in the USA, making connections between \ntechnology movements – such as ‘hacktivism’ – and \ntransparency movements such as open data and \nfreedom of access to information. He discusses \nthe particular origins of ‘civic hacking’ and \napplications of technology to address the opacity \nof public institutions, and says that civic hackers \nare ‘Utopian realists’. How ‘Utopian realism’ \nmerges with the human rights focus and local \nactivisms of the marginalised actors interviewed \nhere is beyond the scope of this discussion, but is \na question that surfaces through the results. The \ndistance between communities ‘on the ground’ and \nexternal ‘experts’ has an uncomfortable legacy, \nfrom colonial dominance and missionary work, \nto more recent development projects. Efforts to \nbridge communities must recognise these different \nhistories, and the history of engagement with \ntechnologies in colonial times, and in post-colonial \nnation-building, and in moments of crisis, conflict \nand revolution. \nMiriyam Aouragh and her colleagues (2015) write \nabout some of these entanglements between \n‘activist’ and ‘techie’ movements by investigating \nweb-based campaign sites that claim to bridge \nthe existing gap between social justice activists \nand progressive techies. The authors “share[d] \na curiosity about the pursuit of fundamental \nchange that takes place at different political \ntemporalities alongside techno-inventions” (2015: \n209) and “attempted to develop a vocabulary \nand offer a snapshot that could help us attend \nto the naturalised divisions of labour and the \ndelegation practices of technology that manifest \nthemselves between activists for social justice and \nactivists for just technologies” (2015: 229). They \nfound troubling replications of universalist ideas \nabout technology that concealed the politics and \nlocations of different actors. They recommend \nvigilant critiques of these associations and of \nthe languages, mechanisms and assumptions of \nchange folded into them.\nThe work of Kavita Philip, Lily Irani and their \ncollaborators to develop “post-colonial computing” \nas a newer approach to digital divides, economic \ndisparities and varying cultural epistemologies is \nanother fruitful resource for T4T&A design and \ndevelopment projects (Irani et al. 2010; Philip et al. \n2012).\nPhilip, Irani and Dourish say that post-colonial \ncomputing is “a way of asking questions, a mode \nof investigating and a form of conversation ... an \napproach to familiar areas of research that could \ntoo easily slip into simple, rigid patterns, achieving \nclosure and canonicity at the expense of discovery \nand experimentation ”(2012: 21).\nThe post-colonial computing discourse does not \nstart with ‘development’, but is “centered on the \nquestions of power, authority, legitimacy, \nparticipation, and intelligibility in the contexts of \n33\n40\nReflections and learningsSection 5\ncultural encounter, particularly in the context of \ncontemporary globalisation” (Irani et al. 2010: 1). \nBy re-reading the scripts of techno-scientific \ndevelopment projects, such as One Laptop Per \nChild, post-colonial computing approaches \nreformulate cultural difference positively as new, \ncreative possibilities. This approach challenges \ndualisms of developed / underdeveloped, or \ntraditional / scientific, and decolonises the \nproduction of knowledge about post-colonial \nlocations. It suggests that computational design \npractices and approaches are created transnationally, \nin situ, rather than from predetermined, fixed \nlocations of users and agentic designers; and \nevolve as a function of relationships between \ndesigners, developers and users, local contextual \nforces (Philip et al. 2012: 5–7). Philip et al. \nsay that: \n“This assemblage includes not only the dreams \nof design but the messiness of manufacture as \nwell. It links materials sourcing, the context of \nmaking, and legal regimes, with the historical \nfields of discourse that make computational \ndesign possible today. Just as STS [science \nand technology studies] has highlighted the \nneed to examine the socially situated and \ncontingent nature of scientific practice, so we \nwant to draw attention to the dynamics and \ncontingencies of design methods, in order \nbetter to understand how they might be subject \nto new forms of translation, transformation, and \nreconfiguration“ (2012: 6).\nThe results of the Utunzi case and the use of \nPAIAs to get access to the housing list in South \nAfrica, offer additional insights and reflections \nabout how race, class and gender differences \nmatter in applying T4T&A. The awareness of \nvarying histories and ambitions should not be \na gratuitous indulgence of difference per se; \nit should be used to productively shape and \ninform mechanisms for articulating shared, \nand divergent, theories of change through \nthe application of T4T&A. Different ideas of \nchange through technology and data originate \nin particular histories of engagement with the \nstate; so, those who believe in ‘connecting \ncitizens to states through wires and expecting \nthem to talk to each other’ may need to verify \nthese assumptions with target communities. \nOr, if certain users and practitioners within a \nmovement require greater privacy than others, \nhow can that be factored in?\nSchrock (2016) points out that within the \nhistorical evolution of civic hacking and the move \nfrom information to data in the transparency \nmovement, the objective may well be the receipt \nof information from the state, but not a plan for \nwhat is done with that information, as respondents \nin this study have noted. He ends by saying that \nnew mechanisms and approaches may be needed \nbeyond just applications of technology, as has \nbeen discussed here:\n“Systemic social disparities are often intractable. \nThe route to alleviate them has never been \ndetachment or abandonment. Looking forward, \nwe should pay attention to how data activism \nand advocacy might result in meaningful \nsystematic change beyond the usual claims \nof ‘transparency.’ To fulfil the possibilities for \nmeaningful social change hinted at in their \nhistory, civic hackers might have to coordinate \naround specific mechanisms for change and \narticulate a deeper sense of democracy than \nthe language of technology provides” (Schrock \n2016: 15).\nPut human rights first\nResults from this paper are filtered into reflections \non the need to engage users and user practices \nin the development of T4T&A applications; and to \nproductively address the differences within and \nacross movements in these engaged collaborations. \nHowever, this study concludes with the obvious \nstatement that for such communities to be involved \nin T4T&A activities beyond organising, mobilising \nand developing a community identity, they need \nto feel more confident and assured that their \nengagement will result in positive change and not \nbe penalised.\nThe LGBTQ activists from Kenya, and the low-\nincome black and mixed-race activists in South \nAfrica, are in states of significant marginalisation, \nand criminalisation by the state. The facts of \nmarginalisation and lack of rights cannot be \nignored, and perhaps have to be the primary \nsubject of T4T&A activities and engagement. \nThis is not to suggest that T4T&A activities \ncannot happen until poverty or marginalisation \nare eradicated. Rather, it is to suggest that a \ngovernment that may be transparent about aid \nflows or the repair of public toilets, yet does not \naddress the violence against its queer citizens, \nor continues to use violence and surveillance \n34\n40\nReflections and learningsSection 5\nto squash dissent by marginalised citizens who \nsimply need basic services, is an example of the \nselective transparency that Dieter Zinnbauer has \nspoken of. It is this institutionalised selective \ntransparency that allows for the perpetuation \nof marginalisation in society; it is perhaps this \nselective transparency that should be the focus of \nT4T&A activities.\nThere is a pervasive misconception about the \nbenefits of technology in bringing about social \nchange. Technology platforms do not bring about \nchange themselves and quite often just replicate \nthe inequalities and divisions which exist in the \noffline world. Nevertheless, many online tools are \nused within the community, and to great effect. \nWhile digital and Web 2.0 technologies have the \nability to access or generate data that could hold \ngovernments to account, what is perhaps required \nis the ability to know how to use that data in \nadvocacy and campaigning; it is not an end-point in \nitself. Marginal groups perhaps need to learn how \nto engage with information as strategic leverage in \nadvocacy for their rights. Of course, for this to be \nsuccessful, members of marginalised groups need \nto feel that their rights are respected and they will \nnot be punished for demanding them.\nIn a 2007 paper that reported on interaction \nwith low-income, marginalised women living in a \ntransitional home facility, Virginia Eubanks offered \ncompelling insights to what it could mean for such \npeople to use technology and become part of the \n“high tech equity agenda” (Eubanks 2007: no \npage). She used the concept of the digital divide \nand asked women in the facility what it would take \nfor people like them, the ‘have-nots’, to become \n‘haves’. Through a drawing exercise, the women \ncreated a vision of what it would take for them to \nbecome more active users of technology to address \ntheir marginalisation. None of these drawings were \nabout building new skills or resources. The barriers \nthey identified were structural inequality, systemic \ninequality, racial prejudice, greed, classism, \neconomic exploitation, basic needs, education, \nand other social supports. The way to bridge the \ndivide, Eubanks concluded, was not to focus on the \nusers themselves, but on the structural inequalities \nthey face. The women in the study recommended \nstronger networks that connected people to each \nother as a way of bridging a range of divides: \nsocial, economic and infrastructural. It was only \nthrough people’s connections to, and empathy for, \neach other that these women believed technology \nwould have any valuable role. \nThere is a pervasive misconception about the benefits of \ntechnology in bringing about social change. Technology \nplatforms do not bring about change themselves. Quite \noften, they just replicate the inequalities and divisions \nwhich exist in the offline world.\n35\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nReferences\nAl Jazeera America (2015) Chaos at South \nAfrica Parliament as Police Clash with Protesting \nStudents, 21 October, http://america.aljazeera.\ncom/articles/2015/10/21/south-african-police-\nstudents-clash-at-parliament.html (accessed 30 \nMay 2016)\nAouragh, M.; Gürses, S.; Rocha, J. and Snelting, F. \n(2015) ‘Let’s First Get Things Done! On Division \nof Labour and Techno-political Practices of \nDelegation in Times of Crisis’, The Fibreculture \nJournal 26: 208–235, http://twentysix.\nfibreculturejournal.org/fcj-196-lets-first-get-\nthings-done-on-division-of-labour-and-techno-\npolitical-practices-of-delegation-in-times-of-crisis \n(accessed 3 June 2016)\nAnderson, M. (1999) Do No Harm: How Can Aid \nSupport Peace or War? Boulder: Lynne Rienner \nPublishers\nAndrejevic, M. (2005) ‘The Work of Watching \nOne Another: Lateral Surveillance, Risk, and \nGovernance’, Surveillance & Society 2.4: \n479–497, www.surveillance-and-society.org/\narticles2%284%29/lateral.pdf (accessed 3 June \n2016)\nAravosis, J. (2014) ‘“Grindr” Gay Smartphone \nApp Turns off “Distance” Option in Face of \nPrivacy Concerns’, AMERICAblog, 1 July, http://\namericablog.com/2014/09/gay-grindr-\nsmartphone-app-turns-distance-option-privacy-\ncomplaints.html (accessed 3 June 2016)\nBall, J. (2014) ‘Mozilla CEO Insists He Won’t \nResign Over ‘Private’ Support for Gay Marriage \nBan’, The Guardian, 2 April, www.theguardian.com/\ntechnology/2014/apr/01/mozilla-ceo-brendan-\neich-refuses-to-quit (accessed 3 June 2016)\nBBC News (2009) ‘Kenya Begins Contentious \nCensus’, 24 August, http://news.bbc.co.uk/1/\nhi/world/africa/8217637.stm (accessed 1 June \n2016)\nBoehler, P. and Sam, C. (2014) ‘Fake “Occupy \nCentral” App Targets Activists’ Smartphones with \nSpyware’, South China Morning Post, 1 October, \nwww.scmp.com/news/hong-kong/\narticle/1594667/fake-occupy-central-app-\ntargets-activists-smartphones (accessed 3 June \n2016)\nCAL and GALCK (2016) Research on the Lived \nExperiences of Lesbian, Bisexual and Queer Women \nin Kenya, Johannesburg: Coalition of African \nLesbians; Nairobi: Gay and Lesbian Coalition of \nKenya, https://issuu.com/galckkenya/docs/\nresearch_on_the_lived_experiences_o (accessed 3 \nJune 2016) \nClark, M. (2014) An Anatomy of Dissent and \nRepression: The Criminal Justice System and the \n2011 Thembelihle Protest. Johannesburg: Socio-\nEconomic Rights Institute of South Africa, www.\nseri- sa.org/images/Thembelihle_FINAL_web.pdf \n(accessed 3 June 2016)\nde Lanerolle, I. (2012) ‘‘The New Wave’: \nWho Connects to the Internet, How they \nConnect, and What they Do When they Connect’, \nSouth Africa Network Society Project, \nJohannesburg: University of Witwatersrand, \nwww.worldinternetproject.net/_files/_Published/_\noldis/413_wip_south_african_2012.pdf (accessed 3 \nJune 2016)\nEdwards, P.N. and Hecht, G. (2010) ‘History \nand the Technopolitics of Identity: The Case of \nApartheid South Africa’, Journal of South African \nStudies 36.3: 619–639\nEubanks, V. (2014) ‘Big Data and Human Rights’, \nin S.P. Gangadharan (ed.) Data and Discrimination: \nCollected Essays, Washington DC: New America \nFoundation\nEubanks, V. (2007) ‘Trapped in the Digital \nDivide: The Distributive Paradigm in Community \nInformatics’, The Journal of Community Informatics \n3: 293–318, http://ci-journal.net/index.php/ciej/\narticle/view/293/318 (accessed 3 June 2016)\nFoucault, M. (1976) The History of Sexuality, \nVolume 1, Paris: Hachette\n36\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nGuerses, S. (2012) ‘The Spectre of Anonymity’, \nVous Etes Ici: The Online Guide to Seda-\nthink, http://vous-etes-ici.net/wp-content/\nuploads/2014/02/SedaAnonymityMute.pdf \n(accessed 3 June 2016)\nGunter, J. (2014) ‘Digital surveillance in Angola \nand Other “Less Important” African Countries’, \nGlobal Voices, 26 February, http://advocacy.\nglobalvoicesonline.org/2014/02/26/digital-\nsurveillance-in-angola-and-other-less-important-\nafrican-countries (accessed 3 June 2016)\nHalloran, B. and Flores, W. (2015) ‘Mobilizing \nAccountability: Citizens, Movements and the State’, \nTransparency and Accountability Initiative Think \nPiece, http://transparencyinitiative.theideabureau.\nnetdna-cdn.com/wp-content/uploads/2015/05/\nMovements-and-Accountability-Final.pdf (accessed \n3 June 2016)\nHuchzermeyer, M. (2013) ‘Humanism, Creativity \nand Rights: Invoking Henri Lefebvre’s Right to \nthe City in the Tension Presented by Informal \nSettlements in South Africa Today’, Inaugural \nLecture, School of Architecture and Planning, \nUniversity of the Witwatersrand, 12 November, \nhttp://abahlali.org/wp-content/uploads/2013/11/\nMarie.lecture.pdf (accessed 3 June 2016)\nIrani, L.; Vertesi. J.; Dourish, P.; Philip, K. and \nGrinter, R.E. (2010) ‘Postcolonial Computing: A \nLens on Design and Development’, Proceedings \nof the ACM Conference on Human Factors \nin Computing Systems CHI 2010, Atlanta, \nGeorgia, 1311–1320, www.dourish.com/\npublications/2010/chi2010-postcolonial.pdf \n(accessed 24 June 2016)\nKazansky, B. (2015) ‘Privacy, Responsibility and \nHuman Rights’, Fibreculture Journal 26: 189–207, \nhttp://twentysix.fibreculturejournal.org/fcj-195-\nprivacy-responsibility-and-human-rights-activism \n(accessed 3 June 2016)\nKvinna till Kvinna Foundation (2014) Femdefenders: \nThe Hatred against Women Human Rights Defenders \nOnline and Offline, Johannesburg: Kvinna till Kvinna \nFoundation http://kvinnatillkvinna.se/en/files/\nqbank/d863d5ec458b0dc3b46cba96d9d49ac3.pdf \n(accessed 3 June 2016)\nMamba (2014) ‘Police Using WhatsApp to Entrap \nGay Men’, Mamba Online, 28 August, www.\nmambaonline.com/2014/08/28/police-using-\nwhatsapp-entrap-gay-men (accessed 3 June 2016)\nMarczak, B.; Guarnieri, C.; Marquis-Boire, M. \nand Scott-Railton, J. (2014) ‘Mapping Hacking \nTeam’s ‘Untraceable’ Software’, Research Brief, \nToronto: University of Toronto Munk School \nof Global Affairs, https://citizenlab.org/wp-\ncontent/uploads/2015/03/Mapping-Hacking-\nTeam%E2%80%99s-_Untraceable_-Spyware.pdf \n(accessed 3 June 2016)\nMatias, J.N.; Johnson, A.; Boesel, W.E.; Keegan, \nB.; Friedman, J. and DeTar, C. (2015) Reporting, \nReviewing, and Responding to Harassment on \nTwitter, Cambridge, MA: Women, Action and the \nMedia, http://womenactionmedia.org/cms/assets/\nuploads/2015/05/wam-twitter-abuse-report.pdf \n(accessed 3 June 2016) \nMcGee, R. and Carlitz, R. (2013) Learning Study \non ‘The Users’ in Technology for Transparency \nand Accountability Initiatives: Assumptions \nand Realities, Brighton: IDS, www.ids.ac.uk/\npublication/learning-study-on-the-users-in-\ntechnology-for-transparency-and-accountability-\ninitiatives-assumptions-and-realities (accessed 3 \nJune 2016)\nMEF (2014) MEF Global Consumer Trust Report \n2015 , San Francisco: Mobile Ecosystem Forum, \nhttp://now.avg.com/mef-global-trust-report-\n2015(accessed 3 June 2016)\nMinkoff, M.; Moore, M.; Poindexter, S. and Welsh, \nB. (2014) ‘Proposition 8: Who Gave in the Gay \nMarriage Battle?’ Los Angeles Times, http://\nprojects.latimes.com/prop8/ (accessed 3 June \n2016)\nMonahan, T. (2009) ‘Dreams of Control at a \nDistance: Gender, Surveillance and Social Control’, \nCultural Studies ↔ Critical Methodologies 9.2: \n286–305 \nMuftah (2014) ‘Egyptian Activist, Alaa Abd El-\nFattah, Penalized by Sarkhov Prize Nominating \nCommittee for Speaking Out Against Israel’, 8 \nOctober, http://muftah.org/sarkhov-freedom-\nthought-prize-nomination-rescinded-egyptian-\nactivist-alaa-speaking-israel/#.V3qBZZN97BI \n(accessed 3 June 2016)\n37\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nNotley, T.; Lowenthal, A. and Gregory, S. (2015) \nVideo for Change: Creating and Measuring Social \nImpact. Working Paper, Video4Change Network, \nwww.v4c.org/en/impact_working_paper (accessed \n3 June 2016)\nNyambura-Mwaura, H. (2009) ‘Ethnic Question \nin Kenya Census Stokes Suspicions,’ Reuters, 25 \nAugust, www.reuters.com/article/2009/08/25/\nozatp-kenya-census-idAFJOE57O0GP20090825 \n(accessed 3 June 2016)\nNYCLU (no date) Stop and Frisk Campaign: About \nthe Issue, New York Civil Liberties Union, www.\nnyclu.org/issues/racial-justice/stop-and-frisk-\npractices (accessed 3 June 2016) \nPew Research Center (2013) The Global Divide \non Homosexuality, Washington DC: Pew Research \nCenter, www.pewglobal.org/2013/06/04/the-\nglobal-divide-on-homosexuality (accessed 3 June \n2016)\nPhillip, K.; Irani, L. and Dourish, P. (2012) \n‘Postcolonial Computing: A Tactical Survey’, \nScience, Technology and Human Values 37.1: 3–29\nPrivacy International (2015) Encryption and \nAnonymity Create a “Zone of Privacy” Online, \nsays UN Special Rapporteur’, 17 June, https://\nprivacyinternational.org/?q=node/600 (accessed \n3 June 2016)\nR2K (2015) Big Brother Exposed: Stories of \nSouth Africa’s Intelligence Structures Monitoring \nand Harassing Activist Movements, Salt River: \nRight to Know, http://bigbrother.r2k.org.za/\nwp-content/uploads/Big-Brother-Exposed-R2K-\nhandbook-on-surveillance-web.pdf (accessed 3 \nJune 2016)\nRobertson, H. and Travaglia, J. (2015) ‘Big Data \nProblems We Face Today can be Traced to the \nSocial Ordering Practices of the 19th Century’, LSE \nImpact Blog, 13 October, http://blogs.lse.ac.uk/\nimpactofsocialsciences/2015/10/13/ideological-\ninheritances-in-the-data-revolution/ (accessed 3 \nJune 2016)\nRonan, E. (2014) ‘Kenya Shuts Down 500 \ngroups in Anti-terrorism Crackdown’, Al Jazeera, \n16 December, www.aljazeera.com/news/\nafrica/2014/12/kenya-closes-down-hundreds-\nngos-20141216124722577348.html (accessed 3 \nJune 2016)\nSasaki, D. and Rising Voices (2010) Technology for \nTransparency: The Role of Technology and Citizen \nMedia in Promoting Transparency, Accountability \nand Civic Participation, Cape Town: Technology \nfor Transparency Network, www.right2info.\norg/resources/publications/technology-for-\ntransparency (accessed 3 June 2016)\nSchoemaker, E. (2015) ‘Facebook Domestication’, \nTanqeed, July, www.tanqeed.org/2015/07/\nFacebook-domestication (accessed 3 June 2016)\nSchrock, A. (2016) ‘Civic Hacking as Data Activism \nand Advocacy: A History from Publicity to Open \nGovernment Data’, New Media and Society 1.19: \n1–15\nSheils, C. (2014) ‘Egyptian Cops Using Grindr \nto Hunt Gays’, CairoScene, 1 September, www.\ncairoscene.com/LifeStyle/Egyptian-Cops-Using-\nGrindr-To-Hunt-Gays (accessed 3 June 2016)\nSinders, C. (2015) ‘I Was on One of Those \nCanceled SXSW Panels’, Slate, 29 October, www.\nslate.com/articles/double_x/doublex/2015/10/\nsxsw_canceled_panels_here_is_what_happened.\nhtml (accessed 3 June 2016)\nSlater, D.; Ganesh, M. and Martini, B. (2015) ‘Leave \nyour Potatoes at Home: Working with Marginalised \nCommunities on Using Data and Tech in Advocacy’, \nVisualising Information for Advocacy Blog, 17 \nApril, https://visualisingadvocacy.org/blog/\nleave-your-potatoes-home-working-marginalised-\ncommunities-using-data-and-tech-advocacy \n(accessed 30 May 2016)\nStanley, J. (2015) ‘Police Body-mounted Cameras: \nWith Right Policies in Place, a Win for All’, American \nCivil Liberties Union, www.aclu.org/police-body-\nmounted-cameras-right-policies-place-win-all \n(accessed 3 June 2016)\nTewksbury, R. (1996) ‘Cruising for Sex in Public \nPlaces: The Structure and Language of Men’s \nHidden Erotic Worlds’, Deviant Behavior 17: 1–19\nTissington, K.; Munshi, N; Mirugi-Mukundi, G. \nand Durojaye, E. (2013) “Jumping the Queue” \nWaiting Lists and Other Myths: Perceptions and \n38\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nPractices around Housing Demand and Allocation \nin South Africa, Johannesburg: Community Law \nCentre and Socio Economic Rights Institute of \nSouth Africa, www.seri-sa.org/images/Jumping_\nthe_Queue_MainReport_Jul13.pdf (accessed 3 \nJune 2016)\nUkwazi, N. (2014) Our Toilets are Dirty: Report \nof the Social Audit into the Janitorial Service for \nCommunal Flush Toilets in Khayelitsha, Cape Town, \nCape Town: International Budget Partnership and \nSocial Justice Coalition, http://nu.org.za/wp-\ncontent/uploads/2014/09/Social-Audit-report-\nfinal.pdf (accessed 3 June 2016)\nVrankulj, A. (2014) ‘UNHCR adopts IrisGuard \ntechnology for refugee registration’, Biometric \nUpdate, www.biometricupdate.com/201402/\nunhcr-adopts-irisguard-technology-for-refugee-\nregistration (accessed 3 June 2016)\nWeeks, J. (2000) Making Sexual History, \nCambridge: Polity Press\nWinker, G. and Degele, N. (2011) ‘Intersectionality \nas Multi-level Analysis: Dealing with Social \nInequality’, European Journal of Women’s Studies \n18.1: 51–66\nZinnbauer, D. (2012) ‘Fighting Corruption Where \nand When It Happens – Ambient Accountability’, \nin D. Offenhuber and K. Schechtner (eds) \nAccountability Technologies - Tools For Asking Hard \nQuestions, Berlin: Ambra\n39\n40\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\nPrivacy, anonymity, visibility: dilemmas in tech use by marginalised communities\n40\n40\nAbout Making All Voices Count\nMaking All Voices Count is a programme working towards a world in which open, effective and participatory \ngovernance is the norm and not the exception. This Grand Challenge focuses global attention on creative \nand cutting-edge solutions to transform the relationship between citizens and their governments. The field \nof technology for Open Government is relatively young and the consortium partners, Hivos, the Institute of \nDevelopment Studies (IDS) and Ushahidi, are a part of this rapidly developing domain. These institutions \nhave extensive and complementary skills and experience in the field of citizen engagement, government \naccountability, private sector entrepreneurs, (technical) innovation and research.\nMaking All Voices Count is supported by the UK Department for International Development (DFID), the \nUS Agency for International Development (USAID), the Swedish International Development Cooperation \nAgency (SIDA) and the Omidyar Network, and is implemented by a consortium consisting of Hivos, IDS and \nUshahidi. The programme is inspired by and supports the goals of the Open Government Partnership.\nResearch, Evidence and Learning component\nThe programme’s research, evidence and learning contributes to improving performance and practice, \nand builds an evidence base in the field of citizen voice, government responsiveness, transparency \nand accountability (T&A) and technology for T&A (Tech4T&A). This component is managed by IDS, a \nleading global organisation for research, teaching and communication with over 30 years’ experience of \ndeveloping knowledge on governance and citizen participation.\nAbout Tactical Tech\nTactical Tech is a non-profit organisation, working since 2003 to advance the use of information and \ndigital technologies by advocates and activists worldwide. Based in Berlin, Tactical Tech works with \nan international network of partners and collaborators to help rights, accountability and transparency \nadvocates and the communities they work with to use information and digital technologies effectively \nin their work, empowering them to effect progressive social, environmental and political change. Its \nwork – developed out of a decade of direct capacity building worldwide – seeks to practically develop \nthe specialised information and technology skills and strategies of those working to defend and advance \nfundamental freedoms and to advance critical thinking, methodology and best practice within the sector.\nDisclaimer: This document has been produced with the financial support of the Omidyar Network, SIDA, \nDFID and USAID. The views expressed in this publication do not necessarily reflect the official policies of \nour funders.\nWeb www.makingallvoicescount.org\nEmail info@makingallvoicescount.org\nTwitter @allvoicescount\nImplemented by:\nIDS_Master Logo\n",
    "id": 43543118,
    "identifiers": {
        "doi": null,
        "oai": "oai:opendocs.ids.ac.uk:123456789/12110"
    },
    "title": "Privacy, anonymity, visibility: dilemmas in tech use by marginalised communities",
    "language": null,
    "publishedDate": "",
    "publisher": "Institute of Development Studies",
    "references": [],
    "sourceFulltextUrls": [],
    "updatedDate": "",
    "yearPublished": "2016",
    "links": [
        {
            "type": "download",
            "url": "https://core.ac.uk/download/pdf/43543118.pdf"
        },
        {
            "type": "reader",
            "url": "https://core.ac.uk/reader/43543118"
        },
        {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/43543118/medium"
        },
        {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/43543118/large"
        },
        {
            "type": "display",
            "url": "https://core.ac.uk/outputs/43543118"
        }
    ],
    "abstract": "Making All Voices Count Research ReportThis paper synthesises reflections and learnings from two studies, in Kenya and South Africa, about how marginalised communities – lesbian, gay, bisexual, trans and queer (LGBTQ) people in Nairobi, Kenya, and economically marginalised housing and urban development rights activists in Johannesburg, South Africa – use technologies commonly applied in transparency and accountability work, and the limits of their use of these technologies.Omidyar NetworkSIDADFIDUSAI",
    "tags": [
        "Series paper (non-IDS)",
        "Rights",
        "Sexuality and Development",
        "Technology"
    ],
    "fulltextStatus": "enabled",
    "subjects": [
        "Series paper (non-IDS)"
    ],
    "oai": "oai:opendocs.ids.ac.uk:123456789/12110",
    "deleted": "ALLOWED",
    "disabled": false,
    "journals": null,
    "repositories": {
        "id": "603",
        "openDoarId": 0,
        "name": "IDS OpenDocs",
        "urlHomepage": null,
        "uriJournals": null,
        "physicalName": "noname",
        "roarId": 0,
        "pdfStatus": null,
        "nrUpdates": 0,
        "lastUpdateTime": null
    },
    "repositoryDocument": {
        "id": 43543118,
        "depositedDate": null,
        "publishedDate": null,
        "updatedDate": "2019-06-08T19:02:05+01:00",
        "acceptedDate": null,
        "createdDate": "2016-08-09T11:27:56+01:00"
    },
    "urls": [
        "http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "http://opendocs.ids.ac.uk/opendocs/handle/123456789/12110"
    ],
    "lastUpdate": "2019-06-08T19:02:05+01:00",
    "setSpecs": []
}